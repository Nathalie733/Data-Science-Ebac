2024-08-22 17:28:03,379:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-22 17:28:03,379:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-22 17:28:03,379:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-22 17:28:03,380:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-22 18:06:02,638:INFO:PyCaret ClassificationExperiment
2024-08-22 18:06:02,638:INFO:Logging name: clf-default-name
2024-08-22 18:06:02,640:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-08-22 18:06:02,640:INFO:version 3.3.2
2024-08-22 18:06:02,640:INFO:Initializing setup()
2024-08-22 18:06:02,640:INFO:self.USI: 1b34
2024-08-22 18:06:02,640:INFO:self._variable_keys: {'_ml_usecase', 'X_test', 'data', 'X', 'html_param', 'is_multiclass', 'fold_shuffle_param', 'y_train', 'fold_groups_param', 'y', 'memory', 'gpu_n_jobs_param', 'USI', 'fold_generator', 'pipeline', 'log_plots_param', 'seed', 'gpu_param', 'exp_name_log', 'logging_param', '_available_plots', 'X_train', 'target_param', 'y_test', 'idx', 'exp_id', 'n_jobs_param', 'fix_imbalance'}
2024-08-22 18:06:02,640:INFO:Checking environment
2024-08-22 18:06:02,640:INFO:python_version: 3.11.5
2024-08-22 18:06:02,640:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-08-22 18:06:02,640:INFO:machine: AMD64
2024-08-22 18:06:02,640:INFO:platform: Windows-10-10.0.22631-SP0
2024-08-22 18:06:02,642:INFO:Memory: svmem(total=8311836672, available=1225224192, percent=85.3, used=7086612480, free=1225224192)
2024-08-22 18:06:02,642:INFO:Physical Core: 4
2024-08-22 18:06:02,642:INFO:Logical Core: 8
2024-08-22 18:06:02,642:INFO:Checking libraries
2024-08-22 18:06:02,642:INFO:System:
2024-08-22 18:06:02,642:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-08-22 18:06:02,642:INFO:executable: C:\Users\natha\anaconda3\python.exe
2024-08-22 18:06:02,642:INFO:   machine: Windows-10-10.0.22631-SP0
2024-08-22 18:06:02,642:INFO:PyCaret required dependencies:
2024-08-22 18:06:05,976:INFO:                 pip: 23.2.1
2024-08-22 18:06:05,976:INFO:          setuptools: 68.0.0
2024-08-22 18:06:05,976:INFO:             pycaret: 3.3.2
2024-08-22 18:06:05,976:INFO:             IPython: 8.15.0
2024-08-22 18:06:05,976:INFO:          ipywidgets: 8.0.4
2024-08-22 18:06:05,976:INFO:                tqdm: 4.65.0
2024-08-22 18:06:05,976:INFO:               numpy: 1.24.3
2024-08-22 18:06:05,976:INFO:              pandas: 2.0.3
2024-08-22 18:06:05,977:INFO:              jinja2: 3.1.2
2024-08-22 18:06:05,977:INFO:               scipy: 1.11.1
2024-08-22 18:06:05,977:INFO:              joblib: 1.3.2
2024-08-22 18:06:05,977:INFO:             sklearn: 1.4.2
2024-08-22 18:06:05,977:INFO:                pyod: 2.0.1
2024-08-22 18:06:05,977:INFO:            imblearn: 0.12.3
2024-08-22 18:06:05,977:INFO:   category_encoders: 2.6.3
2024-08-22 18:06:05,978:INFO:            lightgbm: 4.5.0
2024-08-22 18:06:05,978:INFO:               numba: 0.57.1
2024-08-22 18:06:05,978:INFO:            requests: 2.31.0
2024-08-22 18:06:05,978:INFO:          matplotlib: 3.7.2
2024-08-22 18:06:05,978:INFO:          scikitplot: 0.3.7
2024-08-22 18:06:05,978:INFO:         yellowbrick: 1.5
2024-08-22 18:06:05,978:INFO:              plotly: 5.23.0
2024-08-22 18:06:05,978:INFO:    plotly-resampler: Not installed
2024-08-22 18:06:05,978:INFO:             kaleido: 0.2.1
2024-08-22 18:06:05,978:INFO:           schemdraw: 0.15
2024-08-22 18:06:05,979:INFO:         statsmodels: 0.14.0
2024-08-22 18:06:05,979:INFO:              sktime: 0.26.0
2024-08-22 18:06:05,979:INFO:               tbats: 1.1.3
2024-08-22 18:06:05,979:INFO:            pmdarima: 2.0.4
2024-08-22 18:06:05,979:INFO:              psutil: 5.9.0
2024-08-22 18:06:05,979:INFO:          markupsafe: 2.1.1
2024-08-22 18:06:05,979:INFO:             pickle5: Not installed
2024-08-22 18:06:05,979:INFO:         cloudpickle: 2.2.1
2024-08-22 18:06:05,979:INFO:         deprecation: 2.1.0
2024-08-22 18:06:05,979:INFO:              xxhash: 2.0.2
2024-08-22 18:06:05,980:INFO:           wurlitzer: Not installed
2024-08-22 18:06:05,980:INFO:PyCaret optional dependencies:
2024-08-22 18:06:06,009:INFO:                shap: Not installed
2024-08-22 18:06:06,010:INFO:           interpret: Not installed
2024-08-22 18:06:06,010:INFO:                umap: Not installed
2024-08-22 18:06:06,010:INFO:     ydata_profiling: 4.7.0
2024-08-22 18:06:06,010:INFO:  explainerdashboard: Not installed
2024-08-22 18:06:06,010:INFO:             autoviz: Not installed
2024-08-22 18:06:06,010:INFO:           fairlearn: Not installed
2024-08-22 18:06:06,010:INFO:          deepchecks: Not installed
2024-08-22 18:06:06,010:INFO:             xgboost: Not installed
2024-08-22 18:06:06,010:INFO:            catboost: Not installed
2024-08-22 18:06:06,010:INFO:              kmodes: Not installed
2024-08-22 18:06:06,010:INFO:             mlxtend: Not installed
2024-08-22 18:06:06,010:INFO:       statsforecast: Not installed
2024-08-22 18:06:06,011:INFO:        tune_sklearn: Not installed
2024-08-22 18:06:06,011:INFO:                 ray: Not installed
2024-08-22 18:06:06,011:INFO:            hyperopt: Not installed
2024-08-22 18:06:06,011:INFO:              optuna: Not installed
2024-08-22 18:06:06,011:INFO:               skopt: Not installed
2024-08-22 18:06:06,011:INFO:              mlflow: Not installed
2024-08-22 18:06:06,011:INFO:              gradio: Not installed
2024-08-22 18:06:06,011:INFO:             fastapi: Not installed
2024-08-22 18:06:06,011:INFO:             uvicorn: Not installed
2024-08-22 18:06:06,011:INFO:              m2cgen: Not installed
2024-08-22 18:06:06,011:INFO:           evidently: Not installed
2024-08-22 18:06:06,011:INFO:               fugue: Not installed
2024-08-22 18:06:06,012:INFO:           streamlit: Not installed
2024-08-22 18:06:06,012:INFO:             prophet: Not installed
2024-08-22 18:06:06,012:INFO:None
2024-08-22 18:06:06,012:INFO:Set up data.
2024-08-22 18:06:06,077:INFO:Set up folding strategy.
2024-08-22 18:06:06,077:INFO:Set up train/test split.
2024-08-22 18:06:06,115:INFO:Set up index.
2024-08-22 18:06:06,115:INFO:Assigning column types.
2024-08-22 18:06:06,128:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-08-22 18:06:06,171:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-22 18:06:06,176:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-22 18:06:06,215:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 18:06:06,216:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 18:06:06,282:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-22 18:06:06,283:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-22 18:06:06,308:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 18:06:06,308:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 18:06:06,309:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-08-22 18:06:06,350:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-22 18:06:06,376:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 18:06:06,376:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 18:06:06,422:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-22 18:06:06,450:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 18:06:06,450:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 18:06:06,454:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-08-22 18:06:06,542:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 18:06:06,543:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 18:06:06,665:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 18:06:06,665:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 18:06:06,673:INFO:Preparing preprocessing pipeline...
2024-08-22 18:06:06,677:INFO:Set up simple imputation.
2024-08-22 18:06:06,695:INFO:Set up encoding of ordinal features.
2024-08-22 18:06:06,708:INFO:Set up encoding of categorical features.
2024-08-22 18:06:07,156:INFO:Finished creating preprocessing pipeline.
2024-08-22 18:06:07,187:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\natha\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean')...
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['tipo_renda', 'educacao',
                                             'estado_civil',
                                             'tipo_residencia'],
                                    transformer=OneHotEncoder(cols=['tipo_renda',
                                                                    'educacao',
                                                                    'estado_civil',
                                                                    'tipo_residencia'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2024-08-22 18:06:07,187:INFO:Creating final display dataframe.
2024-08-22 18:06:07,803:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target               mau
2                   Target type            Binary
3           Original data shape       (38000, 13)
4        Transformed data shape       (38000, 30)
5   Transformed train set shape       (26600, 30)
6    Transformed test set shape       (11400, 30)
7              Numeric features                 5
8          Categorical features                 7
9      Rows with missing values             17.1%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  clf-default-name
22                          USI              1b34
2024-08-22 18:06:07,898:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 18:06:07,898:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 18:06:08,007:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 18:06:08,008:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 18:06:08,009:INFO:setup() successfully completed in 5.37s...............
2024-08-22 18:06:10,876:INFO:gpu_param set to False
2024-08-22 18:06:10,964:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 18:06:10,965:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 18:06:11,036:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 18:06:11,036:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 18:08:08,358:INFO:PyCaret ClassificationExperiment
2024-08-22 18:08:08,358:INFO:Logging name: clf-default-name
2024-08-22 18:08:08,359:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-08-22 18:08:08,359:INFO:version 3.3.2
2024-08-22 18:08:08,359:INFO:Initializing setup()
2024-08-22 18:08:08,359:INFO:self.USI: d6d0
2024-08-22 18:08:08,359:INFO:self._variable_keys: {'_ml_usecase', 'X_test', 'data', 'X', 'html_param', 'is_multiclass', 'fold_shuffle_param', 'y_train', 'fold_groups_param', 'y', 'memory', 'gpu_n_jobs_param', 'USI', 'fold_generator', 'pipeline', 'log_plots_param', 'seed', 'gpu_param', 'exp_name_log', 'logging_param', '_available_plots', 'X_train', 'target_param', 'y_test', 'idx', 'exp_id', 'n_jobs_param', 'fix_imbalance'}
2024-08-22 18:08:08,359:INFO:Checking environment
2024-08-22 18:08:08,360:INFO:python_version: 3.11.5
2024-08-22 18:08:08,360:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-08-22 18:08:08,360:INFO:machine: AMD64
2024-08-22 18:08:08,360:INFO:platform: Windows-10-10.0.22631-SP0
2024-08-22 18:08:08,360:INFO:Memory: svmem(total=8311836672, available=1052577792, percent=87.3, used=7259258880, free=1052577792)
2024-08-22 18:08:08,360:INFO:Physical Core: 4
2024-08-22 18:08:08,360:INFO:Logical Core: 8
2024-08-22 18:08:08,360:INFO:Checking libraries
2024-08-22 18:08:08,360:INFO:System:
2024-08-22 18:08:08,360:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-08-22 18:08:08,360:INFO:executable: C:\Users\natha\anaconda3\python.exe
2024-08-22 18:08:08,360:INFO:   machine: Windows-10-10.0.22631-SP0
2024-08-22 18:08:08,360:INFO:PyCaret required dependencies:
2024-08-22 18:08:08,360:INFO:                 pip: 23.2.1
2024-08-22 18:08:08,360:INFO:          setuptools: 68.0.0
2024-08-22 18:08:08,360:INFO:             pycaret: 3.3.2
2024-08-22 18:08:08,360:INFO:             IPython: 8.15.0
2024-08-22 18:08:08,361:INFO:          ipywidgets: 8.0.4
2024-08-22 18:08:08,361:INFO:                tqdm: 4.65.0
2024-08-22 18:08:08,361:INFO:               numpy: 1.24.3
2024-08-22 18:08:08,361:INFO:              pandas: 2.0.3
2024-08-22 18:08:08,361:INFO:              jinja2: 3.1.2
2024-08-22 18:08:08,361:INFO:               scipy: 1.11.1
2024-08-22 18:08:08,361:INFO:              joblib: 1.3.2
2024-08-22 18:08:08,361:INFO:             sklearn: 1.4.2
2024-08-22 18:08:08,361:INFO:                pyod: 2.0.1
2024-08-22 18:08:08,361:INFO:            imblearn: 0.12.3
2024-08-22 18:08:08,361:INFO:   category_encoders: 2.6.3
2024-08-22 18:08:08,362:INFO:            lightgbm: 4.5.0
2024-08-22 18:08:08,362:INFO:               numba: 0.57.1
2024-08-22 18:08:08,362:INFO:            requests: 2.31.0
2024-08-22 18:08:08,362:INFO:          matplotlib: 3.7.2
2024-08-22 18:08:08,362:INFO:          scikitplot: 0.3.7
2024-08-22 18:08:08,362:INFO:         yellowbrick: 1.5
2024-08-22 18:08:08,362:INFO:              plotly: 5.23.0
2024-08-22 18:08:08,362:INFO:    plotly-resampler: Not installed
2024-08-22 18:08:08,362:INFO:             kaleido: 0.2.1
2024-08-22 18:08:08,362:INFO:           schemdraw: 0.15
2024-08-22 18:08:08,362:INFO:         statsmodels: 0.14.0
2024-08-22 18:08:08,362:INFO:              sktime: 0.26.0
2024-08-22 18:08:08,362:INFO:               tbats: 1.1.3
2024-08-22 18:08:08,362:INFO:            pmdarima: 2.0.4
2024-08-22 18:08:08,362:INFO:              psutil: 5.9.0
2024-08-22 18:08:08,362:INFO:          markupsafe: 2.1.1
2024-08-22 18:08:08,362:INFO:             pickle5: Not installed
2024-08-22 18:08:08,362:INFO:         cloudpickle: 2.2.1
2024-08-22 18:08:08,362:INFO:         deprecation: 2.1.0
2024-08-22 18:08:08,362:INFO:              xxhash: 2.0.2
2024-08-22 18:08:08,362:INFO:           wurlitzer: Not installed
2024-08-22 18:08:08,362:INFO:PyCaret optional dependencies:
2024-08-22 18:08:08,363:INFO:                shap: Not installed
2024-08-22 18:08:08,363:INFO:           interpret: Not installed
2024-08-22 18:08:08,363:INFO:                umap: Not installed
2024-08-22 18:08:08,363:INFO:     ydata_profiling: 4.7.0
2024-08-22 18:08:08,363:INFO:  explainerdashboard: Not installed
2024-08-22 18:08:08,363:INFO:             autoviz: Not installed
2024-08-22 18:08:08,363:INFO:           fairlearn: Not installed
2024-08-22 18:08:08,363:INFO:          deepchecks: Not installed
2024-08-22 18:08:08,363:INFO:             xgboost: Not installed
2024-08-22 18:08:08,364:INFO:            catboost: Not installed
2024-08-22 18:08:08,364:INFO:              kmodes: Not installed
2024-08-22 18:08:08,364:INFO:             mlxtend: Not installed
2024-08-22 18:08:08,364:INFO:       statsforecast: Not installed
2024-08-22 18:08:08,364:INFO:        tune_sklearn: Not installed
2024-08-22 18:08:08,364:INFO:                 ray: Not installed
2024-08-22 18:08:08,364:INFO:            hyperopt: Not installed
2024-08-22 18:08:08,364:INFO:              optuna: Not installed
2024-08-22 18:08:08,364:INFO:               skopt: Not installed
2024-08-22 18:08:08,364:INFO:              mlflow: Not installed
2024-08-22 18:08:08,365:INFO:              gradio: Not installed
2024-08-22 18:08:08,365:INFO:             fastapi: Not installed
2024-08-22 18:08:08,365:INFO:             uvicorn: Not installed
2024-08-22 18:08:08,365:INFO:              m2cgen: Not installed
2024-08-22 18:08:08,365:INFO:           evidently: Not installed
2024-08-22 18:08:08,365:INFO:               fugue: Not installed
2024-08-22 18:08:08,365:INFO:           streamlit: Not installed
2024-08-22 18:08:08,365:INFO:             prophet: Not installed
2024-08-22 18:08:08,365:INFO:None
2024-08-22 18:08:08,365:INFO:Set up data.
2024-08-22 18:08:08,403:INFO:Set up folding strategy.
2024-08-22 18:08:08,403:INFO:Set up train/test split.
2024-08-22 18:08:08,421:INFO:Set up index.
2024-08-22 18:08:08,422:INFO:Assigning column types.
2024-08-22 18:08:08,428:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-08-22 18:08:08,470:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-22 18:08:08,470:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-22 18:08:08,518:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 18:08:08,518:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 18:08:08,588:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-22 18:08:08,589:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-22 18:08:08,622:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 18:08:08,622:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 18:08:08,623:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-08-22 18:08:08,697:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-22 18:08:08,722:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 18:08:08,722:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 18:08:08,787:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-22 18:08:08,844:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 18:08:08,844:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 18:08:08,845:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-08-22 18:08:08,984:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 18:08:08,985:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 18:08:09,054:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 18:08:09,054:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 18:08:09,056:INFO:Preparing preprocessing pipeline...
2024-08-22 18:08:09,058:INFO:Set up simple imputation.
2024-08-22 18:08:09,065:INFO:Set up encoding of ordinal features.
2024-08-22 18:08:09,072:INFO:Set up encoding of categorical features.
2024-08-22 18:08:09,276:INFO:Finished creating preprocessing pipeline.
2024-08-22 18:08:09,302:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\natha\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean')...
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['tipo_renda', 'educacao',
                                             'estado_civil',
                                             'tipo_residencia'],
                                    transformer=OneHotEncoder(cols=['tipo_renda',
                                                                    'educacao',
                                                                    'estado_civil',
                                                                    'tipo_residencia'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2024-08-22 18:08:09,302:INFO:Creating final display dataframe.
2024-08-22 18:08:09,862:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target               mau
2                   Target type            Binary
3           Original data shape       (38000, 13)
4        Transformed data shape       (38000, 30)
5   Transformed train set shape       (26600, 30)
6    Transformed test set shape       (11400, 30)
7              Numeric features                 5
8          Categorical features                 7
9      Rows with missing values             17.1%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  clf-default-name
22                          USI              d6d0
2024-08-22 18:08:09,980:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 18:08:09,981:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 18:08:10,048:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 18:08:10,048:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 18:08:10,050:INFO:setup() successfully completed in 1.7s...............
2024-08-22 18:08:40,404:INFO:PyCaret ClassificationExperiment
2024-08-22 18:08:40,404:INFO:Logging name: clf-default-name
2024-08-22 18:08:40,404:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-08-22 18:08:40,404:INFO:version 3.3.2
2024-08-22 18:08:40,404:INFO:Initializing setup()
2024-08-22 18:08:40,404:INFO:self.USI: d7f5
2024-08-22 18:08:40,404:INFO:self._variable_keys: {'_ml_usecase', 'X_test', 'data', 'X', 'html_param', 'is_multiclass', 'fold_shuffle_param', 'y_train', 'fold_groups_param', 'y', 'memory', 'gpu_n_jobs_param', 'USI', 'fold_generator', 'pipeline', 'log_plots_param', 'seed', 'gpu_param', 'exp_name_log', 'logging_param', '_available_plots', 'X_train', 'target_param', 'y_test', 'idx', 'exp_id', 'n_jobs_param', 'fix_imbalance'}
2024-08-22 18:08:40,404:INFO:Checking environment
2024-08-22 18:08:40,404:INFO:python_version: 3.11.5
2024-08-22 18:08:40,404:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-08-22 18:08:40,404:INFO:machine: AMD64
2024-08-22 18:08:40,404:INFO:platform: Windows-10-10.0.22631-SP0
2024-08-22 18:08:40,404:INFO:Memory: svmem(total=8311836672, available=1099501568, percent=86.8, used=7212335104, free=1099501568)
2024-08-22 18:08:40,404:INFO:Physical Core: 4
2024-08-22 18:08:40,404:INFO:Logical Core: 8
2024-08-22 18:08:40,404:INFO:Checking libraries
2024-08-22 18:08:40,404:INFO:System:
2024-08-22 18:08:40,404:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-08-22 18:08:40,405:INFO:executable: C:\Users\natha\anaconda3\python.exe
2024-08-22 18:08:40,405:INFO:   machine: Windows-10-10.0.22631-SP0
2024-08-22 18:08:40,405:INFO:PyCaret required dependencies:
2024-08-22 18:08:40,405:INFO:                 pip: 23.2.1
2024-08-22 18:08:40,405:INFO:          setuptools: 68.0.0
2024-08-22 18:08:40,405:INFO:             pycaret: 3.3.2
2024-08-22 18:08:40,405:INFO:             IPython: 8.15.0
2024-08-22 18:08:40,405:INFO:          ipywidgets: 8.0.4
2024-08-22 18:08:40,405:INFO:                tqdm: 4.65.0
2024-08-22 18:08:40,405:INFO:               numpy: 1.24.3
2024-08-22 18:08:40,405:INFO:              pandas: 2.0.3
2024-08-22 18:08:40,405:INFO:              jinja2: 3.1.2
2024-08-22 18:08:40,405:INFO:               scipy: 1.11.1
2024-08-22 18:08:40,405:INFO:              joblib: 1.3.2
2024-08-22 18:08:40,405:INFO:             sklearn: 1.4.2
2024-08-22 18:08:40,405:INFO:                pyod: 2.0.1
2024-08-22 18:08:40,405:INFO:            imblearn: 0.12.3
2024-08-22 18:08:40,405:INFO:   category_encoders: 2.6.3
2024-08-22 18:08:40,405:INFO:            lightgbm: 4.5.0
2024-08-22 18:08:40,405:INFO:               numba: 0.57.1
2024-08-22 18:08:40,405:INFO:            requests: 2.31.0
2024-08-22 18:08:40,405:INFO:          matplotlib: 3.7.2
2024-08-22 18:08:40,405:INFO:          scikitplot: 0.3.7
2024-08-22 18:08:40,405:INFO:         yellowbrick: 1.5
2024-08-22 18:08:40,405:INFO:              plotly: 5.23.0
2024-08-22 18:08:40,406:INFO:    plotly-resampler: Not installed
2024-08-22 18:08:40,406:INFO:             kaleido: 0.2.1
2024-08-22 18:08:40,406:INFO:           schemdraw: 0.15
2024-08-22 18:08:40,406:INFO:         statsmodels: 0.14.0
2024-08-22 18:08:40,406:INFO:              sktime: 0.26.0
2024-08-22 18:08:40,406:INFO:               tbats: 1.1.3
2024-08-22 18:08:40,406:INFO:            pmdarima: 2.0.4
2024-08-22 18:08:40,406:INFO:              psutil: 5.9.0
2024-08-22 18:08:40,406:INFO:          markupsafe: 2.1.1
2024-08-22 18:08:40,406:INFO:             pickle5: Not installed
2024-08-22 18:08:40,406:INFO:         cloudpickle: 2.2.1
2024-08-22 18:08:40,406:INFO:         deprecation: 2.1.0
2024-08-22 18:08:40,406:INFO:              xxhash: 2.0.2
2024-08-22 18:08:40,406:INFO:           wurlitzer: Not installed
2024-08-22 18:08:40,406:INFO:PyCaret optional dependencies:
2024-08-22 18:08:40,406:INFO:                shap: Not installed
2024-08-22 18:08:40,406:INFO:           interpret: Not installed
2024-08-22 18:08:40,406:INFO:                umap: Not installed
2024-08-22 18:08:40,406:INFO:     ydata_profiling: 4.7.0
2024-08-22 18:08:40,406:INFO:  explainerdashboard: Not installed
2024-08-22 18:08:40,406:INFO:             autoviz: Not installed
2024-08-22 18:08:40,406:INFO:           fairlearn: Not installed
2024-08-22 18:08:40,406:INFO:          deepchecks: Not installed
2024-08-22 18:08:40,406:INFO:             xgboost: Not installed
2024-08-22 18:08:40,406:INFO:            catboost: Not installed
2024-08-22 18:08:40,407:INFO:              kmodes: Not installed
2024-08-22 18:08:40,407:INFO:             mlxtend: Not installed
2024-08-22 18:08:40,407:INFO:       statsforecast: Not installed
2024-08-22 18:08:40,407:INFO:        tune_sklearn: Not installed
2024-08-22 18:08:40,407:INFO:                 ray: Not installed
2024-08-22 18:08:40,407:INFO:            hyperopt: Not installed
2024-08-22 18:08:40,407:INFO:              optuna: Not installed
2024-08-22 18:08:40,407:INFO:               skopt: Not installed
2024-08-22 18:08:40,407:INFO:              mlflow: Not installed
2024-08-22 18:08:40,407:INFO:              gradio: Not installed
2024-08-22 18:08:40,407:INFO:             fastapi: Not installed
2024-08-22 18:08:40,407:INFO:             uvicorn: Not installed
2024-08-22 18:08:40,407:INFO:              m2cgen: Not installed
2024-08-22 18:08:40,407:INFO:           evidently: Not installed
2024-08-22 18:08:40,407:INFO:               fugue: Not installed
2024-08-22 18:08:40,407:INFO:           streamlit: Not installed
2024-08-22 18:08:40,407:INFO:             prophet: Not installed
2024-08-22 18:08:40,407:INFO:None
2024-08-22 18:08:40,407:INFO:Set up data.
2024-08-22 18:08:40,440:INFO:Set up folding strategy.
2024-08-22 18:08:40,440:INFO:Set up train/test split.
2024-08-22 18:08:40,457:INFO:Set up index.
2024-08-22 18:08:40,458:INFO:Assigning column types.
2024-08-22 18:08:40,464:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-08-22 18:08:40,505:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-22 18:08:40,506:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-22 18:08:40,540:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 18:08:40,541:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 18:08:40,626:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-22 18:08:40,627:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-22 18:08:40,651:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 18:08:40,652:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 18:08:40,652:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-08-22 18:08:40,734:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-22 18:08:40,768:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 18:08:40,769:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 18:08:40,811:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-22 18:08:40,847:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 18:08:40,847:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 18:08:40,849:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-08-22 18:08:40,977:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 18:08:40,978:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 18:08:41,052:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 18:08:41,053:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 18:08:41,055:INFO:Preparing preprocessing pipeline...
2024-08-22 18:08:41,059:INFO:Set up simple imputation.
2024-08-22 18:08:41,075:INFO:Set up encoding of ordinal features.
2024-08-22 18:08:41,088:INFO:Set up encoding of categorical features.
2024-08-22 18:08:41,306:INFO:Finished creating preprocessing pipeline.
2024-08-22 18:08:41,331:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\natha\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean')...
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['tipo_renda', 'educacao',
                                             'estado_civil',
                                             'tipo_residencia'],
                                    transformer=OneHotEncoder(cols=['tipo_renda',
                                                                    'educacao',
                                                                    'estado_civil',
                                                                    'tipo_residencia'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2024-08-22 18:08:41,331:INFO:Creating final display dataframe.
2024-08-22 18:08:41,479:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target               mau
2                   Target type            Binary
3           Original data shape       (38000, 13)
4        Transformed data shape       (38000, 30)
5   Transformed train set shape       (26600, 30)
6    Transformed test set shape       (11400, 30)
7              Numeric features                 5
8          Categorical features                 7
9      Rows with missing values             17.1%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  clf-default-name
22                          USI              d7f5
2024-08-22 18:08:41,567:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 18:08:41,568:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 18:08:41,667:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 18:08:41,667:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 18:08:41,668:INFO:setup() successfully completed in 1.27s...............
2024-08-22 18:11:25,577:INFO:PyCaret ClassificationExperiment
2024-08-22 18:11:25,577:INFO:Logging name: credit_1
2024-08-22 18:11:25,577:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-08-22 18:11:25,577:INFO:version 3.3.2
2024-08-22 18:11:25,577:INFO:Initializing setup()
2024-08-22 18:11:25,577:INFO:self.USI: 6542
2024-08-22 18:11:25,577:INFO:self._variable_keys: {'_ml_usecase', 'X_test', 'data', 'X', 'html_param', 'is_multiclass', 'fold_shuffle_param', 'y_train', 'fold_groups_param', 'y', 'memory', 'gpu_n_jobs_param', 'USI', 'fold_generator', 'pipeline', 'log_plots_param', 'seed', 'gpu_param', 'exp_name_log', 'logging_param', '_available_plots', 'X_train', 'target_param', 'y_test', 'idx', 'exp_id', 'n_jobs_param', 'fix_imbalance'}
2024-08-22 18:11:25,578:INFO:Checking environment
2024-08-22 18:11:25,578:INFO:python_version: 3.11.5
2024-08-22 18:11:25,578:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-08-22 18:11:25,578:INFO:machine: AMD64
2024-08-22 18:11:25,578:INFO:platform: Windows-10-10.0.22631-SP0
2024-08-22 18:11:25,578:INFO:Memory: svmem(total=8311836672, available=1160007680, percent=86.0, used=7151828992, free=1160007680)
2024-08-22 18:11:25,578:INFO:Physical Core: 4
2024-08-22 18:11:25,578:INFO:Logical Core: 8
2024-08-22 18:11:25,578:INFO:Checking libraries
2024-08-22 18:11:25,578:INFO:System:
2024-08-22 18:11:25,579:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-08-22 18:11:25,579:INFO:executable: C:\Users\natha\anaconda3\python.exe
2024-08-22 18:11:25,579:INFO:   machine: Windows-10-10.0.22631-SP0
2024-08-22 18:11:25,579:INFO:PyCaret required dependencies:
2024-08-22 18:11:25,579:INFO:                 pip: 23.2.1
2024-08-22 18:11:25,579:INFO:          setuptools: 68.0.0
2024-08-22 18:11:25,579:INFO:             pycaret: 3.3.2
2024-08-22 18:11:25,579:INFO:             IPython: 8.15.0
2024-08-22 18:11:25,579:INFO:          ipywidgets: 8.0.4
2024-08-22 18:11:25,579:INFO:                tqdm: 4.65.0
2024-08-22 18:11:25,579:INFO:               numpy: 1.24.3
2024-08-22 18:11:25,579:INFO:              pandas: 2.0.3
2024-08-22 18:11:25,580:INFO:              jinja2: 3.1.2
2024-08-22 18:11:25,580:INFO:               scipy: 1.11.1
2024-08-22 18:11:25,580:INFO:              joblib: 1.3.2
2024-08-22 18:11:25,580:INFO:             sklearn: 1.4.2
2024-08-22 18:11:25,580:INFO:                pyod: 2.0.1
2024-08-22 18:11:25,580:INFO:            imblearn: 0.12.3
2024-08-22 18:11:25,580:INFO:   category_encoders: 2.6.3
2024-08-22 18:11:25,580:INFO:            lightgbm: 4.5.0
2024-08-22 18:11:25,580:INFO:               numba: 0.57.1
2024-08-22 18:11:25,580:INFO:            requests: 2.31.0
2024-08-22 18:11:25,580:INFO:          matplotlib: 3.7.2
2024-08-22 18:11:25,580:INFO:          scikitplot: 0.3.7
2024-08-22 18:11:25,581:INFO:         yellowbrick: 1.5
2024-08-22 18:11:25,581:INFO:              plotly: 5.23.0
2024-08-22 18:11:25,581:INFO:    plotly-resampler: Not installed
2024-08-22 18:11:25,581:INFO:             kaleido: 0.2.1
2024-08-22 18:11:25,581:INFO:           schemdraw: 0.15
2024-08-22 18:11:25,581:INFO:         statsmodels: 0.14.0
2024-08-22 18:11:25,581:INFO:              sktime: 0.26.0
2024-08-22 18:11:25,581:INFO:               tbats: 1.1.3
2024-08-22 18:11:25,581:INFO:            pmdarima: 2.0.4
2024-08-22 18:11:25,581:INFO:              psutil: 5.9.0
2024-08-22 18:11:25,581:INFO:          markupsafe: 2.1.1
2024-08-22 18:11:25,581:INFO:             pickle5: Not installed
2024-08-22 18:11:25,581:INFO:         cloudpickle: 2.2.1
2024-08-22 18:11:25,582:INFO:         deprecation: 2.1.0
2024-08-22 18:11:25,582:INFO:              xxhash: 2.0.2
2024-08-22 18:11:25,582:INFO:           wurlitzer: Not installed
2024-08-22 18:11:25,582:INFO:PyCaret optional dependencies:
2024-08-22 18:11:25,582:INFO:                shap: Not installed
2024-08-22 18:11:25,582:INFO:           interpret: Not installed
2024-08-22 18:11:25,582:INFO:                umap: Not installed
2024-08-22 18:11:25,582:INFO:     ydata_profiling: 4.7.0
2024-08-22 18:11:25,582:INFO:  explainerdashboard: Not installed
2024-08-22 18:11:25,582:INFO:             autoviz: Not installed
2024-08-22 18:11:25,582:INFO:           fairlearn: Not installed
2024-08-22 18:11:25,583:INFO:          deepchecks: Not installed
2024-08-22 18:11:25,583:INFO:             xgboost: Not installed
2024-08-22 18:11:25,583:INFO:            catboost: Not installed
2024-08-22 18:11:25,583:INFO:              kmodes: Not installed
2024-08-22 18:11:25,583:INFO:             mlxtend: Not installed
2024-08-22 18:11:25,583:INFO:       statsforecast: Not installed
2024-08-22 18:11:25,583:INFO:        tune_sklearn: Not installed
2024-08-22 18:11:25,584:INFO:                 ray: Not installed
2024-08-22 18:11:25,584:INFO:            hyperopt: Not installed
2024-08-22 18:11:25,584:INFO:              optuna: Not installed
2024-08-22 18:11:25,584:INFO:               skopt: Not installed
2024-08-22 18:11:25,584:INFO:              mlflow: Not installed
2024-08-22 18:11:25,584:INFO:              gradio: Not installed
2024-08-22 18:11:25,584:INFO:             fastapi: Not installed
2024-08-22 18:11:25,585:INFO:             uvicorn: Not installed
2024-08-22 18:11:25,585:INFO:              m2cgen: Not installed
2024-08-22 18:11:25,585:INFO:           evidently: Not installed
2024-08-22 18:11:25,585:INFO:               fugue: Not installed
2024-08-22 18:11:25,585:INFO:           streamlit: Not installed
2024-08-22 18:11:25,585:INFO:             prophet: Not installed
2024-08-22 18:11:25,586:INFO:None
2024-08-22 18:11:25,586:INFO:Set up data.
2024-08-22 18:11:25,636:INFO:Set up folding strategy.
2024-08-22 18:11:25,636:INFO:Set up train/test split.
2024-08-22 18:11:25,660:INFO:Set up index.
2024-08-22 18:11:25,661:INFO:Assigning column types.
2024-08-22 18:11:25,667:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-08-22 18:11:25,734:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-22 18:11:25,736:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-22 18:11:25,767:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 18:11:25,768:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 18:11:25,811:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-22 18:11:25,812:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-22 18:11:25,842:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 18:11:25,842:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 18:11:25,843:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-08-22 18:11:25,902:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-22 18:11:25,929:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 18:11:25,929:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 18:11:25,972:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-22 18:11:25,998:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 18:11:25,999:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 18:11:25,999:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-08-22 18:11:26,067:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 18:11:26,067:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 18:11:26,136:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 18:11:26,136:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 18:11:26,137:INFO:Preparing preprocessing pipeline...
2024-08-22 18:11:26,142:INFO:Set up simple imputation.
2024-08-22 18:11:26,150:INFO:Set up encoding of ordinal features.
2024-08-22 18:11:26,156:INFO:Set up encoding of categorical features.
2024-08-22 18:11:26,156:INFO:Set up imbalanced handling.
2024-08-22 18:11:26,156:INFO:Set up column transformation.
2024-08-22 18:11:26,156:INFO:Set up feature normalization.
2024-08-22 18:11:27,416:INFO:Finished creating preprocessing pipeline.
2024-08-22 18:11:27,473:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\natha\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean')...
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=QuantileTransformer(copy=True,
                                                                    ignore_implicit_zeros=False,
                                                                    n_quantiles=1000,
                                                                    output_distribution='normal',
                                                                    random_state=2822,
                                                                    subsample=10000))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2024-08-22 18:11:27,474:INFO:Creating final display dataframe.
2024-08-22 18:11:28,643:INFO:Setup _display_container:                     Description            Value
0                    Session id             2822
1                        Target              mau
2                   Target type           Binary
3           Original data shape      (38000, 13)
4        Transformed data shape      (60290, 30)
5   Transformed train set shape      (48890, 30)
6    Transformed test set shape      (11400, 30)
7              Numeric features                5
8          Categorical features                7
9      Rows with missing values            17.1%
10                   Preprocess             True
11              Imputation type           simple
12           Numeric imputation             mean
13       Categorical imputation             mode
14     Maximum one-hot encoding               25
15              Encoding method             None
16                Fix imbalance             True
17         Fix imbalance method            SMOTE
18               Transformation             True
19        Transformation method         quantile
20                    Normalize             True
21             Normalize method           zscore
22               Fold Generator  StratifiedKFold
23                  Fold Number               10
24                     CPU Jobs               -1
25                      Use GPU            False
26               Log Experiment            False
27              Experiment Name         credit_1
28                          USI             6542
2024-08-22 18:11:28,744:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 18:11:28,744:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 18:11:28,836:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 18:11:28,837:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 18:11:28,838:INFO:setup() successfully completed in 3.27s...............
2024-08-22 18:11:43,551:INFO:Initializing compare_models()
2024-08-22 18:11:43,551:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AEA5613D90>, include=None, exclude=None, fold=4, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001AEA5613D90>, 'include': None, 'exclude': None, 'fold': 4, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-08-22 18:11:43,551:INFO:Checking exceptions
2024-08-22 18:11:43,566:INFO:Preparing display monitor
2024-08-22 18:11:43,598:INFO:Initializing Logistic Regression
2024-08-22 18:11:43,598:INFO:Total runtime is 0.0 minutes
2024-08-22 18:11:43,603:INFO:SubProcess create_model() called ==================================
2024-08-22 18:11:43,604:INFO:Initializing create_model()
2024-08-22 18:11:43,604:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AEA5613D90>, estimator=lr, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AEA563EFD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-22 18:11:43,604:INFO:Checking exceptions
2024-08-22 18:11:43,604:INFO:Importing libraries
2024-08-22 18:11:43,604:INFO:Copying training dataset
2024-08-22 18:11:43,617:INFO:Defining folds
2024-08-22 18:11:43,617:INFO:Declaring metric variables
2024-08-22 18:11:43,621:INFO:Importing untrained model
2024-08-22 18:11:43,625:INFO:Logistic Regression Imported successfully
2024-08-22 18:11:43,633:INFO:Starting cross validation
2024-08-22 18:11:43,637:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-08-22 18:11:51,595:INFO:Calculating mean and std
2024-08-22 18:11:51,597:INFO:Creating metrics dataframe
2024-08-22 18:11:51,601:INFO:Uploading results into container
2024-08-22 18:11:51,602:INFO:Uploading model into container now
2024-08-22 18:11:51,603:INFO:_master_model_container: 1
2024-08-22 18:11:51,603:INFO:_display_container: 2
2024-08-22 18:11:51,604:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2822, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-08-22 18:11:51,604:INFO:create_model() successfully completed......................................
2024-08-22 18:11:51,905:INFO:SubProcess create_model() end ==================================
2024-08-22 18:11:51,905:INFO:Creating metrics dataframe
2024-08-22 18:11:51,921:INFO:Initializing K Neighbors Classifier
2024-08-22 18:11:51,922:INFO:Total runtime is 0.138735028107961 minutes
2024-08-22 18:11:51,926:INFO:SubProcess create_model() called ==================================
2024-08-22 18:11:51,926:INFO:Initializing create_model()
2024-08-22 18:11:51,927:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AEA5613D90>, estimator=knn, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AEA563EFD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-22 18:11:51,927:INFO:Checking exceptions
2024-08-22 18:11:51,927:INFO:Importing libraries
2024-08-22 18:11:51,927:INFO:Copying training dataset
2024-08-22 18:11:51,949:INFO:Defining folds
2024-08-22 18:11:51,949:INFO:Declaring metric variables
2024-08-22 18:11:51,953:INFO:Importing untrained model
2024-08-22 18:11:51,959:INFO:K Neighbors Classifier Imported successfully
2024-08-22 18:11:51,966:INFO:Starting cross validation
2024-08-22 18:11:51,972:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-08-22 18:12:02,972:INFO:Calculating mean and std
2024-08-22 18:12:02,973:INFO:Creating metrics dataframe
2024-08-22 18:12:02,976:INFO:Uploading results into container
2024-08-22 18:12:02,976:INFO:Uploading model into container now
2024-08-22 18:12:02,977:INFO:_master_model_container: 2
2024-08-22 18:12:02,977:INFO:_display_container: 2
2024-08-22 18:12:02,978:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-08-22 18:12:02,978:INFO:create_model() successfully completed......................................
2024-08-22 18:12:03,290:INFO:SubProcess create_model() end ==================================
2024-08-22 18:12:03,292:INFO:Creating metrics dataframe
2024-08-22 18:12:03,304:INFO:Initializing Naive Bayes
2024-08-22 18:12:03,305:INFO:Total runtime is 0.3284560283025106 minutes
2024-08-22 18:12:03,310:INFO:SubProcess create_model() called ==================================
2024-08-22 18:12:03,310:INFO:Initializing create_model()
2024-08-22 18:12:03,310:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AEA5613D90>, estimator=nb, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AEA563EFD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-22 18:12:03,310:INFO:Checking exceptions
2024-08-22 18:12:03,310:INFO:Importing libraries
2024-08-22 18:12:03,310:INFO:Copying training dataset
2024-08-22 18:12:03,330:INFO:Defining folds
2024-08-22 18:12:03,330:INFO:Declaring metric variables
2024-08-22 18:12:03,333:INFO:Importing untrained model
2024-08-22 18:12:03,337:INFO:Naive Bayes Imported successfully
2024-08-22 18:12:03,345:INFO:Starting cross validation
2024-08-22 18:12:03,348:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-08-22 18:12:04,314:INFO:Calculating mean and std
2024-08-22 18:12:04,315:INFO:Creating metrics dataframe
2024-08-22 18:12:04,318:INFO:Uploading results into container
2024-08-22 18:12:04,319:INFO:Uploading model into container now
2024-08-22 18:12:04,320:INFO:_master_model_container: 3
2024-08-22 18:12:04,321:INFO:_display_container: 2
2024-08-22 18:12:04,321:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-08-22 18:12:04,321:INFO:create_model() successfully completed......................................
2024-08-22 18:12:04,616:INFO:SubProcess create_model() end ==================================
2024-08-22 18:12:04,616:INFO:Creating metrics dataframe
2024-08-22 18:12:04,635:INFO:Initializing Decision Tree Classifier
2024-08-22 18:12:04,635:INFO:Total runtime is 0.35061063766479494 minutes
2024-08-22 18:12:04,640:INFO:SubProcess create_model() called ==================================
2024-08-22 18:12:04,641:INFO:Initializing create_model()
2024-08-22 18:12:04,641:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AEA5613D90>, estimator=dt, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AEA563EFD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-22 18:12:04,641:INFO:Checking exceptions
2024-08-22 18:12:04,641:INFO:Importing libraries
2024-08-22 18:12:04,641:INFO:Copying training dataset
2024-08-22 18:12:04,667:INFO:Defining folds
2024-08-22 18:12:04,668:INFO:Declaring metric variables
2024-08-22 18:12:04,672:INFO:Importing untrained model
2024-08-22 18:12:04,676:INFO:Decision Tree Classifier Imported successfully
2024-08-22 18:12:04,684:INFO:Starting cross validation
2024-08-22 18:12:04,690:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-08-22 18:12:06,028:INFO:Calculating mean and std
2024-08-22 18:12:06,029:INFO:Creating metrics dataframe
2024-08-22 18:12:06,032:INFO:Uploading results into container
2024-08-22 18:12:06,033:INFO:Uploading model into container now
2024-08-22 18:12:06,034:INFO:_master_model_container: 4
2024-08-22 18:12:06,034:INFO:_display_container: 2
2024-08-22 18:12:06,035:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2822, splitter='best')
2024-08-22 18:12:06,035:INFO:create_model() successfully completed......................................
2024-08-22 18:12:06,286:INFO:SubProcess create_model() end ==================================
2024-08-22 18:12:06,287:INFO:Creating metrics dataframe
2024-08-22 18:12:06,301:INFO:Initializing SVM - Linear Kernel
2024-08-22 18:12:06,301:INFO:Total runtime is 0.3783773978551229 minutes
2024-08-22 18:12:06,305:INFO:SubProcess create_model() called ==================================
2024-08-22 18:12:06,306:INFO:Initializing create_model()
2024-08-22 18:12:06,306:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AEA5613D90>, estimator=svm, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AEA563EFD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-22 18:12:06,306:INFO:Checking exceptions
2024-08-22 18:12:06,306:INFO:Importing libraries
2024-08-22 18:12:06,306:INFO:Copying training dataset
2024-08-22 18:12:06,322:INFO:Defining folds
2024-08-22 18:12:06,322:INFO:Declaring metric variables
2024-08-22 18:12:06,325:INFO:Importing untrained model
2024-08-22 18:12:06,329:INFO:SVM - Linear Kernel Imported successfully
2024-08-22 18:12:06,335:INFO:Starting cross validation
2024-08-22 18:12:06,338:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-08-22 18:12:07,574:INFO:Calculating mean and std
2024-08-22 18:12:07,576:INFO:Creating metrics dataframe
2024-08-22 18:12:07,579:INFO:Uploading results into container
2024-08-22 18:12:07,580:INFO:Uploading model into container now
2024-08-22 18:12:07,581:INFO:_master_model_container: 5
2024-08-22 18:12:07,581:INFO:_display_container: 2
2024-08-22 18:12:07,583:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=2822, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-08-22 18:12:07,583:INFO:create_model() successfully completed......................................
2024-08-22 18:12:07,859:INFO:SubProcess create_model() end ==================================
2024-08-22 18:12:07,859:INFO:Creating metrics dataframe
2024-08-22 18:12:07,868:INFO:Initializing Ridge Classifier
2024-08-22 18:12:07,868:INFO:Total runtime is 0.4045042276382447 minutes
2024-08-22 18:12:07,873:INFO:SubProcess create_model() called ==================================
2024-08-22 18:12:07,874:INFO:Initializing create_model()
2024-08-22 18:12:07,874:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AEA5613D90>, estimator=ridge, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AEA563EFD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-22 18:12:07,874:INFO:Checking exceptions
2024-08-22 18:12:07,874:INFO:Importing libraries
2024-08-22 18:12:07,874:INFO:Copying training dataset
2024-08-22 18:12:07,893:INFO:Defining folds
2024-08-22 18:12:07,894:INFO:Declaring metric variables
2024-08-22 18:12:07,897:INFO:Importing untrained model
2024-08-22 18:12:07,901:INFO:Ridge Classifier Imported successfully
2024-08-22 18:12:07,908:INFO:Starting cross validation
2024-08-22 18:12:07,910:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-08-22 18:12:08,901:INFO:Calculating mean and std
2024-08-22 18:12:08,903:INFO:Creating metrics dataframe
2024-08-22 18:12:08,906:INFO:Uploading results into container
2024-08-22 18:12:08,907:INFO:Uploading model into container now
2024-08-22 18:12:08,907:INFO:_master_model_container: 6
2024-08-22 18:12:08,908:INFO:_display_container: 2
2024-08-22 18:12:08,908:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=2822, solver='auto',
                tol=0.0001)
2024-08-22 18:12:08,908:INFO:create_model() successfully completed......................................
2024-08-22 18:12:09,195:INFO:SubProcess create_model() end ==================================
2024-08-22 18:12:09,195:INFO:Creating metrics dataframe
2024-08-22 18:12:09,215:INFO:Initializing Random Forest Classifier
2024-08-22 18:12:09,215:INFO:Total runtime is 0.42695693969726567 minutes
2024-08-22 18:12:09,221:INFO:SubProcess create_model() called ==================================
2024-08-22 18:12:09,222:INFO:Initializing create_model()
2024-08-22 18:12:09,222:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AEA5613D90>, estimator=rf, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AEA563EFD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-22 18:12:09,222:INFO:Checking exceptions
2024-08-22 18:12:09,222:INFO:Importing libraries
2024-08-22 18:12:09,222:INFO:Copying training dataset
2024-08-22 18:12:09,242:INFO:Defining folds
2024-08-22 18:12:09,242:INFO:Declaring metric variables
2024-08-22 18:12:09,247:INFO:Importing untrained model
2024-08-22 18:12:09,253:INFO:Random Forest Classifier Imported successfully
2024-08-22 18:12:09,261:INFO:Starting cross validation
2024-08-22 18:12:09,264:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-08-22 18:12:13,928:INFO:Calculating mean and std
2024-08-22 18:12:13,929:INFO:Creating metrics dataframe
2024-08-22 18:12:13,932:INFO:Uploading results into container
2024-08-22 18:12:13,932:INFO:Uploading model into container now
2024-08-22 18:12:13,933:INFO:_master_model_container: 7
2024-08-22 18:12:13,933:INFO:_display_container: 2
2024-08-22 18:12:13,933:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=2822, verbose=0,
                       warm_start=False)
2024-08-22 18:12:13,934:INFO:create_model() successfully completed......................................
2024-08-22 18:12:14,205:INFO:SubProcess create_model() end ==================================
2024-08-22 18:12:14,206:INFO:Creating metrics dataframe
2024-08-22 18:12:14,220:INFO:Initializing Quadratic Discriminant Analysis
2024-08-22 18:12:14,220:INFO:Total runtime is 0.51036536693573 minutes
2024-08-22 18:12:14,224:INFO:SubProcess create_model() called ==================================
2024-08-22 18:12:14,224:INFO:Initializing create_model()
2024-08-22 18:12:14,224:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AEA5613D90>, estimator=qda, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AEA563EFD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-22 18:12:14,224:INFO:Checking exceptions
2024-08-22 18:12:14,224:INFO:Importing libraries
2024-08-22 18:12:14,224:INFO:Copying training dataset
2024-08-22 18:12:14,239:INFO:Defining folds
2024-08-22 18:12:14,240:INFO:Declaring metric variables
2024-08-22 18:12:14,244:INFO:Importing untrained model
2024-08-22 18:12:14,248:INFO:Quadratic Discriminant Analysis Imported successfully
2024-08-22 18:12:14,258:INFO:Starting cross validation
2024-08-22 18:12:14,261:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-08-22 18:12:15,017:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-08-22 18:12:15,018:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-08-22 18:12:15,058:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-08-22 18:12:15,084:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-08-22 18:12:15,294:INFO:Calculating mean and std
2024-08-22 18:12:15,296:INFO:Creating metrics dataframe
2024-08-22 18:12:15,297:INFO:Uploading results into container
2024-08-22 18:12:15,298:INFO:Uploading model into container now
2024-08-22 18:12:15,298:INFO:_master_model_container: 8
2024-08-22 18:12:15,298:INFO:_display_container: 2
2024-08-22 18:12:15,299:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-08-22 18:12:15,299:INFO:create_model() successfully completed......................................
2024-08-22 18:12:15,595:INFO:SubProcess create_model() end ==================================
2024-08-22 18:12:15,596:INFO:Creating metrics dataframe
2024-08-22 18:12:15,620:INFO:Initializing Ada Boost Classifier
2024-08-22 18:12:15,620:INFO:Total runtime is 0.5336914141972859 minutes
2024-08-22 18:12:15,623:INFO:SubProcess create_model() called ==================================
2024-08-22 18:12:15,624:INFO:Initializing create_model()
2024-08-22 18:12:15,624:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AEA5613D90>, estimator=ada, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AEA563EFD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-22 18:12:15,624:INFO:Checking exceptions
2024-08-22 18:12:15,624:INFO:Importing libraries
2024-08-22 18:12:15,624:INFO:Copying training dataset
2024-08-22 18:12:15,645:INFO:Defining folds
2024-08-22 18:12:15,645:INFO:Declaring metric variables
2024-08-22 18:12:15,649:INFO:Importing untrained model
2024-08-22 18:12:15,654:INFO:Ada Boost Classifier Imported successfully
2024-08-22 18:12:15,662:INFO:Starting cross validation
2024-08-22 18:12:15,665:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-08-22 18:12:16,461:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-08-22 18:12:16,461:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-08-22 18:12:16,467:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-08-22 18:12:16,486:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-08-22 18:12:19,845:INFO:Calculating mean and std
2024-08-22 18:12:19,846:INFO:Creating metrics dataframe
2024-08-22 18:12:19,848:INFO:Uploading results into container
2024-08-22 18:12:19,848:INFO:Uploading model into container now
2024-08-22 18:12:19,848:INFO:_master_model_container: 9
2024-08-22 18:12:19,849:INFO:_display_container: 2
2024-08-22 18:12:19,849:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2822)
2024-08-22 18:12:19,849:INFO:create_model() successfully completed......................................
2024-08-22 18:12:20,111:INFO:SubProcess create_model() end ==================================
2024-08-22 18:12:20,111:INFO:Creating metrics dataframe
2024-08-22 18:12:20,128:INFO:Initializing Gradient Boosting Classifier
2024-08-22 18:12:20,128:INFO:Total runtime is 0.6088314135869344 minutes
2024-08-22 18:12:20,132:INFO:SubProcess create_model() called ==================================
2024-08-22 18:12:20,132:INFO:Initializing create_model()
2024-08-22 18:12:20,133:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AEA5613D90>, estimator=gbc, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AEA563EFD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-22 18:12:20,133:INFO:Checking exceptions
2024-08-22 18:12:20,133:INFO:Importing libraries
2024-08-22 18:12:20,133:INFO:Copying training dataset
2024-08-22 18:12:20,152:INFO:Defining folds
2024-08-22 18:12:20,152:INFO:Declaring metric variables
2024-08-22 18:12:20,156:INFO:Importing untrained model
2024-08-22 18:12:20,164:INFO:Gradient Boosting Classifier Imported successfully
2024-08-22 18:12:20,172:INFO:Starting cross validation
2024-08-22 18:12:20,175:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-08-22 18:12:33,951:INFO:Calculating mean and std
2024-08-22 18:12:33,952:INFO:Creating metrics dataframe
2024-08-22 18:12:33,954:INFO:Uploading results into container
2024-08-22 18:12:33,954:INFO:Uploading model into container now
2024-08-22 18:12:33,954:INFO:_master_model_container: 10
2024-08-22 18:12:33,954:INFO:_display_container: 2
2024-08-22 18:12:33,955:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2822, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-08-22 18:12:33,955:INFO:create_model() successfully completed......................................
2024-08-22 18:12:34,238:INFO:SubProcess create_model() end ==================================
2024-08-22 18:12:34,238:INFO:Creating metrics dataframe
2024-08-22 18:12:34,260:INFO:Initializing Linear Discriminant Analysis
2024-08-22 18:12:34,260:INFO:Total runtime is 0.8443588733673095 minutes
2024-08-22 18:12:34,265:INFO:SubProcess create_model() called ==================================
2024-08-22 18:12:34,266:INFO:Initializing create_model()
2024-08-22 18:12:34,266:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AEA5613D90>, estimator=lda, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AEA563EFD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-22 18:12:34,266:INFO:Checking exceptions
2024-08-22 18:12:34,266:INFO:Importing libraries
2024-08-22 18:12:34,266:INFO:Copying training dataset
2024-08-22 18:12:34,287:INFO:Defining folds
2024-08-22 18:12:34,288:INFO:Declaring metric variables
2024-08-22 18:12:34,292:INFO:Importing untrained model
2024-08-22 18:12:34,310:INFO:Linear Discriminant Analysis Imported successfully
2024-08-22 18:12:34,319:INFO:Starting cross validation
2024-08-22 18:12:34,321:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-08-22 18:12:35,533:INFO:Calculating mean and std
2024-08-22 18:12:35,534:INFO:Creating metrics dataframe
2024-08-22 18:12:35,536:INFO:Uploading results into container
2024-08-22 18:12:35,536:INFO:Uploading model into container now
2024-08-22 18:12:35,536:INFO:_master_model_container: 11
2024-08-22 18:12:35,536:INFO:_display_container: 2
2024-08-22 18:12:35,537:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-08-22 18:12:35,537:INFO:create_model() successfully completed......................................
2024-08-22 18:12:35,780:INFO:SubProcess create_model() end ==================================
2024-08-22 18:12:35,780:INFO:Creating metrics dataframe
2024-08-22 18:12:35,791:INFO:Initializing Extra Trees Classifier
2024-08-22 18:12:35,792:INFO:Total runtime is 0.8698979377746582 minutes
2024-08-22 18:12:35,797:INFO:SubProcess create_model() called ==================================
2024-08-22 18:12:35,798:INFO:Initializing create_model()
2024-08-22 18:12:35,798:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AEA5613D90>, estimator=et, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AEA563EFD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-22 18:12:35,798:INFO:Checking exceptions
2024-08-22 18:12:35,798:INFO:Importing libraries
2024-08-22 18:12:35,798:INFO:Copying training dataset
2024-08-22 18:12:35,816:INFO:Defining folds
2024-08-22 18:12:35,817:INFO:Declaring metric variables
2024-08-22 18:12:35,820:INFO:Importing untrained model
2024-08-22 18:12:35,824:INFO:Extra Trees Classifier Imported successfully
2024-08-22 18:12:35,833:INFO:Starting cross validation
2024-08-22 18:12:35,837:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-08-22 18:12:39,094:INFO:Calculating mean and std
2024-08-22 18:12:39,095:INFO:Creating metrics dataframe
2024-08-22 18:12:39,097:INFO:Uploading results into container
2024-08-22 18:12:39,098:INFO:Uploading model into container now
2024-08-22 18:12:39,099:INFO:_master_model_container: 12
2024-08-22 18:12:39,099:INFO:_display_container: 2
2024-08-22 18:12:39,100:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=2822, verbose=0,
                     warm_start=False)
2024-08-22 18:12:39,100:INFO:create_model() successfully completed......................................
2024-08-22 18:12:39,367:INFO:SubProcess create_model() end ==================================
2024-08-22 18:12:39,367:INFO:Creating metrics dataframe
2024-08-22 18:12:39,393:INFO:Initializing Light Gradient Boosting Machine
2024-08-22 18:12:39,394:INFO:Total runtime is 0.9299302538235982 minutes
2024-08-22 18:12:39,403:INFO:SubProcess create_model() called ==================================
2024-08-22 18:12:39,404:INFO:Initializing create_model()
2024-08-22 18:12:39,404:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AEA5613D90>, estimator=lightgbm, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AEA563EFD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-22 18:12:39,404:INFO:Checking exceptions
2024-08-22 18:12:39,405:INFO:Importing libraries
2024-08-22 18:12:39,405:INFO:Copying training dataset
2024-08-22 18:12:39,425:INFO:Defining folds
2024-08-22 18:12:39,425:INFO:Declaring metric variables
2024-08-22 18:12:39,430:INFO:Importing untrained model
2024-08-22 18:12:39,434:INFO:Light Gradient Boosting Machine Imported successfully
2024-08-22 18:12:39,441:INFO:Starting cross validation
2024-08-22 18:12:39,444:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-08-22 18:12:41,461:INFO:Calculating mean and std
2024-08-22 18:12:41,462:INFO:Creating metrics dataframe
2024-08-22 18:12:41,465:INFO:Uploading results into container
2024-08-22 18:12:41,466:INFO:Uploading model into container now
2024-08-22 18:12:41,466:INFO:_master_model_container: 13
2024-08-22 18:12:41,466:INFO:_display_container: 2
2024-08-22 18:12:41,467:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2822, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-08-22 18:12:41,467:INFO:create_model() successfully completed......................................
2024-08-22 18:12:41,750:INFO:SubProcess create_model() end ==================================
2024-08-22 18:12:41,751:INFO:Creating metrics dataframe
2024-08-22 18:12:41,776:INFO:Initializing Dummy Classifier
2024-08-22 18:12:41,776:INFO:Total runtime is 0.9696294347445169 minutes
2024-08-22 18:12:41,779:INFO:SubProcess create_model() called ==================================
2024-08-22 18:12:41,780:INFO:Initializing create_model()
2024-08-22 18:12:41,780:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AEA5613D90>, estimator=dummy, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AEA563EFD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-22 18:12:41,780:INFO:Checking exceptions
2024-08-22 18:12:41,780:INFO:Importing libraries
2024-08-22 18:12:41,780:INFO:Copying training dataset
2024-08-22 18:12:41,800:INFO:Defining folds
2024-08-22 18:12:41,801:INFO:Declaring metric variables
2024-08-22 18:12:41,804:INFO:Importing untrained model
2024-08-22 18:12:41,809:INFO:Dummy Classifier Imported successfully
2024-08-22 18:12:41,815:INFO:Starting cross validation
2024-08-22 18:12:41,818:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-08-22 18:12:42,645:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-22 18:12:42,682:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-22 18:12:42,693:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-22 18:12:42,727:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-22 18:12:42,740:INFO:Calculating mean and std
2024-08-22 18:12:42,742:INFO:Creating metrics dataframe
2024-08-22 18:12:42,745:INFO:Uploading results into container
2024-08-22 18:12:42,746:INFO:Uploading model into container now
2024-08-22 18:12:42,747:INFO:_master_model_container: 14
2024-08-22 18:12:42,747:INFO:_display_container: 2
2024-08-22 18:12:42,747:INFO:DummyClassifier(constant=None, random_state=2822, strategy='prior')
2024-08-22 18:12:42,747:INFO:create_model() successfully completed......................................
2024-08-22 18:12:43,022:INFO:SubProcess create_model() end ==================================
2024-08-22 18:12:43,022:INFO:Creating metrics dataframe
2024-08-22 18:12:43,044:INFO:Initializing create_model()
2024-08-22 18:12:43,045:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AEA5613D90>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2822, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-22 18:12:43,045:INFO:Checking exceptions
2024-08-22 18:12:43,047:INFO:Importing libraries
2024-08-22 18:12:43,047:INFO:Copying training dataset
2024-08-22 18:12:43,063:INFO:Defining folds
2024-08-22 18:12:43,063:INFO:Declaring metric variables
2024-08-22 18:12:43,063:INFO:Importing untrained model
2024-08-22 18:12:43,063:INFO:Declaring custom model
2024-08-22 18:12:43,064:INFO:Gradient Boosting Classifier Imported successfully
2024-08-22 18:12:43,067:INFO:Cross validation set to False
2024-08-22 18:12:43,067:INFO:Fitting Model
2024-08-22 18:12:59,045:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2822, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-08-22 18:12:59,045:INFO:create_model() successfully completed......................................
2024-08-22 18:12:59,350:INFO:_master_model_container: 14
2024-08-22 18:12:59,351:INFO:_display_container: 2
2024-08-22 18:12:59,351:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2822, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-08-22 18:12:59,351:INFO:compare_models() successfully completed......................................
2024-08-22 18:13:50,154:INFO:Initializing plot_model()
2024-08-22 18:13:50,154:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AEA5613D90>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2822, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-08-22 18:13:50,155:INFO:Checking exceptions
2024-08-22 18:13:50,163:INFO:Preloading libraries
2024-08-22 18:13:50,179:INFO:Copying training dataset
2024-08-22 18:13:50,179:INFO:Plot type: feature
2024-08-22 18:13:50,181:WARNING:No coef_ found. Trying feature_importances_
2024-08-22 18:13:50,577:INFO:Visual Rendered Successfully
2024-08-22 18:13:50,844:INFO:plot_model() successfully completed......................................
2024-08-22 18:14:02,917:INFO:Initializing plot_model()
2024-08-22 18:14:02,917:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AEA5613D90>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2822, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-08-22 18:14:02,917:INFO:Checking exceptions
2024-08-22 18:14:02,927:INFO:Preloading libraries
2024-08-22 18:14:02,939:INFO:Copying training dataset
2024-08-22 18:14:02,940:INFO:Plot type: auc
2024-08-22 18:14:03,085:INFO:Fitting Model
2024-08-22 18:14:03,087:INFO:Scoring test/hold-out set
2024-08-22 18:14:03,398:INFO:Visual Rendered Successfully
2024-08-22 18:14:03,667:INFO:plot_model() successfully completed......................................
2024-08-22 18:14:15,089:INFO:Initializing save_model()
2024-08-22 18:14:15,090:INFO:save_model(model=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2822, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), model_name=LR Model Aula 5 062022, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\natha\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean')...
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=QuantileTransformer(copy=True,
                                                                    ignore_implicit_zeros=False,
                                                                    n_quantiles=1000,
                                                                    output_distribution='normal',
                                                                    random_state=2822,
                                                                    subsample=10000))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-08-22 18:14:15,090:INFO:Adding model into prep_pipe
2024-08-22 18:14:15,108:INFO:LR Model Aula 5 062022.pkl saved in current working directory
2024-08-22 18:14:15,157:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWra...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.1, loss='log_loss',
                                            max_depth=3, max_features=None,
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.0,
                                            min_samples_leaf=1,
                                            min_samples_split=2,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=100,
                                            n_iter_no_change=None,
                                            random_state=2822, subsample=1.0,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2024-08-22 18:14:15,157:INFO:save_model() successfully completed......................................
2024-08-22 18:14:27,666:INFO:Initializing load_model()
2024-08-22 18:14:27,667:INFO:load_model(model_name=LR Model Aula 5 062022, platform=None, authentication=None, verbose=True)
2024-08-22 18:14:55,844:INFO:PyCaret ClassificationExperiment
2024-08-22 18:14:55,844:INFO:Logging name: clf-default-name
2024-08-22 18:14:55,844:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-08-22 18:14:55,845:INFO:version 3.3.2
2024-08-22 18:14:55,845:INFO:Initializing setup()
2024-08-22 18:14:55,845:INFO:self.USI: 9802
2024-08-22 18:14:55,845:INFO:self._variable_keys: {'_ml_usecase', 'X_test', 'data', 'X', 'html_param', 'is_multiclass', 'fold_shuffle_param', 'y_train', 'fold_groups_param', 'y', 'memory', 'gpu_n_jobs_param', 'USI', 'fold_generator', 'pipeline', 'log_plots_param', 'seed', 'gpu_param', 'exp_name_log', 'logging_param', '_available_plots', 'X_train', 'target_param', 'y_test', 'idx', 'exp_id', 'n_jobs_param', 'fix_imbalance'}
2024-08-22 18:14:55,845:INFO:Checking environment
2024-08-22 18:14:55,845:INFO:python_version: 3.11.5
2024-08-22 18:14:55,845:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-08-22 18:14:55,845:INFO:machine: AMD64
2024-08-22 18:14:55,845:INFO:platform: Windows-10-10.0.22631-SP0
2024-08-22 18:14:55,846:INFO:Memory: svmem(total=8311836672, available=1222561792, percent=85.3, used=7089274880, free=1222561792)
2024-08-22 18:14:55,846:INFO:Physical Core: 4
2024-08-22 18:14:55,846:INFO:Logical Core: 8
2024-08-22 18:14:55,846:INFO:Checking libraries
2024-08-22 18:14:55,846:INFO:System:
2024-08-22 18:14:55,846:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-08-22 18:14:55,846:INFO:executable: C:\Users\natha\anaconda3\python.exe
2024-08-22 18:14:55,846:INFO:   machine: Windows-10-10.0.22631-SP0
2024-08-22 18:14:55,846:INFO:PyCaret required dependencies:
2024-08-22 18:14:55,847:INFO:                 pip: 23.2.1
2024-08-22 18:14:55,847:INFO:          setuptools: 68.0.0
2024-08-22 18:14:55,847:INFO:             pycaret: 3.3.2
2024-08-22 18:14:55,847:INFO:             IPython: 8.15.0
2024-08-22 18:14:55,847:INFO:          ipywidgets: 8.0.4
2024-08-22 18:14:55,847:INFO:                tqdm: 4.65.0
2024-08-22 18:14:55,847:INFO:               numpy: 1.24.3
2024-08-22 18:14:55,847:INFO:              pandas: 2.0.3
2024-08-22 18:14:55,847:INFO:              jinja2: 3.1.2
2024-08-22 18:14:55,847:INFO:               scipy: 1.11.1
2024-08-22 18:14:55,847:INFO:              joblib: 1.3.2
2024-08-22 18:14:55,847:INFO:             sklearn: 1.4.2
2024-08-22 18:14:55,847:INFO:                pyod: 2.0.1
2024-08-22 18:14:55,847:INFO:            imblearn: 0.12.3
2024-08-22 18:14:55,847:INFO:   category_encoders: 2.6.3
2024-08-22 18:14:55,847:INFO:            lightgbm: 4.5.0
2024-08-22 18:14:55,847:INFO:               numba: 0.57.1
2024-08-22 18:14:55,847:INFO:            requests: 2.31.0
2024-08-22 18:14:55,847:INFO:          matplotlib: 3.7.2
2024-08-22 18:14:55,847:INFO:          scikitplot: 0.3.7
2024-08-22 18:14:55,848:INFO:         yellowbrick: 1.5
2024-08-22 18:14:55,848:INFO:              plotly: 5.23.0
2024-08-22 18:14:55,848:INFO:    plotly-resampler: Not installed
2024-08-22 18:14:55,848:INFO:             kaleido: 0.2.1
2024-08-22 18:14:55,848:INFO:           schemdraw: 0.15
2024-08-22 18:14:55,848:INFO:         statsmodels: 0.14.0
2024-08-22 18:14:55,848:INFO:              sktime: 0.26.0
2024-08-22 18:14:55,848:INFO:               tbats: 1.1.3
2024-08-22 18:14:55,848:INFO:            pmdarima: 2.0.4
2024-08-22 18:14:55,848:INFO:              psutil: 5.9.0
2024-08-22 18:14:55,848:INFO:          markupsafe: 2.1.1
2024-08-22 18:14:55,848:INFO:             pickle5: Not installed
2024-08-22 18:14:55,848:INFO:         cloudpickle: 2.2.1
2024-08-22 18:14:55,848:INFO:         deprecation: 2.1.0
2024-08-22 18:14:55,848:INFO:              xxhash: 2.0.2
2024-08-22 18:14:55,848:INFO:           wurlitzer: Not installed
2024-08-22 18:14:55,848:INFO:PyCaret optional dependencies:
2024-08-22 18:14:55,848:INFO:                shap: Not installed
2024-08-22 18:14:55,849:INFO:           interpret: Not installed
2024-08-22 18:14:55,849:INFO:                umap: Not installed
2024-08-22 18:14:55,849:INFO:     ydata_profiling: 4.7.0
2024-08-22 18:14:55,849:INFO:  explainerdashboard: Not installed
2024-08-22 18:14:55,849:INFO:             autoviz: Not installed
2024-08-22 18:14:55,849:INFO:           fairlearn: Not installed
2024-08-22 18:14:55,849:INFO:          deepchecks: Not installed
2024-08-22 18:14:55,849:INFO:             xgboost: Not installed
2024-08-22 18:14:55,849:INFO:            catboost: Not installed
2024-08-22 18:14:55,849:INFO:              kmodes: Not installed
2024-08-22 18:14:55,849:INFO:             mlxtend: Not installed
2024-08-22 18:14:55,849:INFO:       statsforecast: Not installed
2024-08-22 18:14:55,850:INFO:        tune_sklearn: Not installed
2024-08-22 18:14:55,850:INFO:                 ray: Not installed
2024-08-22 18:14:55,850:INFO:            hyperopt: Not installed
2024-08-22 18:14:55,850:INFO:              optuna: Not installed
2024-08-22 18:14:55,850:INFO:               skopt: Not installed
2024-08-22 18:14:55,850:INFO:              mlflow: Not installed
2024-08-22 18:14:55,850:INFO:              gradio: Not installed
2024-08-22 18:14:55,850:INFO:             fastapi: Not installed
2024-08-22 18:14:55,850:INFO:             uvicorn: Not installed
2024-08-22 18:14:55,850:INFO:              m2cgen: Not installed
2024-08-22 18:14:55,850:INFO:           evidently: Not installed
2024-08-22 18:14:55,850:INFO:               fugue: Not installed
2024-08-22 18:14:55,850:INFO:           streamlit: Not installed
2024-08-22 18:14:55,851:INFO:             prophet: Not installed
2024-08-22 18:14:55,851:INFO:None
2024-08-22 18:14:55,851:INFO:Set up data.
2024-08-22 18:14:56,310:INFO:Set up folding strategy.
2024-08-22 18:14:56,310:INFO:Set up train/test split.
2024-08-22 18:14:57,201:INFO:Set up index.
2024-08-22 18:14:57,229:INFO:Assigning column types.
2024-08-22 18:14:57,830:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-08-22 18:14:57,884:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-22 18:14:57,885:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-22 18:14:57,932:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 18:14:57,932:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 18:14:58,008:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-22 18:14:58,009:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-22 18:14:58,046:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 18:14:58,046:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 18:14:58,048:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-08-22 18:14:58,136:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-22 18:14:58,190:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 18:14:58,190:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 18:14:58,262:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-22 18:14:58,314:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 18:14:58,315:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 18:14:58,318:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-08-22 18:14:58,450:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 18:14:58,450:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 18:14:58,547:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 18:14:58,547:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 18:14:58,549:INFO:Preparing preprocessing pipeline...
2024-08-22 18:14:58,648:INFO:Set up date feature engineering.
2024-08-22 18:14:58,648:INFO:Set up simple imputation.
2024-08-22 18:14:58,648:INFO:Set up removing multicollinearity.
2024-08-22 18:14:58,648:INFO:Set up binning of numerical features.
2024-08-22 18:14:58,871:INFO:Set up column transformation.
2024-08-22 18:14:58,871:INFO:Set up feature normalization.
2024-08-22 18:14:58,945:INFO:Set up column name cleaning.
2024-08-22 18:15:33,243:INFO:Finished creating preprocessing pipeline.
2024-08-22 18:15:33,267:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\natha\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pess...
                                    transformer=PowerTransformer(copy=True,
                                                                 method='yeo-johnson',
                                                                 standardize=False))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2024-08-22 18:15:33,267:INFO:Creating final display dataframe.
2024-08-22 18:15:43,047:INFO:Setup _display_container:                     Description             Value
0                    Session id              6593
1                        Target               mau
2                   Target type            Binary
3           Original data shape      (750000, 35)
4        Transformed data shape      (750000, 37)
5   Transformed train set shape      (525000, 37)
6    Transformed test set shape      (225000, 37)
7              Numeric features                 6
8                 Date features                 1
9      Rows with missing values             16.8%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Remove multicollinearity              True
15  Multicollinearity threshold              0.95
16               Transformation              True
17        Transformation method       yeo-johnson
18                    Normalize              True
19             Normalize method            zscore
20               Fold Generator   StratifiedKFold
21                  Fold Number                10
22                     CPU Jobs                -1
23                      Use GPU             False
24               Log Experiment             False
25              Experiment Name  clf-default-name
26                          USI              9802
2024-08-22 18:15:43,376:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 18:15:43,383:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 18:15:43,461:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 18:15:43,462:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 18:15:43,470:INFO:setup() successfully completed in 47.64s...............
2024-08-22 18:15:43,548:INFO:Initializing create_model()
2024-08-22 18:15:43,548:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AE95CF3ED0>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-22 18:15:43,548:INFO:Checking exceptions
2024-08-22 18:15:43,607:INFO:Importing libraries
2024-08-22 18:15:43,609:INFO:Copying training dataset
2024-08-22 18:15:44,434:INFO:Defining folds
2024-08-22 18:15:44,434:INFO:Declaring metric variables
2024-08-22 18:15:44,440:INFO:Importing untrained model
2024-08-22 18:15:44,445:INFO:Light Gradient Boosting Machine Imported successfully
2024-08-22 18:15:44,454:INFO:Starting cross validation
2024-08-22 18:15:44,466:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-22 18:15:49,899:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 18:15:50,020:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 18:15:50,547:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 18:15:51,753:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 18:15:51,954:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 18:15:52,737:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 18:15:53,145:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 18:15:53,538:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 18:17:17,535:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-22 18:17:17,654:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-22 18:17:17,755:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-22 18:17:18,025:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-22 18:17:19,661:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-22 18:17:20,862:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-22 18:17:20,984:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-22 18:17:22,255:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 18:17:22,343:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 18:18:04,331:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-22 18:18:04,547:INFO:Calculating mean and std
2024-08-22 18:18:04,562:INFO:Creating metrics dataframe
2024-08-22 18:18:04,597:INFO:Finalizing model
2024-08-22 18:18:35,991:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-08-22 18:18:35,993:INFO:[LightGBM] [Info] Number of positive: 41050, number of negative: 483950
2024-08-22 18:18:36,069:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.027068 seconds.
2024-08-22 18:18:36,069:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-22 18:18:36,069:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-22 18:18:36,070:INFO:[LightGBM] [Info] Total Bins 382
2024-08-22 18:18:36,071:INFO:[LightGBM] [Info] Number of data points in the train set: 525000, number of used features: 35
2024-08-22 18:18:36,074:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.078190 -> initscore=-2.467191
2024-08-22 18:18:36,075:INFO:[LightGBM] [Info] Start training from score -2.467191
2024-08-22 18:18:37,962:INFO:Uploading results into container
2024-08-22 18:18:37,964:INFO:Uploading model into container now
2024-08-22 18:18:37,990:INFO:_master_model_container: 1
2024-08-22 18:18:37,990:INFO:_display_container: 2
2024-08-22 18:18:37,991:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6593, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-08-22 18:18:37,991:INFO:create_model() successfully completed......................................
2024-08-22 18:18:39,434:INFO:Initializing tune_model()
2024-08-22 18:18:39,435:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AE95CF3ED0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6593, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-08-22 18:18:39,435:INFO:Checking exceptions
2024-08-22 18:18:39,922:INFO:Copying training dataset
2024-08-22 18:18:40,381:INFO:Checking base model
2024-08-22 18:18:40,382:INFO:Base model : Light Gradient Boosting Machine
2024-08-22 18:18:40,385:INFO:Declaring metric variables
2024-08-22 18:18:40,388:INFO:Defining Hyperparameters
2024-08-22 18:18:40,633:INFO:Tuning with n_jobs=-1
2024-08-22 18:18:40,633:INFO:Initializing RandomizedSearchCV
2024-08-22 18:18:49,047:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 18:18:49,209:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 18:18:49,330:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 18:18:49,789:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 18:18:50,296:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 18:18:51,060:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 18:18:51,275:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 18:18:51,406:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 18:20:13,246:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 18:20:13,625:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 18:20:14,497:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 18:20:14,734:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 18:20:15,373:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 18:20:16,986:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 18:20:20,766:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 18:20:22,335:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 18:21:34,923:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 18:21:35,356:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 18:22:16,412:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 18:22:17,916:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 18:22:26,927:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 18:22:32,518:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 18:22:35,117:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 18:22:59,952:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 18:23:57,470:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 18:23:57,819:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 18:24:02,656:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 18:24:05,568:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 18:25:01,013:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 18:25:04,336:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 18:25:06,063:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 18:25:39,539:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 18:26:15,700:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 18:26:17,856:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 18:26:22,402:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 18:26:35,661:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 18:27:22,446:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 18:27:22,654:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 18:27:37,274:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 18:27:42,116:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 18:27:56,668:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 18:28:36,572:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 18:28:53,205:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 18:28:54,182:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 18:29:08,202:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 18:29:21,575:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 18:29:53,614:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 18:30:08,811:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 18:30:34,333:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 18:30:38,711:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 18:30:46,890:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 18:31:10,597:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 18:31:32,672:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 18:31:47,955:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 18:31:57,295:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 18:32:12,069:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 18:32:31,393:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 18:32:51,089:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 18:32:59,577:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 18:33:13,695:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 18:33:33,100:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 18:33:53,384:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 18:33:56,624:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 18:34:06,028:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 18:34:16,216:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 18:34:40,275:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 18:35:06,414:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 18:35:14,715:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 18:35:37,036:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 18:35:39,244:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 18:37:55,664:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 18:38:08,845:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 18:38:40,099:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 18:38:40,162:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 18:38:40,407:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 18:38:41,473:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 18:38:41,973:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 18:38:42,503:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 18:40:09,285:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 18:40:09,298:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 18:40:09,315:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 18:40:10,167:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 18:40:18,374:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 18:40:38,062:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 18:41:18,256:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 18:41:18,774:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 18:41:19,743:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 18:42:10,745:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 18:42:23,491:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 18:42:23,899:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 18:42:31,740:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 18:42:59,203:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 18:43:45,277:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 18:43:46,181:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 18:43:55,180:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 19:36:00,424:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 19:36:50,839:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 19:36:52,977:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 19:36:53,508:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 19:36:54,446:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 21:12:27,879:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-22 21:12:27,880:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-22 21:12:27,881:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-22 21:12:27,881:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-22 21:12:31,012:INFO:PyCaret ClassificationExperiment
2024-08-22 21:12:31,012:INFO:Logging name: clf-default-name
2024-08-22 21:12:31,012:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-08-22 21:12:31,013:INFO:version 3.3.2
2024-08-22 21:12:31,013:INFO:Initializing setup()
2024-08-22 21:12:31,013:INFO:self.USI: 8be7
2024-08-22 21:12:31,013:INFO:self._variable_keys: {'log_plots_param', 'memory', 'gpu_param', 'seed', 'X_train', 'USI', 'fold_generator', '_available_plots', 'fold_shuffle_param', 'X', 'pipeline', 'y_train', 'exp_name_log', 'fix_imbalance', 'gpu_n_jobs_param', 'y', 'data', '_ml_usecase', 'target_param', 'exp_id', 'idx', 'y_test', 'logging_param', 'n_jobs_param', 'fold_groups_param', 'is_multiclass', 'html_param', 'X_test'}
2024-08-22 21:12:31,013:INFO:Checking environment
2024-08-22 21:12:31,013:INFO:python_version: 3.11.5
2024-08-22 21:12:31,013:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-08-22 21:12:31,013:INFO:machine: AMD64
2024-08-22 21:12:31,013:INFO:platform: Windows-10-10.0.22631-SP0
2024-08-22 21:12:31,013:INFO:Memory: svmem(total=8311836672, available=1901445120, percent=77.1, used=6410391552, free=1901445120)
2024-08-22 21:12:31,014:INFO:Physical Core: 4
2024-08-22 21:12:31,014:INFO:Logical Core: 8
2024-08-22 21:12:31,014:INFO:Checking libraries
2024-08-22 21:12:31,014:INFO:System:
2024-08-22 21:12:31,014:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-08-22 21:12:31,014:INFO:executable: C:\Users\natha\anaconda3\python.exe
2024-08-22 21:12:31,014:INFO:   machine: Windows-10-10.0.22631-SP0
2024-08-22 21:12:31,014:INFO:PyCaret required dependencies:
2024-08-22 21:12:33,559:INFO:                 pip: 23.2.1
2024-08-22 21:12:33,559:INFO:          setuptools: 68.0.0
2024-08-22 21:12:33,559:INFO:             pycaret: 3.3.2
2024-08-22 21:12:33,559:INFO:             IPython: 8.15.0
2024-08-22 21:12:33,559:INFO:          ipywidgets: 8.0.4
2024-08-22 21:12:33,559:INFO:                tqdm: 4.65.0
2024-08-22 21:12:33,560:INFO:               numpy: 1.24.3
2024-08-22 21:12:33,560:INFO:              pandas: 2.0.3
2024-08-22 21:12:33,560:INFO:              jinja2: 3.1.2
2024-08-22 21:12:33,560:INFO:               scipy: 1.11.1
2024-08-22 21:12:33,560:INFO:              joblib: 1.3.2
2024-08-22 21:12:33,560:INFO:             sklearn: 1.4.2
2024-08-22 21:12:33,560:INFO:                pyod: 2.0.1
2024-08-22 21:12:33,560:INFO:            imblearn: 0.12.3
2024-08-22 21:12:33,560:INFO:   category_encoders: 2.6.3
2024-08-22 21:12:33,560:INFO:            lightgbm: 4.5.0
2024-08-22 21:12:33,561:INFO:               numba: 0.57.1
2024-08-22 21:12:33,561:INFO:            requests: 2.31.0
2024-08-22 21:12:33,561:INFO:          matplotlib: 3.7.2
2024-08-22 21:12:33,561:INFO:          scikitplot: 0.3.7
2024-08-22 21:12:33,561:INFO:         yellowbrick: 1.5
2024-08-22 21:12:33,561:INFO:              plotly: 5.23.0
2024-08-22 21:12:33,561:INFO:    plotly-resampler: Not installed
2024-08-22 21:12:33,561:INFO:             kaleido: 0.2.1
2024-08-22 21:12:33,562:INFO:           schemdraw: 0.15
2024-08-22 21:12:33,562:INFO:         statsmodels: 0.14.0
2024-08-22 21:12:33,562:INFO:              sktime: 0.26.0
2024-08-22 21:12:33,562:INFO:               tbats: 1.1.3
2024-08-22 21:12:33,562:INFO:            pmdarima: 2.0.4
2024-08-22 21:12:33,562:INFO:              psutil: 5.9.0
2024-08-22 21:12:33,562:INFO:          markupsafe: 2.1.1
2024-08-22 21:12:33,562:INFO:             pickle5: Not installed
2024-08-22 21:12:33,562:INFO:         cloudpickle: 2.2.1
2024-08-22 21:12:33,562:INFO:         deprecation: 2.1.0
2024-08-22 21:12:33,563:INFO:              xxhash: 2.0.2
2024-08-22 21:12:33,563:INFO:           wurlitzer: Not installed
2024-08-22 21:12:33,563:INFO:PyCaret optional dependencies:
2024-08-22 21:12:33,595:INFO:                shap: Not installed
2024-08-22 21:12:33,596:INFO:           interpret: Not installed
2024-08-22 21:12:33,596:INFO:                umap: Not installed
2024-08-22 21:12:33,596:INFO:     ydata_profiling: 4.7.0
2024-08-22 21:12:33,596:INFO:  explainerdashboard: Not installed
2024-08-22 21:12:33,596:INFO:             autoviz: Not installed
2024-08-22 21:12:33,596:INFO:           fairlearn: Not installed
2024-08-22 21:12:33,596:INFO:          deepchecks: Not installed
2024-08-22 21:12:33,596:INFO:             xgboost: Not installed
2024-08-22 21:12:33,596:INFO:            catboost: Not installed
2024-08-22 21:12:33,596:INFO:              kmodes: Not installed
2024-08-22 21:12:33,596:INFO:             mlxtend: Not installed
2024-08-22 21:12:33,596:INFO:       statsforecast: Not installed
2024-08-22 21:12:33,596:INFO:        tune_sklearn: Not installed
2024-08-22 21:12:33,596:INFO:                 ray: Not installed
2024-08-22 21:12:33,597:INFO:            hyperopt: Not installed
2024-08-22 21:12:33,597:INFO:              optuna: Not installed
2024-08-22 21:12:33,597:INFO:               skopt: Not installed
2024-08-22 21:12:33,597:INFO:              mlflow: Not installed
2024-08-22 21:12:33,597:INFO:              gradio: Not installed
2024-08-22 21:12:33,597:INFO:             fastapi: Not installed
2024-08-22 21:12:33,597:INFO:             uvicorn: Not installed
2024-08-22 21:12:33,597:INFO:              m2cgen: Not installed
2024-08-22 21:12:33,597:INFO:           evidently: Not installed
2024-08-22 21:12:33,597:INFO:               fugue: Not installed
2024-08-22 21:12:33,598:INFO:           streamlit: Not installed
2024-08-22 21:12:33,598:INFO:             prophet: Not installed
2024-08-22 21:12:33,598:INFO:None
2024-08-22 21:12:33,598:INFO:Set up data.
2024-08-22 21:12:33,673:INFO:Set up folding strategy.
2024-08-22 21:12:33,673:INFO:Set up train/test split.
2024-08-22 21:12:33,714:INFO:Set up index.
2024-08-22 21:12:33,716:INFO:Assigning column types.
2024-08-22 21:12:33,733:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-08-22 21:12:33,837:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-22 21:12:33,846:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-22 21:12:33,928:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:12:33,929:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:12:34,041:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-22 21:12:34,043:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-22 21:12:34,126:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:12:34,126:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:12:34,127:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-08-22 21:12:34,246:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-22 21:12:34,319:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:12:34,320:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:12:34,432:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-22 21:12:34,501:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:12:34,501:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:12:34,502:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-08-22 21:12:34,686:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:12:34,687:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:12:34,891:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:12:34,892:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:12:34,898:INFO:Preparing preprocessing pipeline...
2024-08-22 21:12:34,903:INFO:Set up simple imputation.
2024-08-22 21:12:34,925:INFO:Set up encoding of ordinal features.
2024-08-22 21:12:34,943:INFO:Set up encoding of categorical features.
2024-08-22 21:12:35,684:INFO:Finished creating preprocessing pipeline.
2024-08-22 21:12:35,754:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\natha\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean')...
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['tipo_renda', 'educacao',
                                             'estado_civil',
                                             'tipo_residencia'],
                                    transformer=OneHotEncoder(cols=['tipo_renda',
                                                                    'educacao',
                                                                    'estado_civil',
                                                                    'tipo_residencia'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2024-08-22 21:12:35,755:INFO:Creating final display dataframe.
2024-08-22 21:12:36,994:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target               mau
2                   Target type            Binary
3           Original data shape       (38000, 13)
4        Transformed data shape       (38000, 30)
5   Transformed train set shape       (26600, 30)
6    Transformed test set shape       (11400, 30)
7              Numeric features                 5
8          Categorical features                 7
9      Rows with missing values             16.7%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  clf-default-name
22                          USI              8be7
2024-08-22 21:12:37,183:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:12:37,184:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:12:37,377:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:12:37,377:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:12:37,380:INFO:setup() successfully completed in 6.43s...............
2024-08-22 21:12:37,388:INFO:gpu_param set to False
2024-08-22 21:12:37,552:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:12:37,555:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:12:37,715:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:12:37,716:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:12:38,965:INFO:PyCaret ClassificationExperiment
2024-08-22 21:12:38,965:INFO:Logging name: credit_1
2024-08-22 21:12:38,965:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-08-22 21:12:38,965:INFO:version 3.3.2
2024-08-22 21:12:38,965:INFO:Initializing setup()
2024-08-22 21:12:38,967:INFO:self.USI: f782
2024-08-22 21:12:38,967:INFO:self._variable_keys: {'log_plots_param', 'memory', 'gpu_param', 'seed', 'X_train', 'USI', 'fold_generator', '_available_plots', 'fold_shuffle_param', 'X', 'pipeline', 'y_train', 'exp_name_log', 'fix_imbalance', 'gpu_n_jobs_param', 'y', 'data', '_ml_usecase', 'target_param', 'exp_id', 'idx', 'y_test', 'logging_param', 'n_jobs_param', 'fold_groups_param', 'is_multiclass', 'html_param', 'X_test'}
2024-08-22 21:12:38,967:INFO:Checking environment
2024-08-22 21:12:38,967:INFO:python_version: 3.11.5
2024-08-22 21:12:38,967:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-08-22 21:12:38,967:INFO:machine: AMD64
2024-08-22 21:12:38,967:INFO:platform: Windows-10-10.0.22631-SP0
2024-08-22 21:12:38,967:INFO:Memory: svmem(total=8311836672, available=1668771840, percent=79.9, used=6643064832, free=1668771840)
2024-08-22 21:12:38,967:INFO:Physical Core: 4
2024-08-22 21:12:38,967:INFO:Logical Core: 8
2024-08-22 21:12:38,967:INFO:Checking libraries
2024-08-22 21:12:38,968:INFO:System:
2024-08-22 21:12:38,968:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-08-22 21:12:38,968:INFO:executable: C:\Users\natha\anaconda3\python.exe
2024-08-22 21:12:38,968:INFO:   machine: Windows-10-10.0.22631-SP0
2024-08-22 21:12:38,968:INFO:PyCaret required dependencies:
2024-08-22 21:12:38,968:INFO:                 pip: 23.2.1
2024-08-22 21:12:38,968:INFO:          setuptools: 68.0.0
2024-08-22 21:12:38,968:INFO:             pycaret: 3.3.2
2024-08-22 21:12:38,968:INFO:             IPython: 8.15.0
2024-08-22 21:12:38,968:INFO:          ipywidgets: 8.0.4
2024-08-22 21:12:38,969:INFO:                tqdm: 4.65.0
2024-08-22 21:12:38,969:INFO:               numpy: 1.24.3
2024-08-22 21:12:38,969:INFO:              pandas: 2.0.3
2024-08-22 21:12:38,969:INFO:              jinja2: 3.1.2
2024-08-22 21:12:38,969:INFO:               scipy: 1.11.1
2024-08-22 21:12:38,969:INFO:              joblib: 1.3.2
2024-08-22 21:12:38,969:INFO:             sklearn: 1.4.2
2024-08-22 21:12:38,969:INFO:                pyod: 2.0.1
2024-08-22 21:12:38,969:INFO:            imblearn: 0.12.3
2024-08-22 21:12:38,969:INFO:   category_encoders: 2.6.3
2024-08-22 21:12:38,969:INFO:            lightgbm: 4.5.0
2024-08-22 21:12:38,969:INFO:               numba: 0.57.1
2024-08-22 21:12:38,969:INFO:            requests: 2.31.0
2024-08-22 21:12:38,969:INFO:          matplotlib: 3.7.2
2024-08-22 21:12:38,969:INFO:          scikitplot: 0.3.7
2024-08-22 21:12:38,970:INFO:         yellowbrick: 1.5
2024-08-22 21:12:38,970:INFO:              plotly: 5.23.0
2024-08-22 21:12:38,970:INFO:    plotly-resampler: Not installed
2024-08-22 21:12:38,970:INFO:             kaleido: 0.2.1
2024-08-22 21:12:38,970:INFO:           schemdraw: 0.15
2024-08-22 21:12:38,970:INFO:         statsmodels: 0.14.0
2024-08-22 21:12:38,970:INFO:              sktime: 0.26.0
2024-08-22 21:12:38,970:INFO:               tbats: 1.1.3
2024-08-22 21:12:38,970:INFO:            pmdarima: 2.0.4
2024-08-22 21:12:38,970:INFO:              psutil: 5.9.0
2024-08-22 21:12:38,970:INFO:          markupsafe: 2.1.1
2024-08-22 21:12:38,970:INFO:             pickle5: Not installed
2024-08-22 21:12:38,970:INFO:         cloudpickle: 2.2.1
2024-08-22 21:12:38,970:INFO:         deprecation: 2.1.0
2024-08-22 21:12:38,970:INFO:              xxhash: 2.0.2
2024-08-22 21:12:38,971:INFO:           wurlitzer: Not installed
2024-08-22 21:12:38,971:INFO:PyCaret optional dependencies:
2024-08-22 21:12:38,971:INFO:                shap: Not installed
2024-08-22 21:12:38,971:INFO:           interpret: Not installed
2024-08-22 21:12:38,971:INFO:                umap: Not installed
2024-08-22 21:12:38,971:INFO:     ydata_profiling: 4.7.0
2024-08-22 21:12:38,971:INFO:  explainerdashboard: Not installed
2024-08-22 21:12:38,971:INFO:             autoviz: Not installed
2024-08-22 21:12:38,971:INFO:           fairlearn: Not installed
2024-08-22 21:12:38,971:INFO:          deepchecks: Not installed
2024-08-22 21:12:38,971:INFO:             xgboost: Not installed
2024-08-22 21:12:38,971:INFO:            catboost: Not installed
2024-08-22 21:12:38,971:INFO:              kmodes: Not installed
2024-08-22 21:12:38,971:INFO:             mlxtend: Not installed
2024-08-22 21:12:38,971:INFO:       statsforecast: Not installed
2024-08-22 21:12:38,971:INFO:        tune_sklearn: Not installed
2024-08-22 21:12:38,972:INFO:                 ray: Not installed
2024-08-22 21:12:38,972:INFO:            hyperopt: Not installed
2024-08-22 21:12:38,972:INFO:              optuna: Not installed
2024-08-22 21:12:38,972:INFO:               skopt: Not installed
2024-08-22 21:12:38,972:INFO:              mlflow: Not installed
2024-08-22 21:12:38,972:INFO:              gradio: Not installed
2024-08-22 21:12:38,972:INFO:             fastapi: Not installed
2024-08-22 21:12:38,972:INFO:             uvicorn: Not installed
2024-08-22 21:12:38,972:INFO:              m2cgen: Not installed
2024-08-22 21:12:38,972:INFO:           evidently: Not installed
2024-08-22 21:12:38,973:INFO:               fugue: Not installed
2024-08-22 21:12:38,973:INFO:           streamlit: Not installed
2024-08-22 21:12:38,973:INFO:             prophet: Not installed
2024-08-22 21:12:38,973:INFO:None
2024-08-22 21:12:38,973:INFO:Set up data.
2024-08-22 21:12:39,045:INFO:Set up folding strategy.
2024-08-22 21:12:39,046:INFO:Set up train/test split.
2024-08-22 21:12:39,089:INFO:Set up index.
2024-08-22 21:12:39,091:INFO:Assigning column types.
2024-08-22 21:12:39,108:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-08-22 21:12:39,211:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-22 21:12:39,213:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-22 21:12:39,308:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:12:39,309:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:12:39,416:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-22 21:12:39,418:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-22 21:12:39,492:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:12:39,493:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:12:39,494:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-08-22 21:12:39,602:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-22 21:12:39,667:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:12:39,667:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:12:39,772:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-22 21:12:40,172:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:12:40,174:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:12:40,175:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-08-22 21:12:40,382:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:12:40,383:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:12:40,566:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:12:40,566:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:12:40,569:INFO:Preparing preprocessing pipeline...
2024-08-22 21:12:40,576:INFO:Set up simple imputation.
2024-08-22 21:12:40,597:INFO:Set up encoding of ordinal features.
2024-08-22 21:12:40,615:INFO:Set up encoding of categorical features.
2024-08-22 21:12:40,615:INFO:Set up imbalanced handling.
2024-08-22 21:12:40,615:INFO:Set up column transformation.
2024-08-22 21:12:40,615:INFO:Set up feature normalization.
2024-08-22 21:12:43,300:INFO:Finished creating preprocessing pipeline.
2024-08-22 21:12:43,395:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\natha\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean')...
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=QuantileTransformer(copy=True,
                                                                    ignore_implicit_zeros=False,
                                                                    n_quantiles=1000,
                                                                    output_distribution='normal',
                                                                    random_state=1909,
                                                                    subsample=10000))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2024-08-22 21:12:43,395:INFO:Creating final display dataframe.
2024-08-22 21:12:45,870:INFO:Setup _display_container:                     Description            Value
0                    Session id             1909
1                        Target              mau
2                   Target type           Binary
3           Original data shape      (38000, 13)
4        Transformed data shape      (60516, 30)
5   Transformed train set shape      (49116, 30)
6    Transformed test set shape      (11400, 30)
7              Numeric features                5
8          Categorical features                7
9      Rows with missing values            16.7%
10                   Preprocess             True
11              Imputation type           simple
12           Numeric imputation             mean
13       Categorical imputation             mode
14     Maximum one-hot encoding               25
15              Encoding method             None
16                Fix imbalance             True
17         Fix imbalance method            SMOTE
18               Transformation             True
19        Transformation method         quantile
20                    Normalize             True
21             Normalize method           zscore
22               Fold Generator  StratifiedKFold
23                  Fold Number               10
24                     CPU Jobs               -1
25                      Use GPU            False
26               Log Experiment            False
27              Experiment Name         credit_1
28                          USI             f782
2024-08-22 21:12:46,065:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:12:46,066:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:12:46,253:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:12:46,254:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:12:46,257:INFO:setup() successfully completed in 7.32s...............
2024-08-22 21:12:46,268:INFO:Initializing compare_models()
2024-08-22 21:12:46,268:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025211643190>, include=None, exclude=None, fold=4, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000025211643190>, 'include': None, 'exclude': None, 'fold': 4, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-08-22 21:12:46,268:INFO:Checking exceptions
2024-08-22 21:12:46,286:INFO:Preparing display monitor
2024-08-22 21:12:46,338:INFO:Initializing Logistic Regression
2024-08-22 21:12:46,339:INFO:Total runtime is 1.6820430755615234e-05 minutes
2024-08-22 21:12:46,346:INFO:SubProcess create_model() called ==================================
2024-08-22 21:12:46,346:INFO:Initializing create_model()
2024-08-22 21:12:46,346:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025211643190>, estimator=lr, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025211517010>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-22 21:12:46,346:INFO:Checking exceptions
2024-08-22 21:12:46,346:INFO:Importing libraries
2024-08-22 21:12:46,346:INFO:Copying training dataset
2024-08-22 21:12:46,383:INFO:Defining folds
2024-08-22 21:12:46,384:INFO:Declaring metric variables
2024-08-22 21:12:46,391:INFO:Importing untrained model
2024-08-22 21:12:46,398:INFO:Logistic Regression Imported successfully
2024-08-22 21:12:46,414:INFO:Starting cross validation
2024-08-22 21:12:46,420:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-08-22 21:12:52,940:INFO:Calculating mean and std
2024-08-22 21:12:52,942:INFO:Creating metrics dataframe
2024-08-22 21:12:52,946:INFO:Uploading results into container
2024-08-22 21:12:52,947:INFO:Uploading model into container now
2024-08-22 21:12:52,948:INFO:_master_model_container: 1
2024-08-22 21:12:52,948:INFO:_display_container: 2
2024-08-22 21:12:52,949:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1909, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-08-22 21:12:52,949:INFO:create_model() successfully completed......................................
2024-08-22 21:12:53,182:INFO:SubProcess create_model() end ==================================
2024-08-22 21:12:53,183:INFO:Creating metrics dataframe
2024-08-22 21:12:53,197:INFO:Initializing K Neighbors Classifier
2024-08-22 21:12:53,198:INFO:Total runtime is 0.11433478196461995 minutes
2024-08-22 21:12:53,204:INFO:SubProcess create_model() called ==================================
2024-08-22 21:12:53,204:INFO:Initializing create_model()
2024-08-22 21:12:53,204:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025211643190>, estimator=knn, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025211517010>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-22 21:12:53,204:INFO:Checking exceptions
2024-08-22 21:12:53,204:INFO:Importing libraries
2024-08-22 21:12:53,205:INFO:Copying training dataset
2024-08-22 21:12:53,223:INFO:Defining folds
2024-08-22 21:12:53,223:INFO:Declaring metric variables
2024-08-22 21:12:53,231:INFO:Importing untrained model
2024-08-22 21:12:53,237:INFO:K Neighbors Classifier Imported successfully
2024-08-22 21:12:53,250:INFO:Starting cross validation
2024-08-22 21:12:53,256:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-08-22 21:13:12,560:INFO:Calculating mean and std
2024-08-22 21:13:12,564:INFO:Creating metrics dataframe
2024-08-22 21:13:12,571:INFO:Uploading results into container
2024-08-22 21:13:12,573:INFO:Uploading model into container now
2024-08-22 21:13:12,574:INFO:_master_model_container: 2
2024-08-22 21:13:12,575:INFO:_display_container: 2
2024-08-22 21:13:12,576:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-08-22 21:13:12,577:INFO:create_model() successfully completed......................................
2024-08-22 21:13:12,852:INFO:SubProcess create_model() end ==================================
2024-08-22 21:13:12,852:INFO:Creating metrics dataframe
2024-08-22 21:13:12,875:INFO:Initializing Naive Bayes
2024-08-22 21:13:12,876:INFO:Total runtime is 0.4422719955444336 minutes
2024-08-22 21:13:12,883:INFO:SubProcess create_model() called ==================================
2024-08-22 21:13:12,884:INFO:Initializing create_model()
2024-08-22 21:13:12,884:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025211643190>, estimator=nb, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025211517010>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-22 21:13:12,884:INFO:Checking exceptions
2024-08-22 21:13:12,885:INFO:Importing libraries
2024-08-22 21:13:12,885:INFO:Copying training dataset
2024-08-22 21:13:12,906:INFO:Defining folds
2024-08-22 21:13:12,906:INFO:Declaring metric variables
2024-08-22 21:13:12,912:INFO:Importing untrained model
2024-08-22 21:13:12,919:INFO:Naive Bayes Imported successfully
2024-08-22 21:13:12,933:INFO:Starting cross validation
2024-08-22 21:13:12,938:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-08-22 21:13:15,182:INFO:Calculating mean and std
2024-08-22 21:13:15,186:INFO:Creating metrics dataframe
2024-08-22 21:13:15,192:INFO:Uploading results into container
2024-08-22 21:13:15,193:INFO:Uploading model into container now
2024-08-22 21:13:15,194:INFO:_master_model_container: 3
2024-08-22 21:13:15,194:INFO:_display_container: 2
2024-08-22 21:13:15,195:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-08-22 21:13:15,195:INFO:create_model() successfully completed......................................
2024-08-22 21:13:15,442:INFO:SubProcess create_model() end ==================================
2024-08-22 21:13:15,442:INFO:Creating metrics dataframe
2024-08-22 21:13:15,465:INFO:Initializing Decision Tree Classifier
2024-08-22 21:13:15,465:INFO:Total runtime is 0.4854366381963094 minutes
2024-08-22 21:13:15,470:INFO:SubProcess create_model() called ==================================
2024-08-22 21:13:15,471:INFO:Initializing create_model()
2024-08-22 21:13:15,471:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025211643190>, estimator=dt, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025211517010>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-22 21:13:15,472:INFO:Checking exceptions
2024-08-22 21:13:15,472:INFO:Importing libraries
2024-08-22 21:13:15,472:INFO:Copying training dataset
2024-08-22 21:13:15,495:INFO:Defining folds
2024-08-22 21:13:15,496:INFO:Declaring metric variables
2024-08-22 21:13:15,502:INFO:Importing untrained model
2024-08-22 21:13:15,509:INFO:Decision Tree Classifier Imported successfully
2024-08-22 21:13:15,524:INFO:Starting cross validation
2024-08-22 21:13:15,528:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-08-22 21:13:18,342:INFO:Calculating mean and std
2024-08-22 21:13:18,347:INFO:Creating metrics dataframe
2024-08-22 21:13:18,353:INFO:Uploading results into container
2024-08-22 21:13:18,354:INFO:Uploading model into container now
2024-08-22 21:13:18,355:INFO:_master_model_container: 4
2024-08-22 21:13:18,355:INFO:_display_container: 2
2024-08-22 21:13:18,356:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=1909, splitter='best')
2024-08-22 21:13:18,356:INFO:create_model() successfully completed......................................
2024-08-22 21:13:18,620:INFO:SubProcess create_model() end ==================================
2024-08-22 21:13:18,621:INFO:Creating metrics dataframe
2024-08-22 21:13:18,638:INFO:Initializing SVM - Linear Kernel
2024-08-22 21:13:18,639:INFO:Total runtime is 0.5383405526479085 minutes
2024-08-22 21:13:18,648:INFO:SubProcess create_model() called ==================================
2024-08-22 21:13:18,649:INFO:Initializing create_model()
2024-08-22 21:13:18,649:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025211643190>, estimator=svm, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025211517010>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-22 21:13:18,649:INFO:Checking exceptions
2024-08-22 21:13:18,650:INFO:Importing libraries
2024-08-22 21:13:18,650:INFO:Copying training dataset
2024-08-22 21:13:18,671:INFO:Defining folds
2024-08-22 21:13:18,672:INFO:Declaring metric variables
2024-08-22 21:13:18,679:INFO:Importing untrained model
2024-08-22 21:13:18,686:INFO:SVM - Linear Kernel Imported successfully
2024-08-22 21:13:18,700:INFO:Starting cross validation
2024-08-22 21:13:18,706:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-08-22 21:13:21,288:INFO:Calculating mean and std
2024-08-22 21:13:21,291:INFO:Creating metrics dataframe
2024-08-22 21:13:21,297:INFO:Uploading results into container
2024-08-22 21:13:21,299:INFO:Uploading model into container now
2024-08-22 21:13:21,300:INFO:_master_model_container: 5
2024-08-22 21:13:21,300:INFO:_display_container: 2
2024-08-22 21:13:21,301:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=1909, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-08-22 21:13:21,302:INFO:create_model() successfully completed......................................
2024-08-22 21:13:21,546:INFO:SubProcess create_model() end ==================================
2024-08-22 21:13:21,546:INFO:Creating metrics dataframe
2024-08-22 21:13:21,568:INFO:Initializing Ridge Classifier
2024-08-22 21:13:21,569:INFO:Total runtime is 0.5871730804443359 minutes
2024-08-22 21:13:21,576:INFO:SubProcess create_model() called ==================================
2024-08-22 21:13:21,577:INFO:Initializing create_model()
2024-08-22 21:13:21,577:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025211643190>, estimator=ridge, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025211517010>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-22 21:13:21,577:INFO:Checking exceptions
2024-08-22 21:13:21,577:INFO:Importing libraries
2024-08-22 21:13:21,577:INFO:Copying training dataset
2024-08-22 21:13:21,607:INFO:Defining folds
2024-08-22 21:13:21,608:INFO:Declaring metric variables
2024-08-22 21:13:21,616:INFO:Importing untrained model
2024-08-22 21:13:21,624:INFO:Ridge Classifier Imported successfully
2024-08-22 21:13:21,642:INFO:Starting cross validation
2024-08-22 21:13:21,651:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-08-22 21:13:23,779:INFO:Calculating mean and std
2024-08-22 21:13:23,782:INFO:Creating metrics dataframe
2024-08-22 21:13:23,787:INFO:Uploading results into container
2024-08-22 21:13:23,788:INFO:Uploading model into container now
2024-08-22 21:13:23,789:INFO:_master_model_container: 6
2024-08-22 21:13:23,789:INFO:_display_container: 2
2024-08-22 21:13:23,791:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=1909, solver='auto',
                tol=0.0001)
2024-08-22 21:13:23,791:INFO:create_model() successfully completed......................................
2024-08-22 21:13:24,024:INFO:SubProcess create_model() end ==================================
2024-08-22 21:13:24,024:INFO:Creating metrics dataframe
2024-08-22 21:13:24,043:INFO:Initializing Random Forest Classifier
2024-08-22 21:13:24,043:INFO:Total runtime is 0.6284184217453003 minutes
2024-08-22 21:13:24,052:INFO:SubProcess create_model() called ==================================
2024-08-22 21:13:24,052:INFO:Initializing create_model()
2024-08-22 21:13:24,053:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025211643190>, estimator=rf, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025211517010>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-22 21:13:24,053:INFO:Checking exceptions
2024-08-22 21:13:24,053:INFO:Importing libraries
2024-08-22 21:13:24,054:INFO:Copying training dataset
2024-08-22 21:13:24,081:INFO:Defining folds
2024-08-22 21:13:24,081:INFO:Declaring metric variables
2024-08-22 21:13:24,091:INFO:Importing untrained model
2024-08-22 21:13:24,100:INFO:Random Forest Classifier Imported successfully
2024-08-22 21:13:24,111:INFO:Starting cross validation
2024-08-22 21:13:24,116:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-08-22 21:13:34,002:INFO:Calculating mean and std
2024-08-22 21:13:34,007:INFO:Creating metrics dataframe
2024-08-22 21:13:34,013:INFO:Uploading results into container
2024-08-22 21:13:34,014:INFO:Uploading model into container now
2024-08-22 21:13:34,015:INFO:_master_model_container: 7
2024-08-22 21:13:34,016:INFO:_display_container: 2
2024-08-22 21:13:34,017:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=1909, verbose=0,
                       warm_start=False)
2024-08-22 21:13:34,017:INFO:create_model() successfully completed......................................
2024-08-22 21:13:34,278:INFO:SubProcess create_model() end ==================================
2024-08-22 21:13:34,279:INFO:Creating metrics dataframe
2024-08-22 21:13:34,302:INFO:Initializing Quadratic Discriminant Analysis
2024-08-22 21:13:34,303:INFO:Total runtime is 0.7993872880935669 minutes
2024-08-22 21:13:34,310:INFO:SubProcess create_model() called ==================================
2024-08-22 21:13:34,311:INFO:Initializing create_model()
2024-08-22 21:13:34,311:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025211643190>, estimator=qda, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025211517010>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-22 21:13:34,312:INFO:Checking exceptions
2024-08-22 21:13:34,312:INFO:Importing libraries
2024-08-22 21:13:34,312:INFO:Copying training dataset
2024-08-22 21:13:34,342:INFO:Defining folds
2024-08-22 21:13:34,343:INFO:Declaring metric variables
2024-08-22 21:13:34,349:INFO:Importing untrained model
2024-08-22 21:13:34,356:INFO:Quadratic Discriminant Analysis Imported successfully
2024-08-22 21:13:34,371:INFO:Starting cross validation
2024-08-22 21:13:34,379:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-08-22 21:13:36,056:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-08-22 21:13:36,064:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-08-22 21:13:36,072:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-08-22 21:13:36,183:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-08-22 21:13:36,517:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-22 21:13:36,585:INFO:Calculating mean and std
2024-08-22 21:13:36,587:INFO:Creating metrics dataframe
2024-08-22 21:13:36,592:INFO:Uploading results into container
2024-08-22 21:13:36,593:INFO:Uploading model into container now
2024-08-22 21:13:36,594:INFO:_master_model_container: 8
2024-08-22 21:13:36,594:INFO:_display_container: 2
2024-08-22 21:13:36,595:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-08-22 21:13:36,595:INFO:create_model() successfully completed......................................
2024-08-22 21:13:36,813:INFO:SubProcess create_model() end ==================================
2024-08-22 21:13:36,814:INFO:Creating metrics dataframe
2024-08-22 21:13:36,837:INFO:Initializing Ada Boost Classifier
2024-08-22 21:13:36,838:INFO:Total runtime is 0.8416547616322835 minutes
2024-08-22 21:13:36,844:INFO:SubProcess create_model() called ==================================
2024-08-22 21:13:36,845:INFO:Initializing create_model()
2024-08-22 21:13:36,845:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025211643190>, estimator=ada, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025211517010>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-22 21:13:36,846:INFO:Checking exceptions
2024-08-22 21:13:36,846:INFO:Importing libraries
2024-08-22 21:13:36,846:INFO:Copying training dataset
2024-08-22 21:13:36,866:INFO:Defining folds
2024-08-22 21:13:36,866:INFO:Declaring metric variables
2024-08-22 21:13:36,884:INFO:Importing untrained model
2024-08-22 21:13:36,892:INFO:Ada Boost Classifier Imported successfully
2024-08-22 21:13:36,908:INFO:Starting cross validation
2024-08-22 21:13:36,916:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-08-22 21:13:38,457:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-08-22 21:13:38,567:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-08-22 21:13:38,568:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-08-22 21:13:38,656:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-08-22 21:13:46,016:INFO:Calculating mean and std
2024-08-22 21:13:46,019:INFO:Creating metrics dataframe
2024-08-22 21:13:46,024:INFO:Uploading results into container
2024-08-22 21:13:46,025:INFO:Uploading model into container now
2024-08-22 21:13:46,026:INFO:_master_model_container: 9
2024-08-22 21:13:46,026:INFO:_display_container: 2
2024-08-22 21:13:46,026:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=1909)
2024-08-22 21:13:46,027:INFO:create_model() successfully completed......................................
2024-08-22 21:13:46,251:INFO:SubProcess create_model() end ==================================
2024-08-22 21:13:46,252:INFO:Creating metrics dataframe
2024-08-22 21:13:46,278:INFO:Initializing Gradient Boosting Classifier
2024-08-22 21:13:46,279:INFO:Total runtime is 0.9990158915519713 minutes
2024-08-22 21:13:46,288:INFO:SubProcess create_model() called ==================================
2024-08-22 21:13:46,289:INFO:Initializing create_model()
2024-08-22 21:13:46,289:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025211643190>, estimator=gbc, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025211517010>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-22 21:13:46,290:INFO:Checking exceptions
2024-08-22 21:13:46,290:INFO:Importing libraries
2024-08-22 21:13:46,290:INFO:Copying training dataset
2024-08-22 21:13:46,316:INFO:Defining folds
2024-08-22 21:13:46,317:INFO:Declaring metric variables
2024-08-22 21:13:46,325:INFO:Importing untrained model
2024-08-22 21:13:46,334:INFO:Gradient Boosting Classifier Imported successfully
2024-08-22 21:13:46,354:INFO:Starting cross validation
2024-08-22 21:13:46,362:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-08-22 21:14:18,639:INFO:Calculating mean and std
2024-08-22 21:14:18,642:INFO:Creating metrics dataframe
2024-08-22 21:14:18,646:INFO:Uploading results into container
2024-08-22 21:14:18,647:INFO:Uploading model into container now
2024-08-22 21:14:18,648:INFO:_master_model_container: 10
2024-08-22 21:14:18,649:INFO:_display_container: 2
2024-08-22 21:14:18,650:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1909, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-08-22 21:14:18,650:INFO:create_model() successfully completed......................................
2024-08-22 21:14:18,868:INFO:SubProcess create_model() end ==================================
2024-08-22 21:14:18,869:INFO:Creating metrics dataframe
2024-08-22 21:14:18,895:INFO:Initializing Linear Discriminant Analysis
2024-08-22 21:14:18,896:INFO:Total runtime is 1.5426296591758728 minutes
2024-08-22 21:14:18,903:INFO:SubProcess create_model() called ==================================
2024-08-22 21:14:18,904:INFO:Initializing create_model()
2024-08-22 21:14:18,905:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025211643190>, estimator=lda, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025211517010>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-22 21:14:18,905:INFO:Checking exceptions
2024-08-22 21:14:18,905:INFO:Importing libraries
2024-08-22 21:14:18,905:INFO:Copying training dataset
2024-08-22 21:14:18,934:INFO:Defining folds
2024-08-22 21:14:18,934:INFO:Declaring metric variables
2024-08-22 21:14:18,941:INFO:Importing untrained model
2024-08-22 21:14:18,949:INFO:Linear Discriminant Analysis Imported successfully
2024-08-22 21:14:18,964:INFO:Starting cross validation
2024-08-22 21:14:18,970:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-08-22 21:14:21,584:INFO:Calculating mean and std
2024-08-22 21:14:21,586:INFO:Creating metrics dataframe
2024-08-22 21:14:21,591:INFO:Uploading results into container
2024-08-22 21:14:21,592:INFO:Uploading model into container now
2024-08-22 21:14:21,593:INFO:_master_model_container: 11
2024-08-22 21:14:21,594:INFO:_display_container: 2
2024-08-22 21:14:21,594:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-08-22 21:14:21,595:INFO:create_model() successfully completed......................................
2024-08-22 21:14:21,817:INFO:SubProcess create_model() end ==================================
2024-08-22 21:14:21,818:INFO:Creating metrics dataframe
2024-08-22 21:14:21,841:INFO:Initializing Extra Trees Classifier
2024-08-22 21:14:21,842:INFO:Total runtime is 1.5917251626650493 minutes
2024-08-22 21:14:21,849:INFO:SubProcess create_model() called ==================================
2024-08-22 21:14:21,850:INFO:Initializing create_model()
2024-08-22 21:14:21,850:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025211643190>, estimator=et, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025211517010>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-22 21:14:21,851:INFO:Checking exceptions
2024-08-22 21:14:21,851:INFO:Importing libraries
2024-08-22 21:14:21,851:INFO:Copying training dataset
2024-08-22 21:14:21,872:INFO:Defining folds
2024-08-22 21:14:21,872:INFO:Declaring metric variables
2024-08-22 21:14:21,877:INFO:Importing untrained model
2024-08-22 21:14:21,886:INFO:Extra Trees Classifier Imported successfully
2024-08-22 21:14:21,899:INFO:Starting cross validation
2024-08-22 21:14:21,904:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-08-22 21:14:28,950:INFO:Calculating mean and std
2024-08-22 21:14:28,953:INFO:Creating metrics dataframe
2024-08-22 21:14:28,960:INFO:Uploading results into container
2024-08-22 21:14:28,962:INFO:Uploading model into container now
2024-08-22 21:14:28,964:INFO:_master_model_container: 12
2024-08-22 21:14:28,964:INFO:_display_container: 2
2024-08-22 21:14:28,965:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=1909, verbose=0,
                     warm_start=False)
2024-08-22 21:14:28,966:INFO:create_model() successfully completed......................................
2024-08-22 21:14:29,197:INFO:SubProcess create_model() end ==================================
2024-08-22 21:14:29,199:INFO:Creating metrics dataframe
2024-08-22 21:14:29,224:INFO:Initializing Light Gradient Boosting Machine
2024-08-22 21:14:29,224:INFO:Total runtime is 1.714755940437317 minutes
2024-08-22 21:14:29,232:INFO:SubProcess create_model() called ==================================
2024-08-22 21:14:29,233:INFO:Initializing create_model()
2024-08-22 21:14:29,233:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025211643190>, estimator=lightgbm, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025211517010>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-22 21:14:29,234:INFO:Checking exceptions
2024-08-22 21:14:29,234:INFO:Importing libraries
2024-08-22 21:14:29,234:INFO:Copying training dataset
2024-08-22 21:14:29,255:INFO:Defining folds
2024-08-22 21:14:29,256:INFO:Declaring metric variables
2024-08-22 21:14:29,263:INFO:Importing untrained model
2024-08-22 21:14:29,268:INFO:Light Gradient Boosting Machine Imported successfully
2024-08-22 21:14:29,285:INFO:Starting cross validation
2024-08-22 21:14:29,292:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-08-22 21:14:33,841:INFO:Calculating mean and std
2024-08-22 21:14:33,845:INFO:Creating metrics dataframe
2024-08-22 21:14:33,851:INFO:Uploading results into container
2024-08-22 21:14:33,852:INFO:Uploading model into container now
2024-08-22 21:14:33,853:INFO:_master_model_container: 13
2024-08-22 21:14:33,854:INFO:_display_container: 2
2024-08-22 21:14:33,854:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1909, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-08-22 21:14:33,855:INFO:create_model() successfully completed......................................
2024-08-22 21:14:34,077:INFO:SubProcess create_model() end ==================================
2024-08-22 21:14:34,077:INFO:Creating metrics dataframe
2024-08-22 21:14:34,106:INFO:Initializing Dummy Classifier
2024-08-22 21:14:34,107:INFO:Total runtime is 1.796149758497874 minutes
2024-08-22 21:14:34,117:INFO:SubProcess create_model() called ==================================
2024-08-22 21:14:34,118:INFO:Initializing create_model()
2024-08-22 21:14:34,118:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025211643190>, estimator=dummy, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025211517010>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-22 21:14:34,118:INFO:Checking exceptions
2024-08-22 21:14:34,118:INFO:Importing libraries
2024-08-22 21:14:34,119:INFO:Copying training dataset
2024-08-22 21:14:34,143:INFO:Defining folds
2024-08-22 21:14:34,144:INFO:Declaring metric variables
2024-08-22 21:14:34,153:INFO:Importing untrained model
2024-08-22 21:14:34,161:INFO:Dummy Classifier Imported successfully
2024-08-22 21:14:34,178:INFO:Starting cross validation
2024-08-22 21:14:34,185:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-08-22 21:14:36,125:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-22 21:14:36,125:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-22 21:14:36,177:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-22 21:14:36,283:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-22 21:14:36,309:INFO:Calculating mean and std
2024-08-22 21:14:36,311:INFO:Creating metrics dataframe
2024-08-22 21:14:36,315:INFO:Uploading results into container
2024-08-22 21:14:36,317:INFO:Uploading model into container now
2024-08-22 21:14:36,318:INFO:_master_model_container: 14
2024-08-22 21:14:36,318:INFO:_display_container: 2
2024-08-22 21:14:36,319:INFO:DummyClassifier(constant=None, random_state=1909, strategy='prior')
2024-08-22 21:14:36,319:INFO:create_model() successfully completed......................................
2024-08-22 21:14:36,548:INFO:SubProcess create_model() end ==================================
2024-08-22 21:14:36,548:INFO:Creating metrics dataframe
2024-08-22 21:14:36,597:INFO:Initializing create_model()
2024-08-22 21:14:36,597:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025211643190>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1909, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-22 21:14:36,597:INFO:Checking exceptions
2024-08-22 21:14:36,601:INFO:Importing libraries
2024-08-22 21:14:36,601:INFO:Copying training dataset
2024-08-22 21:14:36,639:INFO:Defining folds
2024-08-22 21:14:36,640:INFO:Declaring metric variables
2024-08-22 21:14:36,640:INFO:Importing untrained model
2024-08-22 21:14:36,640:INFO:Declaring custom model
2024-08-22 21:14:36,642:INFO:Gradient Boosting Classifier Imported successfully
2024-08-22 21:14:36,647:INFO:Cross validation set to False
2024-08-22 21:14:36,647:INFO:Fitting Model
2024-08-22 21:15:11,088:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1909, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-08-22 21:15:11,088:INFO:create_model() successfully completed......................................
2024-08-22 21:15:11,402:INFO:_master_model_container: 14
2024-08-22 21:15:11,403:INFO:_display_container: 2
2024-08-22 21:15:11,404:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1909, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-08-22 21:15:11,404:INFO:compare_models() successfully completed......................................
2024-08-22 21:15:11,415:INFO:Initializing plot_model()
2024-08-22 21:15:11,415:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025211643190>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1909, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-08-22 21:15:11,416:INFO:Checking exceptions
2024-08-22 21:15:11,432:INFO:Preloading libraries
2024-08-22 21:15:11,454:INFO:Copying training dataset
2024-08-22 21:15:11,454:INFO:Plot type: feature
2024-08-22 21:15:11,455:WARNING:No coef_ found. Trying feature_importances_
2024-08-22 21:15:11,977:INFO:Visual Rendered Successfully
2024-08-22 21:15:12,196:INFO:plot_model() successfully completed......................................
2024-08-22 21:15:12,210:INFO:Initializing plot_model()
2024-08-22 21:15:12,211:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025211643190>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1909, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-08-22 21:15:12,211:INFO:Checking exceptions
2024-08-22 21:15:12,227:INFO:Preloading libraries
2024-08-22 21:15:12,244:INFO:Copying training dataset
2024-08-22 21:15:12,244:INFO:Plot type: auc
2024-08-22 21:15:12,586:INFO:Fitting Model
2024-08-22 21:15:12,590:INFO:Scoring test/hold-out set
2024-08-22 21:15:13,214:INFO:Visual Rendered Successfully
2024-08-22 21:15:13,425:INFO:plot_model() successfully completed......................................
2024-08-22 21:15:13,531:INFO:Initializing save_model()
2024-08-22 21:15:13,532:INFO:save_model(model=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1909, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), model_name=LR Model Aula 5 062022, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\natha\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean')...
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=QuantileTransformer(copy=True,
                                                                    ignore_implicit_zeros=False,
                                                                    n_quantiles=1000,
                                                                    output_distribution='normal',
                                                                    random_state=1909,
                                                                    subsample=10000))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-08-22 21:15:13,532:INFO:Adding model into prep_pipe
2024-08-22 21:15:13,574:INFO:LR Model Aula 5 062022.pkl saved in current working directory
2024-08-22 21:15:13,665:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWra...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.1, loss='log_loss',
                                            max_depth=3, max_features=None,
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.0,
                                            min_samples_leaf=1,
                                            min_samples_split=2,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=100,
                                            n_iter_no_change=None,
                                            random_state=1909, subsample=1.0,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2024-08-22 21:15:13,666:INFO:save_model() successfully completed......................................
2024-08-22 21:15:13,985:INFO:Initializing load_model()
2024-08-22 21:15:13,986:INFO:load_model(model_name=LR Model Aula 5 062022, platform=None, authentication=None, verbose=True)
2024-08-22 21:15:14,103:INFO:PyCaret ClassificationExperiment
2024-08-22 21:15:14,103:INFO:Logging name: clf-default-name
2024-08-22 21:15:14,103:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-08-22 21:15:14,103:INFO:version 3.3.2
2024-08-22 21:15:14,103:INFO:Initializing setup()
2024-08-22 21:15:14,104:INFO:self.USI: 4212
2024-08-22 21:15:14,104:INFO:self._variable_keys: {'log_plots_param', 'memory', 'gpu_param', 'seed', 'X_train', 'USI', 'fold_generator', '_available_plots', 'fold_shuffle_param', 'X', 'pipeline', 'y_train', 'exp_name_log', 'fix_imbalance', 'gpu_n_jobs_param', 'y', 'data', '_ml_usecase', 'target_param', 'exp_id', 'idx', 'y_test', 'logging_param', 'n_jobs_param', 'fold_groups_param', 'is_multiclass', 'html_param', 'X_test'}
2024-08-22 21:15:14,104:INFO:Checking environment
2024-08-22 21:15:14,104:INFO:python_version: 3.11.5
2024-08-22 21:15:14,104:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-08-22 21:15:14,104:INFO:machine: AMD64
2024-08-22 21:15:14,104:INFO:platform: Windows-10-10.0.22631-SP0
2024-08-22 21:15:14,105:INFO:Memory: svmem(total=8311836672, available=1312190464, percent=84.2, used=6999646208, free=1312190464)
2024-08-22 21:15:14,105:INFO:Physical Core: 4
2024-08-22 21:15:14,105:INFO:Logical Core: 8
2024-08-22 21:15:14,105:INFO:Checking libraries
2024-08-22 21:15:14,105:INFO:System:
2024-08-22 21:15:14,105:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-08-22 21:15:14,105:INFO:executable: C:\Users\natha\anaconda3\python.exe
2024-08-22 21:15:14,105:INFO:   machine: Windows-10-10.0.22631-SP0
2024-08-22 21:15:14,105:INFO:PyCaret required dependencies:
2024-08-22 21:15:14,106:INFO:                 pip: 23.2.1
2024-08-22 21:15:14,106:INFO:          setuptools: 68.0.0
2024-08-22 21:15:14,106:INFO:             pycaret: 3.3.2
2024-08-22 21:15:14,106:INFO:             IPython: 8.15.0
2024-08-22 21:15:14,106:INFO:          ipywidgets: 8.0.4
2024-08-22 21:15:14,106:INFO:                tqdm: 4.65.0
2024-08-22 21:15:14,106:INFO:               numpy: 1.24.3
2024-08-22 21:15:14,106:INFO:              pandas: 2.0.3
2024-08-22 21:15:14,106:INFO:              jinja2: 3.1.2
2024-08-22 21:15:14,107:INFO:               scipy: 1.11.1
2024-08-22 21:15:14,107:INFO:              joblib: 1.3.2
2024-08-22 21:15:14,107:INFO:             sklearn: 1.4.2
2024-08-22 21:15:14,107:INFO:                pyod: 2.0.1
2024-08-22 21:15:14,107:INFO:            imblearn: 0.12.3
2024-08-22 21:15:14,107:INFO:   category_encoders: 2.6.3
2024-08-22 21:15:14,107:INFO:            lightgbm: 4.5.0
2024-08-22 21:15:14,107:INFO:               numba: 0.57.1
2024-08-22 21:15:14,107:INFO:            requests: 2.31.0
2024-08-22 21:15:14,107:INFO:          matplotlib: 3.7.2
2024-08-22 21:15:14,108:INFO:          scikitplot: 0.3.7
2024-08-22 21:15:14,108:INFO:         yellowbrick: 1.5
2024-08-22 21:15:14,108:INFO:              plotly: 5.23.0
2024-08-22 21:15:14,108:INFO:    plotly-resampler: Not installed
2024-08-22 21:15:14,108:INFO:             kaleido: 0.2.1
2024-08-22 21:15:14,108:INFO:           schemdraw: 0.15
2024-08-22 21:15:14,108:INFO:         statsmodels: 0.14.0
2024-08-22 21:15:14,108:INFO:              sktime: 0.26.0
2024-08-22 21:15:14,109:INFO:               tbats: 1.1.3
2024-08-22 21:15:14,109:INFO:            pmdarima: 2.0.4
2024-08-22 21:15:14,109:INFO:              psutil: 5.9.0
2024-08-22 21:15:14,109:INFO:          markupsafe: 2.1.1
2024-08-22 21:15:14,109:INFO:             pickle5: Not installed
2024-08-22 21:15:14,109:INFO:         cloudpickle: 2.2.1
2024-08-22 21:15:14,109:INFO:         deprecation: 2.1.0
2024-08-22 21:15:14,109:INFO:              xxhash: 2.0.2
2024-08-22 21:15:14,109:INFO:           wurlitzer: Not installed
2024-08-22 21:15:14,110:INFO:PyCaret optional dependencies:
2024-08-22 21:15:14,110:INFO:                shap: Not installed
2024-08-22 21:15:14,110:INFO:           interpret: Not installed
2024-08-22 21:15:14,110:INFO:                umap: Not installed
2024-08-22 21:15:14,110:INFO:     ydata_profiling: 4.7.0
2024-08-22 21:15:14,110:INFO:  explainerdashboard: Not installed
2024-08-22 21:15:14,110:INFO:             autoviz: Not installed
2024-08-22 21:15:14,110:INFO:           fairlearn: Not installed
2024-08-22 21:15:14,110:INFO:          deepchecks: Not installed
2024-08-22 21:15:14,111:INFO:             xgboost: Not installed
2024-08-22 21:15:14,111:INFO:            catboost: Not installed
2024-08-22 21:15:14,111:INFO:              kmodes: Not installed
2024-08-22 21:15:14,111:INFO:             mlxtend: Not installed
2024-08-22 21:15:14,111:INFO:       statsforecast: Not installed
2024-08-22 21:15:14,111:INFO:        tune_sklearn: Not installed
2024-08-22 21:15:14,111:INFO:                 ray: Not installed
2024-08-22 21:15:14,111:INFO:            hyperopt: Not installed
2024-08-22 21:15:14,111:INFO:              optuna: Not installed
2024-08-22 21:15:14,112:INFO:               skopt: Not installed
2024-08-22 21:15:14,112:INFO:              mlflow: Not installed
2024-08-22 21:15:14,112:INFO:              gradio: Not installed
2024-08-22 21:15:14,112:INFO:             fastapi: Not installed
2024-08-22 21:15:14,112:INFO:             uvicorn: Not installed
2024-08-22 21:15:14,112:INFO:              m2cgen: Not installed
2024-08-22 21:15:14,112:INFO:           evidently: Not installed
2024-08-22 21:15:14,112:INFO:               fugue: Not installed
2024-08-22 21:15:14,112:INFO:           streamlit: Not installed
2024-08-22 21:15:14,112:INFO:             prophet: Not installed
2024-08-22 21:15:14,113:INFO:None
2024-08-22 21:15:14,113:INFO:Set up data.
2024-08-22 21:15:54,590:INFO:PyCaret ClassificationExperiment
2024-08-22 21:15:54,590:INFO:Logging name: clf-default-name
2024-08-22 21:15:54,590:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-08-22 21:15:54,590:INFO:version 3.3.2
2024-08-22 21:15:54,591:INFO:Initializing setup()
2024-08-22 21:15:54,591:INFO:self.USI: 1d9b
2024-08-22 21:15:54,591:INFO:self._variable_keys: {'log_plots_param', 'memory', 'gpu_param', 'seed', 'X_train', 'USI', 'fold_generator', '_available_plots', 'fold_shuffle_param', 'X', 'pipeline', 'y_train', 'exp_name_log', 'fix_imbalance', 'gpu_n_jobs_param', 'y', 'data', '_ml_usecase', 'target_param', 'exp_id', 'idx', 'y_test', 'logging_param', 'n_jobs_param', 'fold_groups_param', 'is_multiclass', 'html_param', 'X_test'}
2024-08-22 21:15:54,591:INFO:Checking environment
2024-08-22 21:15:54,591:INFO:python_version: 3.11.5
2024-08-22 21:15:54,591:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-08-22 21:15:54,591:INFO:machine: AMD64
2024-08-22 21:15:54,591:INFO:platform: Windows-10-10.0.22631-SP0
2024-08-22 21:15:54,592:INFO:Memory: svmem(total=8311836672, available=1099898880, percent=86.8, used=7211937792, free=1099898880)
2024-08-22 21:15:54,592:INFO:Physical Core: 4
2024-08-22 21:15:54,592:INFO:Logical Core: 8
2024-08-22 21:15:54,592:INFO:Checking libraries
2024-08-22 21:15:54,592:INFO:System:
2024-08-22 21:15:54,592:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-08-22 21:15:54,592:INFO:executable: C:\Users\natha\anaconda3\python.exe
2024-08-22 21:15:54,593:INFO:   machine: Windows-10-10.0.22631-SP0
2024-08-22 21:15:54,593:INFO:PyCaret required dependencies:
2024-08-22 21:15:54,593:INFO:                 pip: 23.2.1
2024-08-22 21:15:54,593:INFO:          setuptools: 68.0.0
2024-08-22 21:15:54,593:INFO:             pycaret: 3.3.2
2024-08-22 21:15:54,593:INFO:             IPython: 8.15.0
2024-08-22 21:15:54,593:INFO:          ipywidgets: 8.0.4
2024-08-22 21:15:54,593:INFO:                tqdm: 4.65.0
2024-08-22 21:15:54,594:INFO:               numpy: 1.24.3
2024-08-22 21:15:54,594:INFO:              pandas: 2.0.3
2024-08-22 21:15:54,594:INFO:              jinja2: 3.1.2
2024-08-22 21:15:54,594:INFO:               scipy: 1.11.1
2024-08-22 21:15:54,594:INFO:              joblib: 1.3.2
2024-08-22 21:15:54,594:INFO:             sklearn: 1.4.2
2024-08-22 21:15:54,594:INFO:                pyod: 2.0.1
2024-08-22 21:15:54,594:INFO:            imblearn: 0.12.3
2024-08-22 21:15:54,594:INFO:   category_encoders: 2.6.3
2024-08-22 21:15:54,594:INFO:            lightgbm: 4.5.0
2024-08-22 21:15:54,595:INFO:               numba: 0.57.1
2024-08-22 21:15:54,595:INFO:            requests: 2.31.0
2024-08-22 21:15:54,595:INFO:          matplotlib: 3.7.2
2024-08-22 21:15:54,595:INFO:          scikitplot: 0.3.7
2024-08-22 21:15:54,595:INFO:         yellowbrick: 1.5
2024-08-22 21:15:54,595:INFO:              plotly: 5.23.0
2024-08-22 21:15:54,595:INFO:    plotly-resampler: Not installed
2024-08-22 21:15:54,595:INFO:             kaleido: 0.2.1
2024-08-22 21:15:54,595:INFO:           schemdraw: 0.15
2024-08-22 21:15:54,596:INFO:         statsmodels: 0.14.0
2024-08-22 21:15:54,596:INFO:              sktime: 0.26.0
2024-08-22 21:15:54,596:INFO:               tbats: 1.1.3
2024-08-22 21:15:54,596:INFO:            pmdarima: 2.0.4
2024-08-22 21:15:54,596:INFO:              psutil: 5.9.0
2024-08-22 21:15:54,596:INFO:          markupsafe: 2.1.1
2024-08-22 21:15:54,596:INFO:             pickle5: Not installed
2024-08-22 21:15:54,596:INFO:         cloudpickle: 2.2.1
2024-08-22 21:15:54,596:INFO:         deprecation: 2.1.0
2024-08-22 21:15:54,597:INFO:              xxhash: 2.0.2
2024-08-22 21:15:54,597:INFO:           wurlitzer: Not installed
2024-08-22 21:15:54,597:INFO:PyCaret optional dependencies:
2024-08-22 21:15:54,597:INFO:                shap: Not installed
2024-08-22 21:15:54,597:INFO:           interpret: Not installed
2024-08-22 21:15:54,597:INFO:                umap: Not installed
2024-08-22 21:15:54,597:INFO:     ydata_profiling: 4.7.0
2024-08-22 21:15:54,597:INFO:  explainerdashboard: Not installed
2024-08-22 21:15:54,598:INFO:             autoviz: Not installed
2024-08-22 21:15:54,598:INFO:           fairlearn: Not installed
2024-08-22 21:15:54,598:INFO:          deepchecks: Not installed
2024-08-22 21:15:54,598:INFO:             xgboost: Not installed
2024-08-22 21:15:54,598:INFO:            catboost: Not installed
2024-08-22 21:15:54,598:INFO:              kmodes: Not installed
2024-08-22 21:15:54,598:INFO:             mlxtend: Not installed
2024-08-22 21:15:54,598:INFO:       statsforecast: Not installed
2024-08-22 21:15:54,599:INFO:        tune_sklearn: Not installed
2024-08-22 21:15:54,599:INFO:                 ray: Not installed
2024-08-22 21:15:54,599:INFO:            hyperopt: Not installed
2024-08-22 21:15:54,599:INFO:              optuna: Not installed
2024-08-22 21:15:54,599:INFO:               skopt: Not installed
2024-08-22 21:15:54,599:INFO:              mlflow: Not installed
2024-08-22 21:15:54,599:INFO:              gradio: Not installed
2024-08-22 21:15:54,599:INFO:             fastapi: Not installed
2024-08-22 21:15:54,599:INFO:             uvicorn: Not installed
2024-08-22 21:15:54,599:INFO:              m2cgen: Not installed
2024-08-22 21:15:54,600:INFO:           evidently: Not installed
2024-08-22 21:15:54,600:INFO:               fugue: Not installed
2024-08-22 21:15:54,600:INFO:           streamlit: Not installed
2024-08-22 21:15:54,600:INFO:             prophet: Not installed
2024-08-22 21:15:54,600:INFO:None
2024-08-22 21:15:54,600:INFO:Set up data.
2024-08-22 21:17:11,125:INFO:PyCaret ClassificationExperiment
2024-08-22 21:17:11,125:INFO:Logging name: clf-default-name
2024-08-22 21:17:11,125:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-08-22 21:17:11,125:INFO:version 3.3.2
2024-08-22 21:17:11,125:INFO:Initializing setup()
2024-08-22 21:17:11,125:INFO:self.USI: 02bf
2024-08-22 21:17:11,126:INFO:self._variable_keys: {'log_plots_param', 'memory', 'gpu_param', 'seed', 'X_train', 'USI', 'fold_generator', '_available_plots', 'fold_shuffle_param', 'X', 'pipeline', 'y_train', 'exp_name_log', 'fix_imbalance', 'gpu_n_jobs_param', 'y', 'data', '_ml_usecase', 'target_param', 'exp_id', 'idx', 'y_test', 'logging_param', 'n_jobs_param', 'fold_groups_param', 'is_multiclass', 'html_param', 'X_test'}
2024-08-22 21:17:11,126:INFO:Checking environment
2024-08-22 21:17:11,126:INFO:python_version: 3.11.5
2024-08-22 21:17:11,126:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-08-22 21:17:11,126:INFO:machine: AMD64
2024-08-22 21:17:11,126:INFO:platform: Windows-10-10.0.22631-SP0
2024-08-22 21:17:11,126:INFO:Memory: svmem(total=8311836672, available=586706944, percent=92.9, used=7725129728, free=586706944)
2024-08-22 21:17:11,127:INFO:Physical Core: 4
2024-08-22 21:17:11,127:INFO:Logical Core: 8
2024-08-22 21:17:11,127:INFO:Checking libraries
2024-08-22 21:17:11,127:INFO:System:
2024-08-22 21:17:11,127:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-08-22 21:17:11,128:INFO:executable: C:\Users\natha\anaconda3\python.exe
2024-08-22 21:17:11,128:INFO:   machine: Windows-10-10.0.22631-SP0
2024-08-22 21:17:11,128:INFO:PyCaret required dependencies:
2024-08-22 21:17:11,128:INFO:                 pip: 23.2.1
2024-08-22 21:17:11,128:INFO:          setuptools: 68.0.0
2024-08-22 21:17:11,128:INFO:             pycaret: 3.3.2
2024-08-22 21:17:11,129:INFO:             IPython: 8.15.0
2024-08-22 21:17:11,129:INFO:          ipywidgets: 8.0.4
2024-08-22 21:17:11,129:INFO:                tqdm: 4.65.0
2024-08-22 21:17:11,129:INFO:               numpy: 1.24.3
2024-08-22 21:17:11,129:INFO:              pandas: 2.0.3
2024-08-22 21:17:11,129:INFO:              jinja2: 3.1.2
2024-08-22 21:17:11,129:INFO:               scipy: 1.11.1
2024-08-22 21:17:11,129:INFO:              joblib: 1.3.2
2024-08-22 21:17:11,129:INFO:             sklearn: 1.4.2
2024-08-22 21:17:11,130:INFO:                pyod: 2.0.1
2024-08-22 21:17:11,130:INFO:            imblearn: 0.12.3
2024-08-22 21:17:11,130:INFO:   category_encoders: 2.6.3
2024-08-22 21:17:11,130:INFO:            lightgbm: 4.5.0
2024-08-22 21:17:11,130:INFO:               numba: 0.57.1
2024-08-22 21:17:11,130:INFO:            requests: 2.31.0
2024-08-22 21:17:11,130:INFO:          matplotlib: 3.7.2
2024-08-22 21:17:11,130:INFO:          scikitplot: 0.3.7
2024-08-22 21:17:11,130:INFO:         yellowbrick: 1.5
2024-08-22 21:17:11,131:INFO:              plotly: 5.23.0
2024-08-22 21:17:11,131:INFO:    plotly-resampler: Not installed
2024-08-22 21:17:11,131:INFO:             kaleido: 0.2.1
2024-08-22 21:17:11,131:INFO:           schemdraw: 0.15
2024-08-22 21:17:11,131:INFO:         statsmodels: 0.14.0
2024-08-22 21:17:11,131:INFO:              sktime: 0.26.0
2024-08-22 21:17:11,131:INFO:               tbats: 1.1.3
2024-08-22 21:17:11,131:INFO:            pmdarima: 2.0.4
2024-08-22 21:17:11,131:INFO:              psutil: 5.9.0
2024-08-22 21:17:11,132:INFO:          markupsafe: 2.1.1
2024-08-22 21:17:11,132:INFO:             pickle5: Not installed
2024-08-22 21:17:11,132:INFO:         cloudpickle: 2.2.1
2024-08-22 21:17:11,132:INFO:         deprecation: 2.1.0
2024-08-22 21:17:11,132:INFO:              xxhash: 2.0.2
2024-08-22 21:17:11,132:INFO:           wurlitzer: Not installed
2024-08-22 21:17:11,132:INFO:PyCaret optional dependencies:
2024-08-22 21:17:11,132:INFO:                shap: Not installed
2024-08-22 21:17:11,133:INFO:           interpret: Not installed
2024-08-22 21:17:11,133:INFO:                umap: Not installed
2024-08-22 21:17:11,133:INFO:     ydata_profiling: 4.7.0
2024-08-22 21:17:11,133:INFO:  explainerdashboard: Not installed
2024-08-22 21:17:11,133:INFO:             autoviz: Not installed
2024-08-22 21:17:11,133:INFO:           fairlearn: Not installed
2024-08-22 21:17:11,133:INFO:          deepchecks: Not installed
2024-08-22 21:17:11,133:INFO:             xgboost: Not installed
2024-08-22 21:17:11,134:INFO:            catboost: Not installed
2024-08-22 21:17:11,134:INFO:              kmodes: Not installed
2024-08-22 21:17:11,134:INFO:             mlxtend: Not installed
2024-08-22 21:17:11,134:INFO:       statsforecast: Not installed
2024-08-22 21:17:11,134:INFO:        tune_sklearn: Not installed
2024-08-22 21:17:11,134:INFO:                 ray: Not installed
2024-08-22 21:17:11,134:INFO:            hyperopt: Not installed
2024-08-22 21:17:11,134:INFO:              optuna: Not installed
2024-08-22 21:17:11,134:INFO:               skopt: Not installed
2024-08-22 21:17:11,135:INFO:              mlflow: Not installed
2024-08-22 21:17:11,135:INFO:              gradio: Not installed
2024-08-22 21:17:11,135:INFO:             fastapi: Not installed
2024-08-22 21:17:11,135:INFO:             uvicorn: Not installed
2024-08-22 21:17:11,135:INFO:              m2cgen: Not installed
2024-08-22 21:17:11,135:INFO:           evidently: Not installed
2024-08-22 21:17:11,135:INFO:               fugue: Not installed
2024-08-22 21:17:11,135:INFO:           streamlit: Not installed
2024-08-22 21:17:11,136:INFO:             prophet: Not installed
2024-08-22 21:17:11,136:INFO:None
2024-08-22 21:17:11,136:INFO:Set up data.
2024-08-22 21:22:44,535:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-22 21:22:44,536:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-22 21:22:44,536:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-22 21:22:44,536:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-22 21:22:47,316:INFO:PyCaret ClassificationExperiment
2024-08-22 21:22:47,317:INFO:Logging name: clf-default-name
2024-08-22 21:22:47,317:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-08-22 21:22:47,317:INFO:version 3.3.2
2024-08-22 21:22:47,317:INFO:Initializing setup()
2024-08-22 21:22:47,317:INFO:self.USI: 9834
2024-08-22 21:22:47,318:INFO:self._variable_keys: {'n_jobs_param', 'fold_generator', 'y_train', 'logging_param', 'html_param', 'is_multiclass', 'fix_imbalance', 'gpu_param', 'log_plots_param', 'fold_groups_param', 'data', 'X_test', 'exp_name_log', 'memory', 'fold_shuffle_param', '_ml_usecase', 'seed', 'pipeline', '_available_plots', 'exp_id', 'target_param', 'y', 'y_test', 'X', 'idx', 'USI', 'X_train', 'gpu_n_jobs_param'}
2024-08-22 21:22:47,318:INFO:Checking environment
2024-08-22 21:22:47,318:INFO:python_version: 3.11.5
2024-08-22 21:22:47,318:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-08-22 21:22:47,318:INFO:machine: AMD64
2024-08-22 21:22:47,318:INFO:platform: Windows-10-10.0.22631-SP0
2024-08-22 21:22:47,318:INFO:Memory: svmem(total=8311836672, available=2247819264, percent=73.0, used=6064017408, free=2247819264)
2024-08-22 21:22:47,319:INFO:Physical Core: 4
2024-08-22 21:22:47,319:INFO:Logical Core: 8
2024-08-22 21:22:47,319:INFO:Checking libraries
2024-08-22 21:22:47,319:INFO:System:
2024-08-22 21:22:47,319:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-08-22 21:22:47,319:INFO:executable: C:\Users\natha\anaconda3\python.exe
2024-08-22 21:22:47,319:INFO:   machine: Windows-10-10.0.22631-SP0
2024-08-22 21:22:47,319:INFO:PyCaret required dependencies:
2024-08-22 21:22:49,692:INFO:                 pip: 23.2.1
2024-08-22 21:22:49,692:INFO:          setuptools: 68.0.0
2024-08-22 21:22:49,693:INFO:             pycaret: 3.3.2
2024-08-22 21:22:49,693:INFO:             IPython: 8.15.0
2024-08-22 21:22:49,693:INFO:          ipywidgets: 8.0.4
2024-08-22 21:22:49,693:INFO:                tqdm: 4.65.0
2024-08-22 21:22:49,693:INFO:               numpy: 1.24.3
2024-08-22 21:22:49,693:INFO:              pandas: 2.0.3
2024-08-22 21:22:49,693:INFO:              jinja2: 3.1.2
2024-08-22 21:22:49,693:INFO:               scipy: 1.11.1
2024-08-22 21:22:49,693:INFO:              joblib: 1.3.2
2024-08-22 21:22:49,693:INFO:             sklearn: 1.4.2
2024-08-22 21:22:49,694:INFO:                pyod: 2.0.1
2024-08-22 21:22:49,694:INFO:            imblearn: 0.12.3
2024-08-22 21:22:49,694:INFO:   category_encoders: 2.6.3
2024-08-22 21:22:49,694:INFO:            lightgbm: 4.5.0
2024-08-22 21:22:49,694:INFO:               numba: 0.57.1
2024-08-22 21:22:49,694:INFO:            requests: 2.31.0
2024-08-22 21:22:49,694:INFO:          matplotlib: 3.7.2
2024-08-22 21:22:49,694:INFO:          scikitplot: 0.3.7
2024-08-22 21:22:49,694:INFO:         yellowbrick: 1.5
2024-08-22 21:22:49,694:INFO:              plotly: 5.23.0
2024-08-22 21:22:49,694:INFO:    plotly-resampler: Not installed
2024-08-22 21:22:49,694:INFO:             kaleido: 0.2.1
2024-08-22 21:22:49,695:INFO:           schemdraw: 0.15
2024-08-22 21:22:49,695:INFO:         statsmodels: 0.14.0
2024-08-22 21:22:49,695:INFO:              sktime: 0.26.0
2024-08-22 21:22:49,695:INFO:               tbats: 1.1.3
2024-08-22 21:22:49,695:INFO:            pmdarima: 2.0.4
2024-08-22 21:22:49,695:INFO:              psutil: 5.9.0
2024-08-22 21:22:49,695:INFO:          markupsafe: 2.1.1
2024-08-22 21:22:49,696:INFO:             pickle5: Not installed
2024-08-22 21:22:49,696:INFO:         cloudpickle: 2.2.1
2024-08-22 21:22:49,696:INFO:         deprecation: 2.1.0
2024-08-22 21:22:49,696:INFO:              xxhash: 2.0.2
2024-08-22 21:22:49,697:INFO:           wurlitzer: Not installed
2024-08-22 21:22:49,697:INFO:PyCaret optional dependencies:
2024-08-22 21:22:49,729:INFO:                shap: Not installed
2024-08-22 21:22:49,729:INFO:           interpret: Not installed
2024-08-22 21:22:49,729:INFO:                umap: Not installed
2024-08-22 21:22:49,729:INFO:     ydata_profiling: 4.7.0
2024-08-22 21:22:49,729:INFO:  explainerdashboard: Not installed
2024-08-22 21:22:49,729:INFO:             autoviz: Not installed
2024-08-22 21:22:49,729:INFO:           fairlearn: Not installed
2024-08-22 21:22:49,730:INFO:          deepchecks: Not installed
2024-08-22 21:22:49,730:INFO:             xgboost: Not installed
2024-08-22 21:22:49,730:INFO:            catboost: Not installed
2024-08-22 21:22:49,730:INFO:              kmodes: Not installed
2024-08-22 21:22:49,730:INFO:             mlxtend: Not installed
2024-08-22 21:22:49,730:INFO:       statsforecast: Not installed
2024-08-22 21:22:49,730:INFO:        tune_sklearn: Not installed
2024-08-22 21:22:49,730:INFO:                 ray: Not installed
2024-08-22 21:22:49,730:INFO:            hyperopt: Not installed
2024-08-22 21:22:49,731:INFO:              optuna: Not installed
2024-08-22 21:22:49,731:INFO:               skopt: Not installed
2024-08-22 21:22:49,731:INFO:              mlflow: Not installed
2024-08-22 21:22:49,731:INFO:              gradio: Not installed
2024-08-22 21:22:49,731:INFO:             fastapi: Not installed
2024-08-22 21:22:49,731:INFO:             uvicorn: Not installed
2024-08-22 21:22:49,731:INFO:              m2cgen: Not installed
2024-08-22 21:22:49,731:INFO:           evidently: Not installed
2024-08-22 21:22:49,731:INFO:               fugue: Not installed
2024-08-22 21:22:49,731:INFO:           streamlit: Not installed
2024-08-22 21:22:49,732:INFO:             prophet: Not installed
2024-08-22 21:22:49,732:INFO:None
2024-08-22 21:22:49,732:INFO:Set up data.
2024-08-22 21:22:49,802:INFO:Set up folding strategy.
2024-08-22 21:22:49,802:INFO:Set up train/test split.
2024-08-22 21:22:49,842:INFO:Set up index.
2024-08-22 21:22:49,844:INFO:Assigning column types.
2024-08-22 21:22:49,861:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-08-22 21:22:49,975:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-22 21:22:49,984:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-22 21:22:50,068:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:22:50,069:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:22:50,183:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-22 21:22:50,185:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-22 21:22:50,251:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:22:50,251:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:22:50,252:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-08-22 21:22:50,370:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-22 21:22:50,443:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:22:50,443:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:22:50,554:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-22 21:22:50,618:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:22:50,619:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:22:50,620:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-08-22 21:22:50,788:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:22:50,788:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:22:50,963:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:22:50,964:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:22:50,972:INFO:Preparing preprocessing pipeline...
2024-08-22 21:22:50,975:INFO:Set up simple imputation.
2024-08-22 21:22:50,994:INFO:Set up encoding of ordinal features.
2024-08-22 21:22:51,012:INFO:Set up encoding of categorical features.
2024-08-22 21:22:51,700:INFO:Finished creating preprocessing pipeline.
2024-08-22 21:22:51,795:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\natha\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean')...
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['tipo_renda', 'educacao',
                                             'estado_civil',
                                             'tipo_residencia'],
                                    transformer=OneHotEncoder(cols=['tipo_renda',
                                                                    'educacao',
                                                                    'estado_civil',
                                                                    'tipo_residencia'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2024-08-22 21:22:51,795:INFO:Creating final display dataframe.
2024-08-22 21:22:53,028:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target               mau
2                   Target type            Binary
3           Original data shape       (38000, 13)
4        Transformed data shape       (38000, 30)
5   Transformed train set shape       (26600, 30)
6    Transformed test set shape       (11400, 30)
7              Numeric features                 5
8          Categorical features                 7
9      Rows with missing values             16.9%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  clf-default-name
22                          USI              9834
2024-08-22 21:22:53,219:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:22:53,219:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:22:53,393:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:22:53,393:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:22:53,396:INFO:setup() successfully completed in 6.11s...............
2024-08-22 21:22:53,406:INFO:gpu_param set to False
2024-08-22 21:22:53,578:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:22:53,578:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:22:53,760:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:22:53,761:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:22:55,115:INFO:PyCaret ClassificationExperiment
2024-08-22 21:22:55,115:INFO:Logging name: credit_1
2024-08-22 21:22:55,116:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-08-22 21:22:55,116:INFO:version 3.3.2
2024-08-22 21:22:55,116:INFO:Initializing setup()
2024-08-22 21:22:55,116:INFO:self.USI: 87b7
2024-08-22 21:22:55,116:INFO:self._variable_keys: {'n_jobs_param', 'fold_generator', 'y_train', 'logging_param', 'html_param', 'is_multiclass', 'fix_imbalance', 'gpu_param', 'log_plots_param', 'fold_groups_param', 'data', 'X_test', 'exp_name_log', 'memory', 'fold_shuffle_param', '_ml_usecase', 'seed', 'pipeline', '_available_plots', 'exp_id', 'target_param', 'y', 'y_test', 'X', 'idx', 'USI', 'X_train', 'gpu_n_jobs_param'}
2024-08-22 21:22:55,116:INFO:Checking environment
2024-08-22 21:22:55,116:INFO:python_version: 3.11.5
2024-08-22 21:22:55,117:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-08-22 21:22:55,117:INFO:machine: AMD64
2024-08-22 21:22:55,117:INFO:platform: Windows-10-10.0.22631-SP0
2024-08-22 21:22:55,117:INFO:Memory: svmem(total=8311836672, available=2126278656, percent=74.4, used=6185558016, free=2126278656)
2024-08-22 21:22:55,117:INFO:Physical Core: 4
2024-08-22 21:22:55,117:INFO:Logical Core: 8
2024-08-22 21:22:55,117:INFO:Checking libraries
2024-08-22 21:22:55,118:INFO:System:
2024-08-22 21:22:55,118:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-08-22 21:22:55,118:INFO:executable: C:\Users\natha\anaconda3\python.exe
2024-08-22 21:22:55,118:INFO:   machine: Windows-10-10.0.22631-SP0
2024-08-22 21:22:55,118:INFO:PyCaret required dependencies:
2024-08-22 21:22:55,118:INFO:                 pip: 23.2.1
2024-08-22 21:22:55,118:INFO:          setuptools: 68.0.0
2024-08-22 21:22:55,118:INFO:             pycaret: 3.3.2
2024-08-22 21:22:55,119:INFO:             IPython: 8.15.0
2024-08-22 21:22:55,119:INFO:          ipywidgets: 8.0.4
2024-08-22 21:22:55,119:INFO:                tqdm: 4.65.0
2024-08-22 21:22:55,119:INFO:               numpy: 1.24.3
2024-08-22 21:22:55,119:INFO:              pandas: 2.0.3
2024-08-22 21:22:55,119:INFO:              jinja2: 3.1.2
2024-08-22 21:22:55,119:INFO:               scipy: 1.11.1
2024-08-22 21:22:55,119:INFO:              joblib: 1.3.2
2024-08-22 21:22:55,119:INFO:             sklearn: 1.4.2
2024-08-22 21:22:55,119:INFO:                pyod: 2.0.1
2024-08-22 21:22:55,120:INFO:            imblearn: 0.12.3
2024-08-22 21:22:55,120:INFO:   category_encoders: 2.6.3
2024-08-22 21:22:55,120:INFO:            lightgbm: 4.5.0
2024-08-22 21:22:55,120:INFO:               numba: 0.57.1
2024-08-22 21:22:55,120:INFO:            requests: 2.31.0
2024-08-22 21:22:55,120:INFO:          matplotlib: 3.7.2
2024-08-22 21:22:55,120:INFO:          scikitplot: 0.3.7
2024-08-22 21:22:55,120:INFO:         yellowbrick: 1.5
2024-08-22 21:22:55,120:INFO:              plotly: 5.23.0
2024-08-22 21:22:55,120:INFO:    plotly-resampler: Not installed
2024-08-22 21:22:55,121:INFO:             kaleido: 0.2.1
2024-08-22 21:22:55,121:INFO:           schemdraw: 0.15
2024-08-22 21:22:55,121:INFO:         statsmodels: 0.14.0
2024-08-22 21:22:55,121:INFO:              sktime: 0.26.0
2024-08-22 21:22:55,121:INFO:               tbats: 1.1.3
2024-08-22 21:22:55,121:INFO:            pmdarima: 2.0.4
2024-08-22 21:22:55,121:INFO:              psutil: 5.9.0
2024-08-22 21:22:55,121:INFO:          markupsafe: 2.1.1
2024-08-22 21:22:55,121:INFO:             pickle5: Not installed
2024-08-22 21:22:55,121:INFO:         cloudpickle: 2.2.1
2024-08-22 21:22:55,121:INFO:         deprecation: 2.1.0
2024-08-22 21:22:55,121:INFO:              xxhash: 2.0.2
2024-08-22 21:22:55,121:INFO:           wurlitzer: Not installed
2024-08-22 21:22:55,121:INFO:PyCaret optional dependencies:
2024-08-22 21:22:55,122:INFO:                shap: Not installed
2024-08-22 21:22:55,122:INFO:           interpret: Not installed
2024-08-22 21:22:55,122:INFO:                umap: Not installed
2024-08-22 21:22:55,122:INFO:     ydata_profiling: 4.7.0
2024-08-22 21:22:55,122:INFO:  explainerdashboard: Not installed
2024-08-22 21:22:55,122:INFO:             autoviz: Not installed
2024-08-22 21:22:55,122:INFO:           fairlearn: Not installed
2024-08-22 21:22:55,122:INFO:          deepchecks: Not installed
2024-08-22 21:22:55,122:INFO:             xgboost: Not installed
2024-08-22 21:22:55,123:INFO:            catboost: Not installed
2024-08-22 21:22:55,123:INFO:              kmodes: Not installed
2024-08-22 21:22:55,123:INFO:             mlxtend: Not installed
2024-08-22 21:22:55,123:INFO:       statsforecast: Not installed
2024-08-22 21:22:55,123:INFO:        tune_sklearn: Not installed
2024-08-22 21:22:55,123:INFO:                 ray: Not installed
2024-08-22 21:22:55,123:INFO:            hyperopt: Not installed
2024-08-22 21:22:55,123:INFO:              optuna: Not installed
2024-08-22 21:22:55,123:INFO:               skopt: Not installed
2024-08-22 21:22:55,123:INFO:              mlflow: Not installed
2024-08-22 21:22:55,124:INFO:              gradio: Not installed
2024-08-22 21:22:55,124:INFO:             fastapi: Not installed
2024-08-22 21:22:55,124:INFO:             uvicorn: Not installed
2024-08-22 21:22:55,124:INFO:              m2cgen: Not installed
2024-08-22 21:22:55,124:INFO:           evidently: Not installed
2024-08-22 21:22:55,124:INFO:               fugue: Not installed
2024-08-22 21:22:55,124:INFO:           streamlit: Not installed
2024-08-22 21:22:55,124:INFO:             prophet: Not installed
2024-08-22 21:22:55,124:INFO:None
2024-08-22 21:22:55,124:INFO:Set up data.
2024-08-22 21:22:55,203:INFO:Set up folding strategy.
2024-08-22 21:22:55,204:INFO:Set up train/test split.
2024-08-22 21:22:55,246:INFO:Set up index.
2024-08-22 21:22:55,248:INFO:Assigning column types.
2024-08-22 21:22:55,266:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-08-22 21:22:55,376:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-22 21:22:55,377:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-22 21:22:55,453:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:22:55,453:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:22:55,584:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-22 21:22:55,586:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-22 21:22:55,672:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:22:55,673:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:22:55,673:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-08-22 21:22:55,793:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-22 21:22:55,870:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:22:55,871:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:22:55,991:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-22 21:22:56,068:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:22:56,069:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:22:56,069:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-08-22 21:22:56,312:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:22:56,312:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:22:56,515:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:22:56,517:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:22:56,519:INFO:Preparing preprocessing pipeline...
2024-08-22 21:22:56,521:INFO:Set up simple imputation.
2024-08-22 21:22:56,531:INFO:Set up encoding of ordinal features.
2024-08-22 21:22:56,544:INFO:Set up encoding of categorical features.
2024-08-22 21:22:56,544:INFO:Set up imbalanced handling.
2024-08-22 21:22:56,544:INFO:Set up column transformation.
2024-08-22 21:22:56,544:INFO:Set up feature normalization.
2024-08-22 21:22:59,205:INFO:Finished creating preprocessing pipeline.
2024-08-22 21:22:59,302:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\natha\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean')...
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=QuantileTransformer(copy=True,
                                                                    ignore_implicit_zeros=False,
                                                                    n_quantiles=1000,
                                                                    output_distribution='normal',
                                                                    random_state=6782,
                                                                    subsample=10000))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2024-08-22 21:22:59,302:INFO:Creating final display dataframe.
2024-08-22 21:23:01,792:INFO:Setup _display_container:                     Description            Value
0                    Session id             6782
1                        Target              mau
2                   Target type           Binary
3           Original data shape      (38000, 13)
4        Transformed data shape      (60420, 30)
5   Transformed train set shape      (49020, 30)
6    Transformed test set shape      (11400, 30)
7              Numeric features                5
8          Categorical features                7
9      Rows with missing values            16.9%
10                   Preprocess             True
11              Imputation type           simple
12           Numeric imputation             mean
13       Categorical imputation             mode
14     Maximum one-hot encoding               25
15              Encoding method             None
16                Fix imbalance             True
17         Fix imbalance method            SMOTE
18               Transformation             True
19        Transformation method         quantile
20                    Normalize             True
21             Normalize method           zscore
22               Fold Generator  StratifiedKFold
23                  Fold Number               10
24                     CPU Jobs               -1
25                      Use GPU            False
26               Log Experiment            False
27              Experiment Name         credit_1
28                          USI             87b7
2024-08-22 21:23:01,968:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:23:01,969:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:23:02,135:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:23:02,136:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:23:02,139:INFO:setup() successfully completed in 7.06s...............
2024-08-22 21:23:02,148:INFO:Initializing compare_models()
2024-08-22 21:23:02,149:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026A0E6A58D0>, include=None, exclude=None, fold=4, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000026A0E6A58D0>, 'include': None, 'exclude': None, 'fold': 4, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-08-22 21:23:02,149:INFO:Checking exceptions
2024-08-22 21:23:02,167:INFO:Preparing display monitor
2024-08-22 21:23:02,217:INFO:Initializing Logistic Regression
2024-08-22 21:23:02,217:INFO:Total runtime is 0.0 minutes
2024-08-22 21:23:02,224:INFO:SubProcess create_model() called ==================================
2024-08-22 21:23:02,225:INFO:Initializing create_model()
2024-08-22 21:23:02,225:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026A0E6A58D0>, estimator=lr, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026A12F66B90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-22 21:23:02,225:INFO:Checking exceptions
2024-08-22 21:23:02,225:INFO:Importing libraries
2024-08-22 21:23:02,225:INFO:Copying training dataset
2024-08-22 21:23:02,250:INFO:Defining folds
2024-08-22 21:23:02,250:INFO:Declaring metric variables
2024-08-22 21:23:02,255:INFO:Importing untrained model
2024-08-22 21:23:02,264:INFO:Logistic Regression Imported successfully
2024-08-22 21:23:02,280:INFO:Starting cross validation
2024-08-22 21:23:02,290:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-08-22 21:23:08,114:INFO:Calculating mean and std
2024-08-22 21:23:08,116:INFO:Creating metrics dataframe
2024-08-22 21:23:08,121:INFO:Uploading results into container
2024-08-22 21:23:08,123:INFO:Uploading model into container now
2024-08-22 21:23:08,124:INFO:_master_model_container: 1
2024-08-22 21:23:08,124:INFO:_display_container: 2
2024-08-22 21:23:08,124:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=6782, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-08-22 21:23:08,124:INFO:create_model() successfully completed......................................
2024-08-22 21:23:08,339:INFO:SubProcess create_model() end ==================================
2024-08-22 21:23:08,339:INFO:Creating metrics dataframe
2024-08-22 21:23:08,354:INFO:Initializing K Neighbors Classifier
2024-08-22 21:23:08,354:INFO:Total runtime is 0.10227901935577392 minutes
2024-08-22 21:23:08,361:INFO:SubProcess create_model() called ==================================
2024-08-22 21:23:08,362:INFO:Initializing create_model()
2024-08-22 21:23:08,362:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026A0E6A58D0>, estimator=knn, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026A12F66B90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-22 21:23:08,362:INFO:Checking exceptions
2024-08-22 21:23:08,363:INFO:Importing libraries
2024-08-22 21:23:08,363:INFO:Copying training dataset
2024-08-22 21:23:08,392:INFO:Defining folds
2024-08-22 21:23:08,392:INFO:Declaring metric variables
2024-08-22 21:23:08,401:INFO:Importing untrained model
2024-08-22 21:23:08,409:INFO:K Neighbors Classifier Imported successfully
2024-08-22 21:23:08,421:INFO:Starting cross validation
2024-08-22 21:23:08,429:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-08-22 21:23:26,348:INFO:Calculating mean and std
2024-08-22 21:23:26,351:INFO:Creating metrics dataframe
2024-08-22 21:23:26,358:INFO:Uploading results into container
2024-08-22 21:23:26,360:INFO:Uploading model into container now
2024-08-22 21:23:26,361:INFO:_master_model_container: 2
2024-08-22 21:23:26,361:INFO:_display_container: 2
2024-08-22 21:23:26,362:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-08-22 21:23:26,363:INFO:create_model() successfully completed......................................
2024-08-22 21:23:26,615:INFO:SubProcess create_model() end ==================================
2024-08-22 21:23:26,616:INFO:Creating metrics dataframe
2024-08-22 21:23:26,631:INFO:Initializing Naive Bayes
2024-08-22 21:23:26,632:INFO:Total runtime is 0.4069196859995524 minutes
2024-08-22 21:23:26,639:INFO:SubProcess create_model() called ==================================
2024-08-22 21:23:26,640:INFO:Initializing create_model()
2024-08-22 21:23:26,640:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026A0E6A58D0>, estimator=nb, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026A12F66B90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-22 21:23:26,640:INFO:Checking exceptions
2024-08-22 21:23:26,641:INFO:Importing libraries
2024-08-22 21:23:26,641:INFO:Copying training dataset
2024-08-22 21:23:26,668:INFO:Defining folds
2024-08-22 21:23:26,668:INFO:Declaring metric variables
2024-08-22 21:23:26,675:INFO:Importing untrained model
2024-08-22 21:23:26,682:INFO:Naive Bayes Imported successfully
2024-08-22 21:23:26,696:INFO:Starting cross validation
2024-08-22 21:23:26,702:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-08-22 21:23:28,864:INFO:Calculating mean and std
2024-08-22 21:23:28,866:INFO:Creating metrics dataframe
2024-08-22 21:23:28,871:INFO:Uploading results into container
2024-08-22 21:23:28,872:INFO:Uploading model into container now
2024-08-22 21:23:28,873:INFO:_master_model_container: 3
2024-08-22 21:23:28,874:INFO:_display_container: 2
2024-08-22 21:23:28,874:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-08-22 21:23:28,875:INFO:create_model() successfully completed......................................
2024-08-22 21:23:29,094:INFO:SubProcess create_model() end ==================================
2024-08-22 21:23:29,095:INFO:Creating metrics dataframe
2024-08-22 21:23:29,113:INFO:Initializing Decision Tree Classifier
2024-08-22 21:23:29,114:INFO:Total runtime is 0.4482892433802287 minutes
2024-08-22 21:23:29,121:INFO:SubProcess create_model() called ==================================
2024-08-22 21:23:29,122:INFO:Initializing create_model()
2024-08-22 21:23:29,122:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026A0E6A58D0>, estimator=dt, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026A12F66B90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-22 21:23:29,122:INFO:Checking exceptions
2024-08-22 21:23:29,122:INFO:Importing libraries
2024-08-22 21:23:29,123:INFO:Copying training dataset
2024-08-22 21:23:29,149:INFO:Defining folds
2024-08-22 21:23:29,150:INFO:Declaring metric variables
2024-08-22 21:23:29,158:INFO:Importing untrained model
2024-08-22 21:23:29,164:INFO:Decision Tree Classifier Imported successfully
2024-08-22 21:23:29,179:INFO:Starting cross validation
2024-08-22 21:23:29,185:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-08-22 21:23:32,099:INFO:Calculating mean and std
2024-08-22 21:23:32,101:INFO:Creating metrics dataframe
2024-08-22 21:23:32,106:INFO:Uploading results into container
2024-08-22 21:23:32,107:INFO:Uploading model into container now
2024-08-22 21:23:32,108:INFO:_master_model_container: 4
2024-08-22 21:23:32,108:INFO:_display_container: 2
2024-08-22 21:23:32,110:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=6782, splitter='best')
2024-08-22 21:23:32,110:INFO:create_model() successfully completed......................................
2024-08-22 21:23:32,318:INFO:SubProcess create_model() end ==================================
2024-08-22 21:23:32,318:INFO:Creating metrics dataframe
2024-08-22 21:23:32,336:INFO:Initializing SVM - Linear Kernel
2024-08-22 21:23:32,336:INFO:Total runtime is 0.501990803082784 minutes
2024-08-22 21:23:32,342:INFO:SubProcess create_model() called ==================================
2024-08-22 21:23:32,343:INFO:Initializing create_model()
2024-08-22 21:23:32,343:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026A0E6A58D0>, estimator=svm, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026A12F66B90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-22 21:23:32,343:INFO:Checking exceptions
2024-08-22 21:23:32,343:INFO:Importing libraries
2024-08-22 21:23:32,344:INFO:Copying training dataset
2024-08-22 21:23:32,370:INFO:Defining folds
2024-08-22 21:23:32,370:INFO:Declaring metric variables
2024-08-22 21:23:32,378:INFO:Importing untrained model
2024-08-22 21:23:32,385:INFO:SVM - Linear Kernel Imported successfully
2024-08-22 21:23:32,398:INFO:Starting cross validation
2024-08-22 21:23:32,405:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-08-22 21:23:34,944:INFO:Calculating mean and std
2024-08-22 21:23:34,946:INFO:Creating metrics dataframe
2024-08-22 21:23:34,948:INFO:Uploading results into container
2024-08-22 21:23:34,950:INFO:Uploading model into container now
2024-08-22 21:23:34,951:INFO:_master_model_container: 5
2024-08-22 21:23:34,952:INFO:_display_container: 2
2024-08-22 21:23:34,952:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=6782, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-08-22 21:23:34,952:INFO:create_model() successfully completed......................................
2024-08-22 21:23:35,146:INFO:SubProcess create_model() end ==================================
2024-08-22 21:23:35,147:INFO:Creating metrics dataframe
2024-08-22 21:23:35,166:INFO:Initializing Ridge Classifier
2024-08-22 21:23:35,166:INFO:Total runtime is 0.5491478522618611 minutes
2024-08-22 21:23:35,170:INFO:SubProcess create_model() called ==================================
2024-08-22 21:23:35,170:INFO:Initializing create_model()
2024-08-22 21:23:35,171:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026A0E6A58D0>, estimator=ridge, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026A12F66B90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-22 21:23:35,171:INFO:Checking exceptions
2024-08-22 21:23:35,171:INFO:Importing libraries
2024-08-22 21:23:35,171:INFO:Copying training dataset
2024-08-22 21:23:35,190:INFO:Defining folds
2024-08-22 21:23:35,190:INFO:Declaring metric variables
2024-08-22 21:23:35,195:INFO:Importing untrained model
2024-08-22 21:23:35,203:INFO:Ridge Classifier Imported successfully
2024-08-22 21:23:35,227:INFO:Starting cross validation
2024-08-22 21:23:35,232:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-08-22 21:23:37,398:INFO:Calculating mean and std
2024-08-22 21:23:37,401:INFO:Creating metrics dataframe
2024-08-22 21:23:37,405:INFO:Uploading results into container
2024-08-22 21:23:37,407:INFO:Uploading model into container now
2024-08-22 21:23:37,408:INFO:_master_model_container: 6
2024-08-22 21:23:37,409:INFO:_display_container: 2
2024-08-22 21:23:37,409:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=6782, solver='auto',
                tol=0.0001)
2024-08-22 21:23:37,410:INFO:create_model() successfully completed......................................
2024-08-22 21:23:37,623:INFO:SubProcess create_model() end ==================================
2024-08-22 21:23:37,623:INFO:Creating metrics dataframe
2024-08-22 21:23:37,646:INFO:Initializing Random Forest Classifier
2024-08-22 21:23:37,646:INFO:Total runtime is 0.5904841939608255 minutes
2024-08-22 21:23:37,654:INFO:SubProcess create_model() called ==================================
2024-08-22 21:23:37,655:INFO:Initializing create_model()
2024-08-22 21:23:37,655:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026A0E6A58D0>, estimator=rf, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026A12F66B90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-22 21:23:37,655:INFO:Checking exceptions
2024-08-22 21:23:37,655:INFO:Importing libraries
2024-08-22 21:23:37,655:INFO:Copying training dataset
2024-08-22 21:23:37,682:INFO:Defining folds
2024-08-22 21:23:37,682:INFO:Declaring metric variables
2024-08-22 21:23:37,689:INFO:Importing untrained model
2024-08-22 21:23:37,696:INFO:Random Forest Classifier Imported successfully
2024-08-22 21:23:37,709:INFO:Starting cross validation
2024-08-22 21:23:37,714:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-08-22 21:23:48,040:INFO:Calculating mean and std
2024-08-22 21:23:48,047:INFO:Creating metrics dataframe
2024-08-22 21:23:48,053:INFO:Uploading results into container
2024-08-22 21:23:48,054:INFO:Uploading model into container now
2024-08-22 21:23:48,055:INFO:_master_model_container: 7
2024-08-22 21:23:48,055:INFO:_display_container: 2
2024-08-22 21:23:48,057:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=6782, verbose=0,
                       warm_start=False)
2024-08-22 21:23:48,059:INFO:create_model() successfully completed......................................
2024-08-22 21:23:48,272:INFO:SubProcess create_model() end ==================================
2024-08-22 21:23:48,272:INFO:Creating metrics dataframe
2024-08-22 21:23:48,293:INFO:Initializing Quadratic Discriminant Analysis
2024-08-22 21:23:48,294:INFO:Total runtime is 0.7679307142893472 minutes
2024-08-22 21:23:48,300:INFO:SubProcess create_model() called ==================================
2024-08-22 21:23:48,301:INFO:Initializing create_model()
2024-08-22 21:23:48,301:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026A0E6A58D0>, estimator=qda, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026A12F66B90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-22 21:23:48,302:INFO:Checking exceptions
2024-08-22 21:23:48,302:INFO:Importing libraries
2024-08-22 21:23:48,302:INFO:Copying training dataset
2024-08-22 21:23:48,333:INFO:Defining folds
2024-08-22 21:23:48,334:INFO:Declaring metric variables
2024-08-22 21:23:48,343:INFO:Importing untrained model
2024-08-22 21:23:48,349:INFO:Quadratic Discriminant Analysis Imported successfully
2024-08-22 21:23:48,366:INFO:Starting cross validation
2024-08-22 21:23:48,372:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-08-22 21:23:49,978:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-08-22 21:23:49,997:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-08-22 21:23:50,036:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-08-22 21:23:50,038:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-08-22 21:23:50,280:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-22 21:23:50,378:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-22 21:23:50,401:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-22 21:23:50,422:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-22 21:23:50,450:INFO:Calculating mean and std
2024-08-22 21:23:50,453:INFO:Creating metrics dataframe
2024-08-22 21:23:50,457:INFO:Uploading results into container
2024-08-22 21:23:50,458:INFO:Uploading model into container now
2024-08-22 21:23:50,459:INFO:_master_model_container: 8
2024-08-22 21:23:50,460:INFO:_display_container: 2
2024-08-22 21:23:50,460:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-08-22 21:23:50,460:INFO:create_model() successfully completed......................................
2024-08-22 21:23:50,672:INFO:SubProcess create_model() end ==================================
2024-08-22 21:23:50,672:INFO:Creating metrics dataframe
2024-08-22 21:23:50,693:INFO:Initializing Ada Boost Classifier
2024-08-22 21:23:50,694:INFO:Total runtime is 0.8079578280448912 minutes
2024-08-22 21:23:50,703:INFO:SubProcess create_model() called ==================================
2024-08-22 21:23:50,704:INFO:Initializing create_model()
2024-08-22 21:23:50,705:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026A0E6A58D0>, estimator=ada, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026A12F66B90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-22 21:23:50,705:INFO:Checking exceptions
2024-08-22 21:23:50,705:INFO:Importing libraries
2024-08-22 21:23:50,705:INFO:Copying training dataset
2024-08-22 21:23:50,741:INFO:Defining folds
2024-08-22 21:23:50,742:INFO:Declaring metric variables
2024-08-22 21:23:50,749:INFO:Importing untrained model
2024-08-22 21:23:50,759:INFO:Ada Boost Classifier Imported successfully
2024-08-22 21:23:50,777:INFO:Starting cross validation
2024-08-22 21:23:50,786:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-08-22 21:23:52,319:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-08-22 21:23:52,326:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-08-22 21:23:52,437:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-08-22 21:23:52,472:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-08-22 21:24:00,331:INFO:Calculating mean and std
2024-08-22 21:24:00,335:INFO:Creating metrics dataframe
2024-08-22 21:24:00,341:INFO:Uploading results into container
2024-08-22 21:24:00,342:INFO:Uploading model into container now
2024-08-22 21:24:00,343:INFO:_master_model_container: 9
2024-08-22 21:24:00,344:INFO:_display_container: 2
2024-08-22 21:24:00,345:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=6782)
2024-08-22 21:24:00,346:INFO:create_model() successfully completed......................................
2024-08-22 21:24:00,595:INFO:SubProcess create_model() end ==================================
2024-08-22 21:24:00,596:INFO:Creating metrics dataframe
2024-08-22 21:24:00,624:INFO:Initializing Gradient Boosting Classifier
2024-08-22 21:24:00,625:INFO:Total runtime is 0.9734494884808857 minutes
2024-08-22 21:24:00,631:INFO:SubProcess create_model() called ==================================
2024-08-22 21:24:00,632:INFO:Initializing create_model()
2024-08-22 21:24:00,633:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026A0E6A58D0>, estimator=gbc, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026A12F66B90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-22 21:24:00,633:INFO:Checking exceptions
2024-08-22 21:24:00,633:INFO:Importing libraries
2024-08-22 21:24:00,634:INFO:Copying training dataset
2024-08-22 21:24:00,663:INFO:Defining folds
2024-08-22 21:24:00,665:INFO:Declaring metric variables
2024-08-22 21:24:00,672:INFO:Importing untrained model
2024-08-22 21:24:00,680:INFO:Gradient Boosting Classifier Imported successfully
2024-08-22 21:24:00,695:INFO:Starting cross validation
2024-08-22 21:24:00,701:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-08-22 21:24:33,394:INFO:Calculating mean and std
2024-08-22 21:24:33,398:INFO:Creating metrics dataframe
2024-08-22 21:24:33,402:INFO:Uploading results into container
2024-08-22 21:24:33,403:INFO:Uploading model into container now
2024-08-22 21:24:33,405:INFO:_master_model_container: 10
2024-08-22 21:24:33,405:INFO:_display_container: 2
2024-08-22 21:24:33,406:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6782, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-08-22 21:24:33,407:INFO:create_model() successfully completed......................................
2024-08-22 21:24:33,619:INFO:SubProcess create_model() end ==================================
2024-08-22 21:24:33,620:INFO:Creating metrics dataframe
2024-08-22 21:24:33,640:INFO:Initializing Linear Discriminant Analysis
2024-08-22 21:24:33,641:INFO:Total runtime is 1.523742647965749 minutes
2024-08-22 21:24:33,649:INFO:SubProcess create_model() called ==================================
2024-08-22 21:24:33,649:INFO:Initializing create_model()
2024-08-22 21:24:33,650:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026A0E6A58D0>, estimator=lda, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026A12F66B90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-22 21:24:33,650:INFO:Checking exceptions
2024-08-22 21:24:33,650:INFO:Importing libraries
2024-08-22 21:24:33,651:INFO:Copying training dataset
2024-08-22 21:24:33,678:INFO:Defining folds
2024-08-22 21:24:33,678:INFO:Declaring metric variables
2024-08-22 21:24:33,686:INFO:Importing untrained model
2024-08-22 21:24:33,693:INFO:Linear Discriminant Analysis Imported successfully
2024-08-22 21:24:33,708:INFO:Starting cross validation
2024-08-22 21:24:33,715:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-08-22 21:24:36,285:INFO:Calculating mean and std
2024-08-22 21:24:36,288:INFO:Creating metrics dataframe
2024-08-22 21:24:36,293:INFO:Uploading results into container
2024-08-22 21:24:36,294:INFO:Uploading model into container now
2024-08-22 21:24:36,294:INFO:_master_model_container: 11
2024-08-22 21:24:36,295:INFO:_display_container: 2
2024-08-22 21:24:36,295:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-08-22 21:24:36,295:INFO:create_model() successfully completed......................................
2024-08-22 21:24:36,504:INFO:SubProcess create_model() end ==================================
2024-08-22 21:24:36,504:INFO:Creating metrics dataframe
2024-08-22 21:24:36,526:INFO:Initializing Extra Trees Classifier
2024-08-22 21:24:36,526:INFO:Total runtime is 1.5718175212542216 minutes
2024-08-22 21:24:36,536:INFO:SubProcess create_model() called ==================================
2024-08-22 21:24:36,536:INFO:Initializing create_model()
2024-08-22 21:24:36,537:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026A0E6A58D0>, estimator=et, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026A12F66B90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-22 21:24:36,537:INFO:Checking exceptions
2024-08-22 21:24:36,537:INFO:Importing libraries
2024-08-22 21:24:36,537:INFO:Copying training dataset
2024-08-22 21:24:36,567:INFO:Defining folds
2024-08-22 21:24:36,567:INFO:Declaring metric variables
2024-08-22 21:24:36,576:INFO:Importing untrained model
2024-08-22 21:24:36,583:INFO:Extra Trees Classifier Imported successfully
2024-08-22 21:24:36,596:INFO:Starting cross validation
2024-08-22 21:24:36,602:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-08-22 21:24:43,362:INFO:Calculating mean and std
2024-08-22 21:24:43,367:INFO:Creating metrics dataframe
2024-08-22 21:24:43,375:INFO:Uploading results into container
2024-08-22 21:24:43,377:INFO:Uploading model into container now
2024-08-22 21:24:43,378:INFO:_master_model_container: 12
2024-08-22 21:24:43,378:INFO:_display_container: 2
2024-08-22 21:24:43,380:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=6782, verbose=0,
                     warm_start=False)
2024-08-22 21:24:43,381:INFO:create_model() successfully completed......................................
2024-08-22 21:24:43,629:INFO:SubProcess create_model() end ==================================
2024-08-22 21:24:43,629:INFO:Creating metrics dataframe
2024-08-22 21:24:43,656:INFO:Initializing Light Gradient Boosting Machine
2024-08-22 21:24:43,656:INFO:Total runtime is 1.690651281674703 minutes
2024-08-22 21:24:43,664:INFO:SubProcess create_model() called ==================================
2024-08-22 21:24:43,665:INFO:Initializing create_model()
2024-08-22 21:24:43,665:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026A0E6A58D0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026A12F66B90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-22 21:24:43,665:INFO:Checking exceptions
2024-08-22 21:24:43,665:INFO:Importing libraries
2024-08-22 21:24:43,666:INFO:Copying training dataset
2024-08-22 21:24:43,694:INFO:Defining folds
2024-08-22 21:24:43,695:INFO:Declaring metric variables
2024-08-22 21:24:43,702:INFO:Importing untrained model
2024-08-22 21:24:43,707:INFO:Light Gradient Boosting Machine Imported successfully
2024-08-22 21:24:43,719:INFO:Starting cross validation
2024-08-22 21:24:43,725:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-08-22 21:24:48,283:INFO:Calculating mean and std
2024-08-22 21:24:48,286:INFO:Creating metrics dataframe
2024-08-22 21:24:48,292:INFO:Uploading results into container
2024-08-22 21:24:48,294:INFO:Uploading model into container now
2024-08-22 21:24:48,296:INFO:_master_model_container: 13
2024-08-22 21:24:48,296:INFO:_display_container: 2
2024-08-22 21:24:48,297:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6782, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-08-22 21:24:48,297:INFO:create_model() successfully completed......................................
2024-08-22 21:24:48,517:INFO:SubProcess create_model() end ==================================
2024-08-22 21:24:48,517:INFO:Creating metrics dataframe
2024-08-22 21:24:48,541:INFO:Initializing Dummy Classifier
2024-08-22 21:24:48,541:INFO:Total runtime is 1.7720736583073935 minutes
2024-08-22 21:24:48,549:INFO:SubProcess create_model() called ==================================
2024-08-22 21:24:48,550:INFO:Initializing create_model()
2024-08-22 21:24:48,551:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026A0E6A58D0>, estimator=dummy, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026A12F66B90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-22 21:24:48,551:INFO:Checking exceptions
2024-08-22 21:24:48,551:INFO:Importing libraries
2024-08-22 21:24:48,551:INFO:Copying training dataset
2024-08-22 21:24:48,587:INFO:Defining folds
2024-08-22 21:24:48,587:INFO:Declaring metric variables
2024-08-22 21:24:48,596:INFO:Importing untrained model
2024-08-22 21:24:48,604:INFO:Dummy Classifier Imported successfully
2024-08-22 21:24:48,620:INFO:Starting cross validation
2024-08-22 21:24:48,626:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-08-22 21:24:50,486:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-22 21:24:50,486:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-22 21:24:50,773:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-22 21:24:50,796:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-22 21:24:50,828:INFO:Calculating mean and std
2024-08-22 21:24:50,830:INFO:Creating metrics dataframe
2024-08-22 21:24:50,835:INFO:Uploading results into container
2024-08-22 21:24:50,836:INFO:Uploading model into container now
2024-08-22 21:24:50,837:INFO:_master_model_container: 14
2024-08-22 21:24:50,837:INFO:_display_container: 2
2024-08-22 21:24:50,838:INFO:DummyClassifier(constant=None, random_state=6782, strategy='prior')
2024-08-22 21:24:50,838:INFO:create_model() successfully completed......................................
2024-08-22 21:24:51,044:INFO:SubProcess create_model() end ==================================
2024-08-22 21:24:51,045:INFO:Creating metrics dataframe
2024-08-22 21:24:51,098:INFO:Initializing create_model()
2024-08-22 21:24:51,099:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026A0E6A58D0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6782, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-22 21:24:51,099:INFO:Checking exceptions
2024-08-22 21:24:51,102:INFO:Importing libraries
2024-08-22 21:24:51,103:INFO:Copying training dataset
2024-08-22 21:24:51,134:INFO:Defining folds
2024-08-22 21:24:51,134:INFO:Declaring metric variables
2024-08-22 21:24:51,134:INFO:Importing untrained model
2024-08-22 21:24:51,134:INFO:Declaring custom model
2024-08-22 21:24:51,135:INFO:Gradient Boosting Classifier Imported successfully
2024-08-22 21:24:51,140:INFO:Cross validation set to False
2024-08-22 21:24:51,141:INFO:Fitting Model
2024-08-22 21:25:24,966:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6782, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-08-22 21:25:24,967:INFO:create_model() successfully completed......................................
2024-08-22 21:25:25,284:INFO:_master_model_container: 14
2024-08-22 21:25:25,285:INFO:_display_container: 2
2024-08-22 21:25:25,287:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6782, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-08-22 21:25:25,287:INFO:compare_models() successfully completed......................................
2024-08-22 21:25:25,303:INFO:Initializing plot_model()
2024-08-22 21:25:25,303:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026A0E6A58D0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6782, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-08-22 21:25:25,304:INFO:Checking exceptions
2024-08-22 21:25:25,327:INFO:Preloading libraries
2024-08-22 21:25:25,350:INFO:Copying training dataset
2024-08-22 21:25:25,351:INFO:Plot type: feature
2024-08-22 21:25:25,351:WARNING:No coef_ found. Trying feature_importances_
2024-08-22 21:25:25,858:INFO:Visual Rendered Successfully
2024-08-22 21:25:26,042:INFO:plot_model() successfully completed......................................
2024-08-22 21:25:26,056:INFO:Initializing plot_model()
2024-08-22 21:25:26,056:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026A0E6A58D0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6782, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-08-22 21:25:26,056:INFO:Checking exceptions
2024-08-22 21:25:26,076:INFO:Preloading libraries
2024-08-22 21:25:26,100:INFO:Copying training dataset
2024-08-22 21:25:26,101:INFO:Plot type: auc
2024-08-22 21:25:26,417:INFO:Fitting Model
2024-08-22 21:25:26,421:INFO:Scoring test/hold-out set
2024-08-22 21:25:26,954:INFO:Visual Rendered Successfully
2024-08-22 21:25:27,203:INFO:plot_model() successfully completed......................................
2024-08-22 21:25:27,342:INFO:Initializing save_model()
2024-08-22 21:25:27,343:INFO:save_model(model=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6782, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), model_name=LR Model Aula 5 062022, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\natha\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean')...
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=QuantileTransformer(copy=True,
                                                                    ignore_implicit_zeros=False,
                                                                    n_quantiles=1000,
                                                                    output_distribution='normal',
                                                                    random_state=6782,
                                                                    subsample=10000))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-08-22 21:25:27,343:INFO:Adding model into prep_pipe
2024-08-22 21:25:27,382:INFO:LR Model Aula 5 062022.pkl saved in current working directory
2024-08-22 21:25:27,488:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWra...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.1, loss='log_loss',
                                            max_depth=3, max_features=None,
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.0,
                                            min_samples_leaf=1,
                                            min_samples_split=2,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=100,
                                            n_iter_no_change=None,
                                            random_state=6782, subsample=1.0,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2024-08-22 21:25:27,489:INFO:save_model() successfully completed......................................
2024-08-22 21:25:27,834:INFO:Initializing load_model()
2024-08-22 21:25:27,835:INFO:load_model(model_name=LR Model Aula 5 062022, platform=None, authentication=None, verbose=True)
2024-08-22 21:25:27,988:INFO:PyCaret ClassificationExperiment
2024-08-22 21:25:27,988:INFO:Logging name: clf-default-name
2024-08-22 21:25:27,988:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-08-22 21:25:27,988:INFO:version 3.3.2
2024-08-22 21:25:27,989:INFO:Initializing setup()
2024-08-22 21:25:27,989:INFO:self.USI: 4a3f
2024-08-22 21:25:27,989:INFO:self._variable_keys: {'n_jobs_param', 'fold_generator', 'y_train', 'logging_param', 'html_param', 'is_multiclass', 'fix_imbalance', 'gpu_param', 'log_plots_param', 'fold_groups_param', 'data', 'X_test', 'exp_name_log', 'memory', 'fold_shuffle_param', '_ml_usecase', 'seed', 'pipeline', '_available_plots', 'exp_id', 'target_param', 'y', 'y_test', 'X', 'idx', 'USI', 'X_train', 'gpu_n_jobs_param'}
2024-08-22 21:25:27,989:INFO:Checking environment
2024-08-22 21:25:27,989:INFO:python_version: 3.11.5
2024-08-22 21:25:27,989:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-08-22 21:25:27,989:INFO:machine: AMD64
2024-08-22 21:25:27,989:INFO:platform: Windows-10-10.0.22631-SP0
2024-08-22 21:25:27,990:INFO:Memory: svmem(total=8311836672, available=615165952, percent=92.6, used=7696670720, free=615165952)
2024-08-22 21:25:27,990:INFO:Physical Core: 4
2024-08-22 21:25:27,990:INFO:Logical Core: 8
2024-08-22 21:25:27,990:INFO:Checking libraries
2024-08-22 21:25:27,990:INFO:System:
2024-08-22 21:25:27,990:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-08-22 21:25:27,990:INFO:executable: C:\Users\natha\anaconda3\python.exe
2024-08-22 21:25:27,990:INFO:   machine: Windows-10-10.0.22631-SP0
2024-08-22 21:25:27,991:INFO:PyCaret required dependencies:
2024-08-22 21:25:27,991:INFO:                 pip: 23.2.1
2024-08-22 21:25:27,991:INFO:          setuptools: 68.0.0
2024-08-22 21:25:27,991:INFO:             pycaret: 3.3.2
2024-08-22 21:25:27,991:INFO:             IPython: 8.15.0
2024-08-22 21:25:27,991:INFO:          ipywidgets: 8.0.4
2024-08-22 21:25:27,991:INFO:                tqdm: 4.65.0
2024-08-22 21:25:27,991:INFO:               numpy: 1.24.3
2024-08-22 21:25:27,991:INFO:              pandas: 2.0.3
2024-08-22 21:25:27,992:INFO:              jinja2: 3.1.2
2024-08-22 21:25:27,992:INFO:               scipy: 1.11.1
2024-08-22 21:25:27,992:INFO:              joblib: 1.3.2
2024-08-22 21:25:27,992:INFO:             sklearn: 1.4.2
2024-08-22 21:25:27,992:INFO:                pyod: 2.0.1
2024-08-22 21:25:27,992:INFO:            imblearn: 0.12.3
2024-08-22 21:25:27,992:INFO:   category_encoders: 2.6.3
2024-08-22 21:25:27,992:INFO:            lightgbm: 4.5.0
2024-08-22 21:25:27,992:INFO:               numba: 0.57.1
2024-08-22 21:25:27,992:INFO:            requests: 2.31.0
2024-08-22 21:25:27,993:INFO:          matplotlib: 3.7.2
2024-08-22 21:25:27,993:INFO:          scikitplot: 0.3.7
2024-08-22 21:25:27,993:INFO:         yellowbrick: 1.5
2024-08-22 21:25:27,993:INFO:              plotly: 5.23.0
2024-08-22 21:25:27,993:INFO:    plotly-resampler: Not installed
2024-08-22 21:25:27,993:INFO:             kaleido: 0.2.1
2024-08-22 21:25:27,993:INFO:           schemdraw: 0.15
2024-08-22 21:25:27,993:INFO:         statsmodels: 0.14.0
2024-08-22 21:25:27,993:INFO:              sktime: 0.26.0
2024-08-22 21:25:27,993:INFO:               tbats: 1.1.3
2024-08-22 21:25:27,994:INFO:            pmdarima: 2.0.4
2024-08-22 21:25:27,994:INFO:              psutil: 5.9.0
2024-08-22 21:25:27,994:INFO:          markupsafe: 2.1.1
2024-08-22 21:25:27,994:INFO:             pickle5: Not installed
2024-08-22 21:25:27,994:INFO:         cloudpickle: 2.2.1
2024-08-22 21:25:27,994:INFO:         deprecation: 2.1.0
2024-08-22 21:25:27,994:INFO:              xxhash: 2.0.2
2024-08-22 21:25:27,994:INFO:           wurlitzer: Not installed
2024-08-22 21:25:27,994:INFO:PyCaret optional dependencies:
2024-08-22 21:25:27,995:INFO:                shap: Not installed
2024-08-22 21:25:27,995:INFO:           interpret: Not installed
2024-08-22 21:25:27,995:INFO:                umap: Not installed
2024-08-22 21:25:27,995:INFO:     ydata_profiling: 4.7.0
2024-08-22 21:25:27,995:INFO:  explainerdashboard: Not installed
2024-08-22 21:25:27,995:INFO:             autoviz: Not installed
2024-08-22 21:25:27,995:INFO:           fairlearn: Not installed
2024-08-22 21:25:27,995:INFO:          deepchecks: Not installed
2024-08-22 21:25:27,995:INFO:             xgboost: Not installed
2024-08-22 21:25:27,995:INFO:            catboost: Not installed
2024-08-22 21:25:27,996:INFO:              kmodes: Not installed
2024-08-22 21:25:27,996:INFO:             mlxtend: Not installed
2024-08-22 21:25:27,996:INFO:       statsforecast: Not installed
2024-08-22 21:25:27,996:INFO:        tune_sklearn: Not installed
2024-08-22 21:25:27,996:INFO:                 ray: Not installed
2024-08-22 21:25:27,996:INFO:            hyperopt: Not installed
2024-08-22 21:25:27,996:INFO:              optuna: Not installed
2024-08-22 21:25:27,996:INFO:               skopt: Not installed
2024-08-22 21:25:27,996:INFO:              mlflow: Not installed
2024-08-22 21:25:27,996:INFO:              gradio: Not installed
2024-08-22 21:25:27,997:INFO:             fastapi: Not installed
2024-08-22 21:25:27,997:INFO:             uvicorn: Not installed
2024-08-22 21:25:27,997:INFO:              m2cgen: Not installed
2024-08-22 21:25:27,997:INFO:           evidently: Not installed
2024-08-22 21:25:27,997:INFO:               fugue: Not installed
2024-08-22 21:25:27,997:INFO:           streamlit: Not installed
2024-08-22 21:25:27,997:INFO:             prophet: Not installed
2024-08-22 21:25:27,997:INFO:None
2024-08-22 21:25:27,997:INFO:Set up data.
2024-08-22 21:47:11,082:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-22 21:47:11,083:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-22 21:47:11,083:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-22 21:47:11,083:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-22 21:47:13,997:INFO:PyCaret ClassificationExperiment
2024-08-22 21:47:13,998:INFO:Logging name: clf-default-name
2024-08-22 21:47:13,998:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-08-22 21:47:13,998:INFO:version 3.3.2
2024-08-22 21:47:13,998:INFO:Initializing setup()
2024-08-22 21:47:13,998:INFO:self.USI: 99e5
2024-08-22 21:47:13,998:INFO:self._variable_keys: {'X', 'n_jobs_param', 'is_multiclass', 'log_plots_param', 'y_test', 'target_param', 'X_train', 'gpu_param', 'USI', 'html_param', 'memory', 'exp_id', 'seed', 'fold_shuffle_param', 'exp_name_log', 'pipeline', '_ml_usecase', 'data', 'gpu_n_jobs_param', 'idx', 'fold_groups_param', 'X_test', 'fold_generator', 'fix_imbalance', 'logging_param', 'y_train', '_available_plots', 'y'}
2024-08-22 21:47:13,998:INFO:Checking environment
2024-08-22 21:47:13,998:INFO:python_version: 3.11.5
2024-08-22 21:47:13,998:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-08-22 21:47:13,998:INFO:machine: AMD64
2024-08-22 21:47:13,998:INFO:platform: Windows-10-10.0.22631-SP0
2024-08-22 21:47:14,000:INFO:Memory: svmem(total=8311836672, available=1919438848, percent=76.9, used=6392397824, free=1919438848)
2024-08-22 21:47:14,000:INFO:Physical Core: 4
2024-08-22 21:47:14,000:INFO:Logical Core: 8
2024-08-22 21:47:14,000:INFO:Checking libraries
2024-08-22 21:47:14,000:INFO:System:
2024-08-22 21:47:14,000:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-08-22 21:47:14,000:INFO:executable: C:\Users\natha\anaconda3\python.exe
2024-08-22 21:47:14,001:INFO:   machine: Windows-10-10.0.22631-SP0
2024-08-22 21:47:14,001:INFO:PyCaret required dependencies:
2024-08-22 21:47:16,170:INFO:                 pip: 23.2.1
2024-08-22 21:47:16,170:INFO:          setuptools: 68.0.0
2024-08-22 21:47:16,170:INFO:             pycaret: 3.3.2
2024-08-22 21:47:16,170:INFO:             IPython: 8.15.0
2024-08-22 21:47:16,170:INFO:          ipywidgets: 8.0.4
2024-08-22 21:47:16,170:INFO:                tqdm: 4.65.0
2024-08-22 21:47:16,170:INFO:               numpy: 1.24.3
2024-08-22 21:47:16,170:INFO:              pandas: 2.0.3
2024-08-22 21:47:16,170:INFO:              jinja2: 3.1.2
2024-08-22 21:47:16,171:INFO:               scipy: 1.11.1
2024-08-22 21:47:16,171:INFO:              joblib: 1.3.2
2024-08-22 21:47:16,171:INFO:             sklearn: 1.4.2
2024-08-22 21:47:16,171:INFO:                pyod: 2.0.1
2024-08-22 21:47:16,171:INFO:            imblearn: 0.12.3
2024-08-22 21:47:16,171:INFO:   category_encoders: 2.6.3
2024-08-22 21:47:16,171:INFO:            lightgbm: 4.5.0
2024-08-22 21:47:16,171:INFO:               numba: 0.57.1
2024-08-22 21:47:16,171:INFO:            requests: 2.31.0
2024-08-22 21:47:16,171:INFO:          matplotlib: 3.7.2
2024-08-22 21:47:16,171:INFO:          scikitplot: 0.3.7
2024-08-22 21:47:16,171:INFO:         yellowbrick: 1.5
2024-08-22 21:47:16,171:INFO:              plotly: 5.23.0
2024-08-22 21:47:16,171:INFO:    plotly-resampler: Not installed
2024-08-22 21:47:16,171:INFO:             kaleido: 0.2.1
2024-08-22 21:47:16,172:INFO:           schemdraw: 0.15
2024-08-22 21:47:16,172:INFO:         statsmodels: 0.14.0
2024-08-22 21:47:16,172:INFO:              sktime: 0.26.0
2024-08-22 21:47:16,172:INFO:               tbats: 1.1.3
2024-08-22 21:47:16,172:INFO:            pmdarima: 2.0.4
2024-08-22 21:47:16,172:INFO:              psutil: 5.9.0
2024-08-22 21:47:16,172:INFO:          markupsafe: 2.1.1
2024-08-22 21:47:16,172:INFO:             pickle5: Not installed
2024-08-22 21:47:16,172:INFO:         cloudpickle: 2.2.1
2024-08-22 21:47:16,172:INFO:         deprecation: 2.1.0
2024-08-22 21:47:16,172:INFO:              xxhash: 2.0.2
2024-08-22 21:47:16,172:INFO:           wurlitzer: Not installed
2024-08-22 21:47:16,172:INFO:PyCaret optional dependencies:
2024-08-22 21:47:16,202:INFO:                shap: Not installed
2024-08-22 21:47:16,203:INFO:           interpret: Not installed
2024-08-22 21:47:16,203:INFO:                umap: Not installed
2024-08-22 21:47:16,203:INFO:     ydata_profiling: 4.7.0
2024-08-22 21:47:16,203:INFO:  explainerdashboard: Not installed
2024-08-22 21:47:16,203:INFO:             autoviz: Not installed
2024-08-22 21:47:16,203:INFO:           fairlearn: Not installed
2024-08-22 21:47:16,203:INFO:          deepchecks: Not installed
2024-08-22 21:47:16,203:INFO:             xgboost: Not installed
2024-08-22 21:47:16,203:INFO:            catboost: Not installed
2024-08-22 21:47:16,204:INFO:              kmodes: Not installed
2024-08-22 21:47:16,204:INFO:             mlxtend: Not installed
2024-08-22 21:47:16,204:INFO:       statsforecast: Not installed
2024-08-22 21:47:16,204:INFO:        tune_sklearn: Not installed
2024-08-22 21:47:16,204:INFO:                 ray: Not installed
2024-08-22 21:47:16,204:INFO:            hyperopt: Not installed
2024-08-22 21:47:16,204:INFO:              optuna: Not installed
2024-08-22 21:47:16,204:INFO:               skopt: Not installed
2024-08-22 21:47:16,204:INFO:              mlflow: Not installed
2024-08-22 21:47:16,204:INFO:              gradio: Not installed
2024-08-22 21:47:16,205:INFO:             fastapi: Not installed
2024-08-22 21:47:16,205:INFO:             uvicorn: Not installed
2024-08-22 21:47:16,205:INFO:              m2cgen: Not installed
2024-08-22 21:47:16,205:INFO:           evidently: Not installed
2024-08-22 21:47:16,205:INFO:               fugue: Not installed
2024-08-22 21:47:16,205:INFO:           streamlit: Not installed
2024-08-22 21:47:16,205:INFO:             prophet: Not installed
2024-08-22 21:47:16,205:INFO:None
2024-08-22 21:47:16,205:INFO:Set up data.
2024-08-22 21:47:16,277:INFO:Set up folding strategy.
2024-08-22 21:47:16,278:INFO:Set up train/test split.
2024-08-22 21:47:16,312:INFO:Set up index.
2024-08-22 21:47:16,313:INFO:Assigning column types.
2024-08-22 21:47:16,323:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-08-22 21:47:16,432:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-22 21:47:16,443:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-22 21:47:16,520:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:47:16,521:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:47:16,632:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-22 21:47:16,633:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-22 21:47:16,710:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:47:16,711:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:47:16,712:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-08-22 21:47:16,823:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-22 21:47:16,886:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:47:16,887:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:47:16,994:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-22 21:47:17,052:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:47:17,053:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:47:17,053:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-08-22 21:47:17,233:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:47:17,234:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:47:17,421:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:47:17,421:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:47:17,429:INFO:Preparing preprocessing pipeline...
2024-08-22 21:47:17,434:INFO:Set up simple imputation.
2024-08-22 21:47:17,451:INFO:Set up encoding of ordinal features.
2024-08-22 21:47:17,468:INFO:Set up encoding of categorical features.
2024-08-22 21:47:18,130:INFO:Finished creating preprocessing pipeline.
2024-08-22 21:47:18,198:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\natha\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean')...
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['tipo_renda', 'educacao',
                                             'estado_civil',
                                             'tipo_residencia'],
                                    transformer=OneHotEncoder(cols=['tipo_renda',
                                                                    'educacao',
                                                                    'estado_civil',
                                                                    'tipo_residencia'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2024-08-22 21:47:18,198:INFO:Creating final display dataframe.
2024-08-22 21:47:19,203:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target               mau
2                   Target type            Binary
3           Original data shape       (38000, 13)
4        Transformed data shape       (38000, 30)
5   Transformed train set shape       (26600, 30)
6    Transformed test set shape       (11400, 30)
7              Numeric features                 5
8          Categorical features                 7
9      Rows with missing values             17.3%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  clf-default-name
22                          USI              99e5
2024-08-22 21:47:19,410:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:47:19,410:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:47:19,611:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:47:19,612:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:47:19,615:INFO:setup() successfully completed in 5.65s...............
2024-08-22 21:47:19,624:INFO:gpu_param set to False
2024-08-22 21:47:19,808:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:47:19,809:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:47:19,985:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:47:19,987:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:47:21,404:INFO:PyCaret ClassificationExperiment
2024-08-22 21:47:21,405:INFO:Logging name: credit_1
2024-08-22 21:47:21,405:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-08-22 21:47:21,405:INFO:version 3.3.2
2024-08-22 21:47:21,405:INFO:Initializing setup()
2024-08-22 21:47:21,405:INFO:self.USI: 6972
2024-08-22 21:47:21,405:INFO:self._variable_keys: {'X', 'n_jobs_param', 'is_multiclass', 'log_plots_param', 'y_test', 'target_param', 'X_train', 'gpu_param', 'USI', 'html_param', 'memory', 'exp_id', 'seed', 'fold_shuffle_param', 'exp_name_log', 'pipeline', '_ml_usecase', 'data', 'gpu_n_jobs_param', 'idx', 'fold_groups_param', 'X_test', 'fold_generator', 'fix_imbalance', 'logging_param', 'y_train', '_available_plots', 'y'}
2024-08-22 21:47:21,405:INFO:Checking environment
2024-08-22 21:47:21,406:INFO:python_version: 3.11.5
2024-08-22 21:47:21,406:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-08-22 21:47:21,406:INFO:machine: AMD64
2024-08-22 21:47:21,406:INFO:platform: Windows-10-10.0.22631-SP0
2024-08-22 21:47:21,406:INFO:Memory: svmem(total=8311836672, available=1782714368, percent=78.6, used=6529122304, free=1782714368)
2024-08-22 21:47:21,406:INFO:Physical Core: 4
2024-08-22 21:47:21,406:INFO:Logical Core: 8
2024-08-22 21:47:21,407:INFO:Checking libraries
2024-08-22 21:47:21,407:INFO:System:
2024-08-22 21:47:21,407:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-08-22 21:47:21,407:INFO:executable: C:\Users\natha\anaconda3\python.exe
2024-08-22 21:47:21,407:INFO:   machine: Windows-10-10.0.22631-SP0
2024-08-22 21:47:21,407:INFO:PyCaret required dependencies:
2024-08-22 21:47:21,407:INFO:                 pip: 23.2.1
2024-08-22 21:47:21,407:INFO:          setuptools: 68.0.0
2024-08-22 21:47:21,408:INFO:             pycaret: 3.3.2
2024-08-22 21:47:21,408:INFO:             IPython: 8.15.0
2024-08-22 21:47:21,408:INFO:          ipywidgets: 8.0.4
2024-08-22 21:47:21,408:INFO:                tqdm: 4.65.0
2024-08-22 21:47:21,408:INFO:               numpy: 1.24.3
2024-08-22 21:47:21,408:INFO:              pandas: 2.0.3
2024-08-22 21:47:21,408:INFO:              jinja2: 3.1.2
2024-08-22 21:47:21,408:INFO:               scipy: 1.11.1
2024-08-22 21:47:21,408:INFO:              joblib: 1.3.2
2024-08-22 21:47:21,408:INFO:             sklearn: 1.4.2
2024-08-22 21:47:21,409:INFO:                pyod: 2.0.1
2024-08-22 21:47:21,409:INFO:            imblearn: 0.12.3
2024-08-22 21:47:21,409:INFO:   category_encoders: 2.6.3
2024-08-22 21:47:21,409:INFO:            lightgbm: 4.5.0
2024-08-22 21:47:21,409:INFO:               numba: 0.57.1
2024-08-22 21:47:21,409:INFO:            requests: 2.31.0
2024-08-22 21:47:21,409:INFO:          matplotlib: 3.7.2
2024-08-22 21:47:21,409:INFO:          scikitplot: 0.3.7
2024-08-22 21:47:21,409:INFO:         yellowbrick: 1.5
2024-08-22 21:47:21,409:INFO:              plotly: 5.23.0
2024-08-22 21:47:21,410:INFO:    plotly-resampler: Not installed
2024-08-22 21:47:21,410:INFO:             kaleido: 0.2.1
2024-08-22 21:47:21,410:INFO:           schemdraw: 0.15
2024-08-22 21:47:21,410:INFO:         statsmodels: 0.14.0
2024-08-22 21:47:21,410:INFO:              sktime: 0.26.0
2024-08-22 21:47:21,410:INFO:               tbats: 1.1.3
2024-08-22 21:47:21,410:INFO:            pmdarima: 2.0.4
2024-08-22 21:47:21,410:INFO:              psutil: 5.9.0
2024-08-22 21:47:21,411:INFO:          markupsafe: 2.1.1
2024-08-22 21:47:21,411:INFO:             pickle5: Not installed
2024-08-22 21:47:21,411:INFO:         cloudpickle: 2.2.1
2024-08-22 21:47:21,411:INFO:         deprecation: 2.1.0
2024-08-22 21:47:21,411:INFO:              xxhash: 2.0.2
2024-08-22 21:47:21,411:INFO:           wurlitzer: Not installed
2024-08-22 21:47:21,411:INFO:PyCaret optional dependencies:
2024-08-22 21:47:21,411:INFO:                shap: Not installed
2024-08-22 21:47:21,411:INFO:           interpret: Not installed
2024-08-22 21:47:21,412:INFO:                umap: Not installed
2024-08-22 21:47:21,412:INFO:     ydata_profiling: 4.7.0
2024-08-22 21:47:21,412:INFO:  explainerdashboard: Not installed
2024-08-22 21:47:21,412:INFO:             autoviz: Not installed
2024-08-22 21:47:21,412:INFO:           fairlearn: Not installed
2024-08-22 21:47:21,412:INFO:          deepchecks: Not installed
2024-08-22 21:47:21,412:INFO:             xgboost: Not installed
2024-08-22 21:47:21,412:INFO:            catboost: Not installed
2024-08-22 21:47:21,412:INFO:              kmodes: Not installed
2024-08-22 21:47:21,412:INFO:             mlxtend: Not installed
2024-08-22 21:47:21,412:INFO:       statsforecast: Not installed
2024-08-22 21:47:21,412:INFO:        tune_sklearn: Not installed
2024-08-22 21:47:21,413:INFO:                 ray: Not installed
2024-08-22 21:47:21,413:INFO:            hyperopt: Not installed
2024-08-22 21:47:21,413:INFO:              optuna: Not installed
2024-08-22 21:47:21,413:INFO:               skopt: Not installed
2024-08-22 21:47:21,413:INFO:              mlflow: Not installed
2024-08-22 21:47:21,413:INFO:              gradio: Not installed
2024-08-22 21:47:21,413:INFO:             fastapi: Not installed
2024-08-22 21:47:21,413:INFO:             uvicorn: Not installed
2024-08-22 21:47:21,413:INFO:              m2cgen: Not installed
2024-08-22 21:47:21,414:INFO:           evidently: Not installed
2024-08-22 21:47:21,414:INFO:               fugue: Not installed
2024-08-22 21:47:21,414:INFO:           streamlit: Not installed
2024-08-22 21:47:21,414:INFO:             prophet: Not installed
2024-08-22 21:47:21,414:INFO:None
2024-08-22 21:47:21,414:INFO:Set up data.
2024-08-22 21:47:21,492:INFO:Set up folding strategy.
2024-08-22 21:47:21,493:INFO:Set up train/test split.
2024-08-22 21:47:21,534:INFO:Set up index.
2024-08-22 21:47:21,536:INFO:Assigning column types.
2024-08-22 21:47:21,554:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-08-22 21:47:21,666:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-22 21:47:21,668:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-22 21:47:21,741:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:47:21,742:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:47:21,863:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-22 21:47:21,865:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-22 21:47:21,934:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:47:21,935:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:47:21,935:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-08-22 21:47:22,048:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-22 21:47:22,119:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:47:22,120:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:47:22,233:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-22 21:47:22,303:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:47:22,303:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:47:22,304:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-08-22 21:47:22,493:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:47:22,494:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:47:22,679:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:47:22,681:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:47:22,683:INFO:Preparing preprocessing pipeline...
2024-08-22 21:47:22,687:INFO:Set up simple imputation.
2024-08-22 21:47:22,706:INFO:Set up encoding of ordinal features.
2024-08-22 21:47:22,724:INFO:Set up encoding of categorical features.
2024-08-22 21:47:22,724:INFO:Set up imbalanced handling.
2024-08-22 21:47:22,724:INFO:Set up column transformation.
2024-08-22 21:47:22,724:INFO:Set up feature normalization.
2024-08-22 21:47:25,210:INFO:Finished creating preprocessing pipeline.
2024-08-22 21:47:25,298:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\natha\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean')...
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=QuantileTransformer(copy=True,
                                                                    ignore_implicit_zeros=False,
                                                                    n_quantiles=1000,
                                                                    output_distribution='normal',
                                                                    random_state=3330,
                                                                    subsample=10000))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2024-08-22 21:47:25,298:INFO:Creating final display dataframe.
2024-08-22 21:47:27,591:INFO:Setup _display_container:                     Description            Value
0                    Session id             3330
1                        Target              mau
2                   Target type           Binary
3           Original data shape      (38000, 13)
4        Transformed data shape      (60434, 30)
5   Transformed train set shape      (49034, 30)
6    Transformed test set shape      (11400, 30)
7              Numeric features                5
8          Categorical features                7
9      Rows with missing values            17.3%
10                   Preprocess             True
11              Imputation type           simple
12           Numeric imputation             mean
13       Categorical imputation             mode
14     Maximum one-hot encoding               25
15              Encoding method             None
16                Fix imbalance             True
17         Fix imbalance method            SMOTE
18               Transformation             True
19        Transformation method         quantile
20                    Normalize             True
21             Normalize method           zscore
22               Fold Generator  StratifiedKFold
23                  Fold Number               10
24                     CPU Jobs               -1
25                      Use GPU            False
26               Log Experiment            False
27              Experiment Name         credit_1
28                          USI             6972
2024-08-22 21:47:27,784:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:47:27,784:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:47:27,972:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:47:27,973:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:47:27,974:INFO:setup() successfully completed in 6.61s...............
2024-08-22 21:47:27,983:INFO:Initializing compare_models()
2024-08-22 21:47:27,983:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C58C83D1D0>, include=None, exclude=None, fold=4, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002C58C83D1D0>, 'include': None, 'exclude': None, 'fold': 4, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-08-22 21:47:27,983:INFO:Checking exceptions
2024-08-22 21:47:27,999:INFO:Preparing display monitor
2024-08-22 21:47:28,051:INFO:Initializing Logistic Regression
2024-08-22 21:47:28,052:INFO:Total runtime is 1.680453618367513e-05 minutes
2024-08-22 21:47:28,060:INFO:SubProcess create_model() called ==================================
2024-08-22 21:47:28,061:INFO:Initializing create_model()
2024-08-22 21:47:28,061:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C58C83D1D0>, estimator=lr, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C583702450>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-22 21:47:28,062:INFO:Checking exceptions
2024-08-22 21:47:28,062:INFO:Importing libraries
2024-08-22 21:47:28,062:INFO:Copying training dataset
2024-08-22 21:47:28,086:INFO:Defining folds
2024-08-22 21:47:28,086:INFO:Declaring metric variables
2024-08-22 21:47:28,090:INFO:Importing untrained model
2024-08-22 21:47:28,099:INFO:Logistic Regression Imported successfully
2024-08-22 21:47:28,112:INFO:Starting cross validation
2024-08-22 21:47:28,121:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-08-22 21:47:33,987:INFO:Calculating mean and std
2024-08-22 21:47:33,991:INFO:Creating metrics dataframe
2024-08-22 21:47:33,997:INFO:Uploading results into container
2024-08-22 21:47:33,999:INFO:Uploading model into container now
2024-08-22 21:47:34,000:INFO:_master_model_container: 1
2024-08-22 21:47:34,000:INFO:_display_container: 2
2024-08-22 21:47:34,001:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=3330, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-08-22 21:47:34,002:INFO:create_model() successfully completed......................................
2024-08-22 21:47:34,238:INFO:SubProcess create_model() end ==================================
2024-08-22 21:47:34,239:INFO:Creating metrics dataframe
2024-08-22 21:47:34,257:INFO:Initializing K Neighbors Classifier
2024-08-22 21:47:34,258:INFO:Total runtime is 0.10344998439153036 minutes
2024-08-22 21:47:34,264:INFO:SubProcess create_model() called ==================================
2024-08-22 21:47:34,265:INFO:Initializing create_model()
2024-08-22 21:47:34,265:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C58C83D1D0>, estimator=knn, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C583702450>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-22 21:47:34,266:INFO:Checking exceptions
2024-08-22 21:47:34,266:INFO:Importing libraries
2024-08-22 21:47:34,266:INFO:Copying training dataset
2024-08-22 21:47:34,295:INFO:Defining folds
2024-08-22 21:47:34,295:INFO:Declaring metric variables
2024-08-22 21:47:34,300:INFO:Importing untrained model
2024-08-22 21:47:34,309:INFO:K Neighbors Classifier Imported successfully
2024-08-22 21:47:34,320:INFO:Starting cross validation
2024-08-22 21:47:34,325:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-08-22 21:47:53,876:INFO:Calculating mean and std
2024-08-22 21:47:53,881:INFO:Creating metrics dataframe
2024-08-22 21:47:53,889:INFO:Uploading results into container
2024-08-22 21:47:53,891:INFO:Uploading model into container now
2024-08-22 21:47:53,892:INFO:_master_model_container: 2
2024-08-22 21:47:53,892:INFO:_display_container: 2
2024-08-22 21:47:53,893:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-08-22 21:47:53,893:INFO:create_model() successfully completed......................................
2024-08-22 21:47:54,157:INFO:SubProcess create_model() end ==================================
2024-08-22 21:47:54,158:INFO:Creating metrics dataframe
2024-08-22 21:47:54,175:INFO:Initializing Naive Bayes
2024-08-22 21:47:54,176:INFO:Total runtime is 0.43541498978932697 minutes
2024-08-22 21:47:54,183:INFO:SubProcess create_model() called ==================================
2024-08-22 21:47:54,185:INFO:Initializing create_model()
2024-08-22 21:47:54,186:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C58C83D1D0>, estimator=nb, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C583702450>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-22 21:47:54,186:INFO:Checking exceptions
2024-08-22 21:47:54,186:INFO:Importing libraries
2024-08-22 21:47:54,186:INFO:Copying training dataset
2024-08-22 21:47:54,211:INFO:Defining folds
2024-08-22 21:47:54,211:INFO:Declaring metric variables
2024-08-22 21:47:54,220:INFO:Importing untrained model
2024-08-22 21:47:54,228:INFO:Naive Bayes Imported successfully
2024-08-22 21:47:54,253:INFO:Starting cross validation
2024-08-22 21:47:54,260:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-08-22 21:47:56,417:INFO:Calculating mean and std
2024-08-22 21:47:56,421:INFO:Creating metrics dataframe
2024-08-22 21:47:56,426:INFO:Uploading results into container
2024-08-22 21:47:56,428:INFO:Uploading model into container now
2024-08-22 21:47:56,429:INFO:_master_model_container: 3
2024-08-22 21:47:56,430:INFO:_display_container: 2
2024-08-22 21:47:56,430:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-08-22 21:47:56,430:INFO:create_model() successfully completed......................................
2024-08-22 21:47:56,671:INFO:SubProcess create_model() end ==================================
2024-08-22 21:47:56,672:INFO:Creating metrics dataframe
2024-08-22 21:47:56,698:INFO:Initializing Decision Tree Classifier
2024-08-22 21:47:56,698:INFO:Total runtime is 0.47745346228281654 minutes
2024-08-22 21:47:56,707:INFO:SubProcess create_model() called ==================================
2024-08-22 21:47:56,708:INFO:Initializing create_model()
2024-08-22 21:47:56,708:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C58C83D1D0>, estimator=dt, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C583702450>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-22 21:47:56,708:INFO:Checking exceptions
2024-08-22 21:47:56,708:INFO:Importing libraries
2024-08-22 21:47:56,708:INFO:Copying training dataset
2024-08-22 21:47:56,735:INFO:Defining folds
2024-08-22 21:47:56,735:INFO:Declaring metric variables
2024-08-22 21:47:56,742:INFO:Importing untrained model
2024-08-22 21:47:56,751:INFO:Decision Tree Classifier Imported successfully
2024-08-22 21:47:56,770:INFO:Starting cross validation
2024-08-22 21:47:56,777:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-08-22 21:47:59,693:INFO:Calculating mean and std
2024-08-22 21:47:59,696:INFO:Creating metrics dataframe
2024-08-22 21:47:59,700:INFO:Uploading results into container
2024-08-22 21:47:59,701:INFO:Uploading model into container now
2024-08-22 21:47:59,703:INFO:_master_model_container: 4
2024-08-22 21:47:59,703:INFO:_display_container: 2
2024-08-22 21:47:59,704:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=3330, splitter='best')
2024-08-22 21:47:59,704:INFO:create_model() successfully completed......................................
2024-08-22 21:47:59,895:INFO:SubProcess create_model() end ==================================
2024-08-22 21:47:59,896:INFO:Creating metrics dataframe
2024-08-22 21:47:59,913:INFO:Initializing SVM - Linear Kernel
2024-08-22 21:47:59,914:INFO:Total runtime is 0.5310473918914794 minutes
2024-08-22 21:47:59,922:INFO:SubProcess create_model() called ==================================
2024-08-22 21:47:59,923:INFO:Initializing create_model()
2024-08-22 21:47:59,924:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C58C83D1D0>, estimator=svm, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C583702450>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-22 21:47:59,924:INFO:Checking exceptions
2024-08-22 21:47:59,924:INFO:Importing libraries
2024-08-22 21:47:59,924:INFO:Copying training dataset
2024-08-22 21:47:59,958:INFO:Defining folds
2024-08-22 21:47:59,959:INFO:Declaring metric variables
2024-08-22 21:47:59,967:INFO:Importing untrained model
2024-08-22 21:47:59,977:INFO:SVM - Linear Kernel Imported successfully
2024-08-22 21:47:59,994:INFO:Starting cross validation
2024-08-22 21:48:00,003:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-08-22 21:48:02,716:INFO:Calculating mean and std
2024-08-22 21:48:02,719:INFO:Creating metrics dataframe
2024-08-22 21:48:02,725:INFO:Uploading results into container
2024-08-22 21:48:02,727:INFO:Uploading model into container now
2024-08-22 21:48:02,728:INFO:_master_model_container: 5
2024-08-22 21:48:02,728:INFO:_display_container: 2
2024-08-22 21:48:02,730:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=3330, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-08-22 21:48:02,730:INFO:create_model() successfully completed......................................
2024-08-22 21:48:02,946:INFO:SubProcess create_model() end ==================================
2024-08-22 21:48:02,946:INFO:Creating metrics dataframe
2024-08-22 21:48:02,966:INFO:Initializing Ridge Classifier
2024-08-22 21:48:02,967:INFO:Total runtime is 0.5819270133972168 minutes
2024-08-22 21:48:02,974:INFO:SubProcess create_model() called ==================================
2024-08-22 21:48:02,974:INFO:Initializing create_model()
2024-08-22 21:48:02,974:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C58C83D1D0>, estimator=ridge, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C583702450>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-22 21:48:02,975:INFO:Checking exceptions
2024-08-22 21:48:02,975:INFO:Importing libraries
2024-08-22 21:48:02,975:INFO:Copying training dataset
2024-08-22 21:48:02,998:INFO:Defining folds
2024-08-22 21:48:02,999:INFO:Declaring metric variables
2024-08-22 21:48:03,006:INFO:Importing untrained model
2024-08-22 21:48:03,014:INFO:Ridge Classifier Imported successfully
2024-08-22 21:48:03,030:INFO:Starting cross validation
2024-08-22 21:48:03,038:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-08-22 21:48:05,187:INFO:Calculating mean and std
2024-08-22 21:48:05,189:INFO:Creating metrics dataframe
2024-08-22 21:48:05,193:INFO:Uploading results into container
2024-08-22 21:48:05,195:INFO:Uploading model into container now
2024-08-22 21:48:05,196:INFO:_master_model_container: 6
2024-08-22 21:48:05,196:INFO:_display_container: 2
2024-08-22 21:48:05,197:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=3330, solver='auto',
                tol=0.0001)
2024-08-22 21:48:05,198:INFO:create_model() successfully completed......................................
2024-08-22 21:48:05,381:INFO:SubProcess create_model() end ==================================
2024-08-22 21:48:05,382:INFO:Creating metrics dataframe
2024-08-22 21:48:05,403:INFO:Initializing Random Forest Classifier
2024-08-22 21:48:05,404:INFO:Total runtime is 0.6225424488385518 minutes
2024-08-22 21:48:05,412:INFO:SubProcess create_model() called ==================================
2024-08-22 21:48:05,413:INFO:Initializing create_model()
2024-08-22 21:48:05,413:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C58C83D1D0>, estimator=rf, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C583702450>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-22 21:48:05,413:INFO:Checking exceptions
2024-08-22 21:48:05,413:INFO:Importing libraries
2024-08-22 21:48:05,413:INFO:Copying training dataset
2024-08-22 21:48:05,439:INFO:Defining folds
2024-08-22 21:48:05,440:INFO:Declaring metric variables
2024-08-22 21:48:05,447:INFO:Importing untrained model
2024-08-22 21:48:05,455:INFO:Random Forest Classifier Imported successfully
2024-08-22 21:48:05,467:INFO:Starting cross validation
2024-08-22 21:48:05,472:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-08-22 21:48:15,619:INFO:Calculating mean and std
2024-08-22 21:48:15,623:INFO:Creating metrics dataframe
2024-08-22 21:48:15,630:INFO:Uploading results into container
2024-08-22 21:48:15,631:INFO:Uploading model into container now
2024-08-22 21:48:15,632:INFO:_master_model_container: 7
2024-08-22 21:48:15,632:INFO:_display_container: 2
2024-08-22 21:48:15,633:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=3330, verbose=0,
                       warm_start=False)
2024-08-22 21:48:15,634:INFO:create_model() successfully completed......................................
2024-08-22 21:48:15,820:INFO:SubProcess create_model() end ==================================
2024-08-22 21:48:15,821:INFO:Creating metrics dataframe
2024-08-22 21:48:15,841:INFO:Initializing Quadratic Discriminant Analysis
2024-08-22 21:48:15,842:INFO:Total runtime is 0.7965068141619365 minutes
2024-08-22 21:48:15,848:INFO:SubProcess create_model() called ==================================
2024-08-22 21:48:15,849:INFO:Initializing create_model()
2024-08-22 21:48:15,849:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C58C83D1D0>, estimator=qda, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C583702450>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-22 21:48:15,849:INFO:Checking exceptions
2024-08-22 21:48:15,849:INFO:Importing libraries
2024-08-22 21:48:15,849:INFO:Copying training dataset
2024-08-22 21:48:15,878:INFO:Defining folds
2024-08-22 21:48:15,879:INFO:Declaring metric variables
2024-08-22 21:48:15,887:INFO:Importing untrained model
2024-08-22 21:48:15,893:INFO:Quadratic Discriminant Analysis Imported successfully
2024-08-22 21:48:15,908:INFO:Starting cross validation
2024-08-22 21:48:15,913:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-08-22 21:48:17,604:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-08-22 21:48:17,628:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-08-22 21:48:17,645:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-08-22 21:48:17,810:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-08-22 21:48:18,201:INFO:Calculating mean and std
2024-08-22 21:48:18,204:INFO:Creating metrics dataframe
2024-08-22 21:48:18,210:INFO:Uploading results into container
2024-08-22 21:48:18,211:INFO:Uploading model into container now
2024-08-22 21:48:18,212:INFO:_master_model_container: 8
2024-08-22 21:48:18,213:INFO:_display_container: 2
2024-08-22 21:48:18,213:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-08-22 21:48:18,214:INFO:create_model() successfully completed......................................
2024-08-22 21:48:18,398:INFO:SubProcess create_model() end ==================================
2024-08-22 21:48:18,398:INFO:Creating metrics dataframe
2024-08-22 21:48:18,420:INFO:Initializing Ada Boost Classifier
2024-08-22 21:48:18,420:INFO:Total runtime is 0.8394858916600546 minutes
2024-08-22 21:48:18,428:INFO:SubProcess create_model() called ==================================
2024-08-22 21:48:18,429:INFO:Initializing create_model()
2024-08-22 21:48:18,429:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C58C83D1D0>, estimator=ada, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C583702450>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-22 21:48:18,429:INFO:Checking exceptions
2024-08-22 21:48:18,430:INFO:Importing libraries
2024-08-22 21:48:18,430:INFO:Copying training dataset
2024-08-22 21:48:18,463:INFO:Defining folds
2024-08-22 21:48:18,463:INFO:Declaring metric variables
2024-08-22 21:48:18,471:INFO:Importing untrained model
2024-08-22 21:48:18,478:INFO:Ada Boost Classifier Imported successfully
2024-08-22 21:48:18,491:INFO:Starting cross validation
2024-08-22 21:48:18,497:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-08-22 21:48:20,032:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-08-22 21:48:20,179:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-08-22 21:48:20,190:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-08-22 21:48:20,243:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-08-22 21:48:27,818:INFO:Calculating mean and std
2024-08-22 21:48:27,820:INFO:Creating metrics dataframe
2024-08-22 21:48:27,823:INFO:Uploading results into container
2024-08-22 21:48:27,825:INFO:Uploading model into container now
2024-08-22 21:48:27,826:INFO:_master_model_container: 9
2024-08-22 21:48:27,826:INFO:_display_container: 2
2024-08-22 21:48:27,828:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=3330)
2024-08-22 21:48:27,828:INFO:create_model() successfully completed......................................
2024-08-22 21:48:28,025:INFO:SubProcess create_model() end ==================================
2024-08-22 21:48:28,026:INFO:Creating metrics dataframe
2024-08-22 21:48:28,047:INFO:Initializing Gradient Boosting Classifier
2024-08-22 21:48:28,047:INFO:Total runtime is 0.9999365846316021 minutes
2024-08-22 21:48:28,055:INFO:SubProcess create_model() called ==================================
2024-08-22 21:48:28,056:INFO:Initializing create_model()
2024-08-22 21:48:28,057:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C58C83D1D0>, estimator=gbc, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C583702450>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-22 21:48:28,057:INFO:Checking exceptions
2024-08-22 21:48:28,058:INFO:Importing libraries
2024-08-22 21:48:28,058:INFO:Copying training dataset
2024-08-22 21:48:28,086:INFO:Defining folds
2024-08-22 21:48:28,087:INFO:Declaring metric variables
2024-08-22 21:48:28,095:INFO:Importing untrained model
2024-08-22 21:48:28,103:INFO:Gradient Boosting Classifier Imported successfully
2024-08-22 21:48:28,120:INFO:Starting cross validation
2024-08-22 21:48:28,127:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-08-22 21:49:00,351:INFO:Calculating mean and std
2024-08-22 21:49:00,353:INFO:Creating metrics dataframe
2024-08-22 21:49:00,359:INFO:Uploading results into container
2024-08-22 21:49:00,360:INFO:Uploading model into container now
2024-08-22 21:49:00,362:INFO:_master_model_container: 10
2024-08-22 21:49:00,362:INFO:_display_container: 2
2024-08-22 21:49:00,363:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=3330, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-08-22 21:49:00,365:INFO:create_model() successfully completed......................................
2024-08-22 21:49:00,580:INFO:SubProcess create_model() end ==================================
2024-08-22 21:49:00,581:INFO:Creating metrics dataframe
2024-08-22 21:49:00,600:INFO:Initializing Linear Discriminant Analysis
2024-08-22 21:49:00,600:INFO:Total runtime is 1.5424806992212932 minutes
2024-08-22 21:49:00,606:INFO:SubProcess create_model() called ==================================
2024-08-22 21:49:00,607:INFO:Initializing create_model()
2024-08-22 21:49:00,607:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C58C83D1D0>, estimator=lda, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C583702450>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-22 21:49:00,607:INFO:Checking exceptions
2024-08-22 21:49:00,608:INFO:Importing libraries
2024-08-22 21:49:00,608:INFO:Copying training dataset
2024-08-22 21:49:00,654:INFO:Defining folds
2024-08-22 21:49:00,655:INFO:Declaring metric variables
2024-08-22 21:49:00,663:INFO:Importing untrained model
2024-08-22 21:49:00,674:INFO:Linear Discriminant Analysis Imported successfully
2024-08-22 21:49:00,691:INFO:Starting cross validation
2024-08-22 21:49:00,696:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-08-22 21:49:03,231:INFO:Calculating mean and std
2024-08-22 21:49:03,234:INFO:Creating metrics dataframe
2024-08-22 21:49:03,238:INFO:Uploading results into container
2024-08-22 21:49:03,239:INFO:Uploading model into container now
2024-08-22 21:49:03,240:INFO:_master_model_container: 11
2024-08-22 21:49:03,240:INFO:_display_container: 2
2024-08-22 21:49:03,241:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-08-22 21:49:03,241:INFO:create_model() successfully completed......................................
2024-08-22 21:49:03,442:INFO:SubProcess create_model() end ==================================
2024-08-22 21:49:03,442:INFO:Creating metrics dataframe
2024-08-22 21:49:03,467:INFO:Initializing Extra Trees Classifier
2024-08-22 21:49:03,468:INFO:Total runtime is 1.5902807593345643 minutes
2024-08-22 21:49:03,475:INFO:SubProcess create_model() called ==================================
2024-08-22 21:49:03,477:INFO:Initializing create_model()
2024-08-22 21:49:03,478:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C58C83D1D0>, estimator=et, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C583702450>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-22 21:49:03,478:INFO:Checking exceptions
2024-08-22 21:49:03,479:INFO:Importing libraries
2024-08-22 21:49:03,479:INFO:Copying training dataset
2024-08-22 21:49:03,501:INFO:Defining folds
2024-08-22 21:49:03,501:INFO:Declaring metric variables
2024-08-22 21:49:03,510:INFO:Importing untrained model
2024-08-22 21:49:03,515:INFO:Extra Trees Classifier Imported successfully
2024-08-22 21:49:03,529:INFO:Starting cross validation
2024-08-22 21:49:03,535:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-08-22 21:49:10,343:INFO:Calculating mean and std
2024-08-22 21:49:10,347:INFO:Creating metrics dataframe
2024-08-22 21:49:10,354:INFO:Uploading results into container
2024-08-22 21:49:10,356:INFO:Uploading model into container now
2024-08-22 21:49:10,357:INFO:_master_model_container: 12
2024-08-22 21:49:10,358:INFO:_display_container: 2
2024-08-22 21:49:10,359:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=3330, verbose=0,
                     warm_start=False)
2024-08-22 21:49:10,360:INFO:create_model() successfully completed......................................
2024-08-22 21:49:10,577:INFO:SubProcess create_model() end ==================================
2024-08-22 21:49:10,578:INFO:Creating metrics dataframe
2024-08-22 21:49:10,595:INFO:Initializing Light Gradient Boosting Machine
2024-08-22 21:49:10,595:INFO:Total runtime is 1.7090589046478273 minutes
2024-08-22 21:49:10,603:INFO:SubProcess create_model() called ==================================
2024-08-22 21:49:10,604:INFO:Initializing create_model()
2024-08-22 21:49:10,604:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C58C83D1D0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C583702450>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-22 21:49:10,604:INFO:Checking exceptions
2024-08-22 21:49:10,605:INFO:Importing libraries
2024-08-22 21:49:10,605:INFO:Copying training dataset
2024-08-22 21:49:10,628:INFO:Defining folds
2024-08-22 21:49:10,628:INFO:Declaring metric variables
2024-08-22 21:49:10,634:INFO:Importing untrained model
2024-08-22 21:49:10,639:INFO:Light Gradient Boosting Machine Imported successfully
2024-08-22 21:49:10,654:INFO:Starting cross validation
2024-08-22 21:49:10,659:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-08-22 21:49:15,198:INFO:Calculating mean and std
2024-08-22 21:49:15,202:INFO:Creating metrics dataframe
2024-08-22 21:49:15,207:INFO:Uploading results into container
2024-08-22 21:49:15,208:INFO:Uploading model into container now
2024-08-22 21:49:15,210:INFO:_master_model_container: 13
2024-08-22 21:49:15,210:INFO:_display_container: 2
2024-08-22 21:49:15,212:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3330, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-08-22 21:49:15,212:INFO:create_model() successfully completed......................................
2024-08-22 21:49:15,401:INFO:SubProcess create_model() end ==================================
2024-08-22 21:49:15,401:INFO:Creating metrics dataframe
2024-08-22 21:49:15,428:INFO:Initializing Dummy Classifier
2024-08-22 21:49:15,429:INFO:Total runtime is 1.7896273573239645 minutes
2024-08-22 21:49:15,435:INFO:SubProcess create_model() called ==================================
2024-08-22 21:49:15,436:INFO:Initializing create_model()
2024-08-22 21:49:15,436:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C58C83D1D0>, estimator=dummy, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C583702450>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-22 21:49:15,436:INFO:Checking exceptions
2024-08-22 21:49:15,436:INFO:Importing libraries
2024-08-22 21:49:15,436:INFO:Copying training dataset
2024-08-22 21:49:15,464:INFO:Defining folds
2024-08-22 21:49:15,464:INFO:Declaring metric variables
2024-08-22 21:49:15,472:INFO:Importing untrained model
2024-08-22 21:49:15,479:INFO:Dummy Classifier Imported successfully
2024-08-22 21:49:15,491:INFO:Starting cross validation
2024-08-22 21:49:15,496:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-08-22 21:49:17,266:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-22 21:49:17,314:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-22 21:49:17,396:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-22 21:49:17,402:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-22 21:49:17,428:INFO:Calculating mean and std
2024-08-22 21:49:17,430:INFO:Creating metrics dataframe
2024-08-22 21:49:17,437:INFO:Uploading results into container
2024-08-22 21:49:17,438:INFO:Uploading model into container now
2024-08-22 21:49:17,440:INFO:_master_model_container: 14
2024-08-22 21:49:17,440:INFO:_display_container: 2
2024-08-22 21:49:17,441:INFO:DummyClassifier(constant=None, random_state=3330, strategy='prior')
2024-08-22 21:49:17,441:INFO:create_model() successfully completed......................................
2024-08-22 21:49:17,644:INFO:SubProcess create_model() end ==================================
2024-08-22 21:49:17,645:INFO:Creating metrics dataframe
2024-08-22 21:49:17,696:INFO:Initializing create_model()
2024-08-22 21:49:17,697:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C58C83D1D0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=3330, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-22 21:49:17,697:INFO:Checking exceptions
2024-08-22 21:49:17,701:INFO:Importing libraries
2024-08-22 21:49:17,701:INFO:Copying training dataset
2024-08-22 21:49:17,741:INFO:Defining folds
2024-08-22 21:49:17,742:INFO:Declaring metric variables
2024-08-22 21:49:17,742:INFO:Importing untrained model
2024-08-22 21:49:17,742:INFO:Declaring custom model
2024-08-22 21:49:17,745:INFO:Gradient Boosting Classifier Imported successfully
2024-08-22 21:49:17,752:INFO:Cross validation set to False
2024-08-22 21:49:17,753:INFO:Fitting Model
2024-08-22 21:49:51,696:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=3330, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-08-22 21:49:51,696:INFO:create_model() successfully completed......................................
2024-08-22 21:49:51,946:INFO:_master_model_container: 14
2024-08-22 21:49:51,946:INFO:_display_container: 2
2024-08-22 21:49:51,947:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=3330, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-08-22 21:49:51,947:INFO:compare_models() successfully completed......................................
2024-08-22 21:49:51,957:INFO:Initializing plot_model()
2024-08-22 21:49:51,959:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C58C83D1D0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=3330, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-08-22 21:49:51,959:INFO:Checking exceptions
2024-08-22 21:49:51,978:INFO:Preloading libraries
2024-08-22 21:49:51,997:INFO:Copying training dataset
2024-08-22 21:49:51,998:INFO:Plot type: feature
2024-08-22 21:49:51,998:WARNING:No coef_ found. Trying feature_importances_
2024-08-22 21:49:52,527:INFO:Visual Rendered Successfully
2024-08-22 21:49:52,717:INFO:plot_model() successfully completed......................................
2024-08-22 21:49:52,729:INFO:Initializing plot_model()
2024-08-22 21:49:52,730:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C58C83D1D0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=3330, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-08-22 21:49:52,730:INFO:Checking exceptions
2024-08-22 21:49:52,746:INFO:Preloading libraries
2024-08-22 21:49:52,761:INFO:Copying training dataset
2024-08-22 21:49:52,762:INFO:Plot type: auc
2024-08-22 21:49:53,086:INFO:Fitting Model
2024-08-22 21:49:53,091:INFO:Scoring test/hold-out set
2024-08-22 21:49:53,689:INFO:Visual Rendered Successfully
2024-08-22 21:49:53,889:INFO:plot_model() successfully completed......................................
2024-08-22 21:49:53,985:INFO:Initializing save_model()
2024-08-22 21:49:53,986:INFO:save_model(model=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=3330, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), model_name=LR Model Aula 5 062022, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\natha\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean')...
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=QuantileTransformer(copy=True,
                                                                    ignore_implicit_zeros=False,
                                                                    n_quantiles=1000,
                                                                    output_distribution='normal',
                                                                    random_state=3330,
                                                                    subsample=10000))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-08-22 21:49:53,986:INFO:Adding model into prep_pipe
2024-08-22 21:49:54,023:INFO:LR Model Aula 5 062022.pkl saved in current working directory
2024-08-22 21:49:54,111:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWra...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.1, loss='log_loss',
                                            max_depth=3, max_features=None,
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.0,
                                            min_samples_leaf=1,
                                            min_samples_split=2,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=100,
                                            n_iter_no_change=None,
                                            random_state=3330, subsample=1.0,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2024-08-22 21:49:54,112:INFO:save_model() successfully completed......................................
2024-08-22 21:49:54,420:INFO:Initializing load_model()
2024-08-22 21:49:54,420:INFO:load_model(model_name=LR Model Aula 5 062022, platform=None, authentication=None, verbose=True)
2024-08-22 21:49:54,579:INFO:PyCaret ClassificationExperiment
2024-08-22 21:49:54,579:INFO:Logging name: clf-default-name
2024-08-22 21:49:54,580:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-08-22 21:49:54,580:INFO:version 3.3.2
2024-08-22 21:49:54,580:INFO:Initializing setup()
2024-08-22 21:49:54,580:INFO:self.USI: 7b3d
2024-08-22 21:49:54,581:INFO:self._variable_keys: {'X', 'n_jobs_param', 'is_multiclass', 'log_plots_param', 'y_test', 'target_param', 'X_train', 'gpu_param', 'USI', 'html_param', 'memory', 'exp_id', 'seed', 'fold_shuffle_param', 'exp_name_log', 'pipeline', '_ml_usecase', 'data', 'gpu_n_jobs_param', 'idx', 'fold_groups_param', 'X_test', 'fold_generator', 'fix_imbalance', 'logging_param', 'y_train', '_available_plots', 'y'}
2024-08-22 21:49:54,581:INFO:Checking environment
2024-08-22 21:49:54,581:INFO:python_version: 3.11.5
2024-08-22 21:49:54,582:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-08-22 21:49:54,582:INFO:machine: AMD64
2024-08-22 21:49:54,582:INFO:platform: Windows-10-10.0.22631-SP0
2024-08-22 21:49:54,582:INFO:Memory: svmem(total=8311836672, available=1413447680, percent=83.0, used=6898388992, free=1413447680)
2024-08-22 21:49:54,583:INFO:Physical Core: 4
2024-08-22 21:49:54,583:INFO:Logical Core: 8
2024-08-22 21:49:54,584:INFO:Checking libraries
2024-08-22 21:49:54,584:INFO:System:
2024-08-22 21:49:54,584:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-08-22 21:49:54,585:INFO:executable: C:\Users\natha\anaconda3\python.exe
2024-08-22 21:49:54,585:INFO:   machine: Windows-10-10.0.22631-SP0
2024-08-22 21:49:54,585:INFO:PyCaret required dependencies:
2024-08-22 21:49:54,585:INFO:                 pip: 23.2.1
2024-08-22 21:49:54,586:INFO:          setuptools: 68.0.0
2024-08-22 21:49:54,586:INFO:             pycaret: 3.3.2
2024-08-22 21:49:54,586:INFO:             IPython: 8.15.0
2024-08-22 21:49:54,586:INFO:          ipywidgets: 8.0.4
2024-08-22 21:49:54,586:INFO:                tqdm: 4.65.0
2024-08-22 21:49:54,586:INFO:               numpy: 1.24.3
2024-08-22 21:49:54,587:INFO:              pandas: 2.0.3
2024-08-22 21:49:54,587:INFO:              jinja2: 3.1.2
2024-08-22 21:49:54,587:INFO:               scipy: 1.11.1
2024-08-22 21:49:54,587:INFO:              joblib: 1.3.2
2024-08-22 21:49:54,587:INFO:             sklearn: 1.4.2
2024-08-22 21:49:54,588:INFO:                pyod: 2.0.1
2024-08-22 21:49:54,588:INFO:            imblearn: 0.12.3
2024-08-22 21:49:54,588:INFO:   category_encoders: 2.6.3
2024-08-22 21:49:54,588:INFO:            lightgbm: 4.5.0
2024-08-22 21:49:54,588:INFO:               numba: 0.57.1
2024-08-22 21:49:54,589:INFO:            requests: 2.31.0
2024-08-22 21:49:54,589:INFO:          matplotlib: 3.7.2
2024-08-22 21:49:54,589:INFO:          scikitplot: 0.3.7
2024-08-22 21:49:54,590:INFO:         yellowbrick: 1.5
2024-08-22 21:49:54,590:INFO:              plotly: 5.23.0
2024-08-22 21:49:54,590:INFO:    plotly-resampler: Not installed
2024-08-22 21:49:54,590:INFO:             kaleido: 0.2.1
2024-08-22 21:49:54,591:INFO:           schemdraw: 0.15
2024-08-22 21:49:54,591:INFO:         statsmodels: 0.14.0
2024-08-22 21:49:54,592:INFO:              sktime: 0.26.0
2024-08-22 21:49:54,592:INFO:               tbats: 1.1.3
2024-08-22 21:49:54,592:INFO:            pmdarima: 2.0.4
2024-08-22 21:49:54,592:INFO:              psutil: 5.9.0
2024-08-22 21:49:54,592:INFO:          markupsafe: 2.1.1
2024-08-22 21:49:54,593:INFO:             pickle5: Not installed
2024-08-22 21:49:54,593:INFO:         cloudpickle: 2.2.1
2024-08-22 21:49:54,593:INFO:         deprecation: 2.1.0
2024-08-22 21:49:54,593:INFO:              xxhash: 2.0.2
2024-08-22 21:49:54,593:INFO:           wurlitzer: Not installed
2024-08-22 21:49:54,594:INFO:PyCaret optional dependencies:
2024-08-22 21:49:54,594:INFO:                shap: Not installed
2024-08-22 21:49:54,594:INFO:           interpret: Not installed
2024-08-22 21:49:54,594:INFO:                umap: Not installed
2024-08-22 21:49:54,595:INFO:     ydata_profiling: 4.7.0
2024-08-22 21:49:54,595:INFO:  explainerdashboard: Not installed
2024-08-22 21:49:54,595:INFO:             autoviz: Not installed
2024-08-22 21:49:54,595:INFO:           fairlearn: Not installed
2024-08-22 21:49:54,595:INFO:          deepchecks: Not installed
2024-08-22 21:49:54,596:INFO:             xgboost: Not installed
2024-08-22 21:49:54,596:INFO:            catboost: Not installed
2024-08-22 21:49:54,596:INFO:              kmodes: Not installed
2024-08-22 21:49:54,596:INFO:             mlxtend: Not installed
2024-08-22 21:49:54,596:INFO:       statsforecast: Not installed
2024-08-22 21:49:54,596:INFO:        tune_sklearn: Not installed
2024-08-22 21:49:54,596:INFO:                 ray: Not installed
2024-08-22 21:49:54,597:INFO:            hyperopt: Not installed
2024-08-22 21:49:54,597:INFO:              optuna: Not installed
2024-08-22 21:49:54,597:INFO:               skopt: Not installed
2024-08-22 21:49:54,597:INFO:              mlflow: Not installed
2024-08-22 21:49:54,598:INFO:              gradio: Not installed
2024-08-22 21:49:54,598:INFO:             fastapi: Not installed
2024-08-22 21:49:54,599:INFO:             uvicorn: Not installed
2024-08-22 21:49:54,599:INFO:              m2cgen: Not installed
2024-08-22 21:49:54,599:INFO:           evidently: Not installed
2024-08-22 21:49:54,599:INFO:               fugue: Not installed
2024-08-22 21:49:54,599:INFO:           streamlit: Not installed
2024-08-22 21:49:54,599:INFO:             prophet: Not installed
2024-08-22 21:49:54,600:INFO:None
2024-08-22 21:49:54,600:INFO:Set up data.
2024-08-22 21:49:55,135:INFO:Set up folding strategy.
2024-08-22 21:49:55,135:INFO:Set up train/test split.
2024-08-22 21:49:56,542:INFO:Set up index.
2024-08-22 21:49:56,597:INFO:Assigning column types.
2024-08-22 21:49:57,676:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-08-22 21:49:57,801:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-22 21:49:57,803:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-22 21:49:57,885:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:49:57,886:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:49:57,992:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-22 21:49:57,993:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-22 21:49:58,037:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:49:58,037:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:49:58,039:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-08-22 21:49:58,178:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-22 21:49:58,236:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:49:58,237:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:49:58,366:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-22 21:49:58,463:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:49:58,464:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:49:58,465:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-08-22 21:49:58,694:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:49:58,696:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:49:58,933:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:49:58,934:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:49:58,939:INFO:Preparing preprocessing pipeline...
2024-08-22 21:49:59,137:INFO:Set up date feature engineering.
2024-08-22 21:49:59,137:INFO:Set up simple imputation.
2024-08-22 21:49:59,138:INFO:Set up removing multicollinearity.
2024-08-22 21:49:59,138:INFO:Set up binning of numerical features.
2024-08-22 21:49:59,501:INFO:Set up column transformation.
2024-08-22 21:49:59,502:INFO:Set up feature normalization.
2024-08-22 21:49:59,720:INFO:Set up column name cleaning.
2024-08-22 21:51:03,382:INFO:Finished creating preprocessing pipeline.
2024-08-22 21:51:03,413:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\natha\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pess...
                                    transformer=PowerTransformer(copy=True,
                                                                 method='yeo-johnson',
                                                                 standardize=False))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2024-08-22 21:51:03,413:INFO:Creating final display dataframe.
2024-08-22 21:51:20,816:INFO:Setup _display_container:                     Description             Value
0                    Session id              8075
1                        Target               mau
2                   Target type            Binary
3           Original data shape      (750000, 36)
4        Transformed data shape      (750000, 38)
5   Transformed train set shape      (525000, 38)
6    Transformed test set shape      (225000, 38)
7              Numeric features                 7
8                 Date features                 1
9      Rows with missing values             16.8%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Remove multicollinearity              True
15  Multicollinearity threshold              0.95
16               Transformation              True
17        Transformation method       yeo-johnson
18                    Normalize              True
19             Normalize method            zscore
20               Fold Generator   StratifiedKFold
21                  Fold Number                10
22                     CPU Jobs                -1
23                      Use GPU             False
24               Log Experiment             False
25              Experiment Name  clf-default-name
26                          USI              7b3d
2024-08-22 21:51:21,070:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:51:21,071:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:51:21,268:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:51:21,269:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-22 21:51:21,273:INFO:setup() successfully completed in 86.76s...............
2024-08-22 21:51:21,312:INFO:Initializing create_model()
2024-08-22 21:51:21,312:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C5ECC056D0>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-22 21:51:21,312:INFO:Checking exceptions
2024-08-22 21:51:21,354:INFO:Importing libraries
2024-08-22 21:51:21,354:INFO:Copying training dataset
2024-08-22 21:51:22,851:INFO:Defining folds
2024-08-22 21:51:22,852:INFO:Declaring metric variables
2024-08-22 21:51:22,862:INFO:Importing untrained model
2024-08-22 21:51:22,871:INFO:Light Gradient Boosting Machine Imported successfully
2024-08-22 21:51:22,889:INFO:Starting cross validation
2024-08-22 21:51:22,892:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-22 21:51:31,748:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 21:51:31,933:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 21:51:33,507:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 21:51:34,656:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 21:51:34,926:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 21:51:34,953:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 21:51:35,883:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 21:51:36,245:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 21:53:23,638:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 21:53:23,935:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 21:54:26,255:INFO:Calculating mean and std
2024-08-22 21:54:26,280:INFO:Creating metrics dataframe
2024-08-22 21:54:26,330:INFO:Finalizing model
2024-08-22 21:55:27,956:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-08-22 21:55:27,960:INFO:[LightGBM] [Info] Number of positive: 41050, number of negative: 483950
2024-08-22 21:55:28,190:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.095287 seconds.
2024-08-22 21:55:28,190:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-22 21:55:28,190:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-22 21:55:28,192:INFO:[LightGBM] [Info] Total Bins 385
2024-08-22 21:55:28,192:INFO:[LightGBM] [Info] Number of data points in the train set: 525000, number of used features: 36
2024-08-22 21:55:28,200:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.078190 -> initscore=-2.467191
2024-08-22 21:55:28,201:INFO:[LightGBM] [Info] Start training from score -2.467191
2024-08-22 21:55:28,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-22 21:55:28,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-22 21:55:28,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-22 21:55:28,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-22 21:55:28,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-22 21:55:28,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-22 21:55:28,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-22 21:55:28,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-22 21:55:28,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-22 21:55:28,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-22 21:55:28,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-22 21:55:28,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-22 21:55:28,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-22 21:55:28,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-22 21:55:28,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-22 21:55:28,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-22 21:55:28,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-22 21:55:28,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-22 21:55:28,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-22 21:55:28,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-22 21:55:28,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-22 21:55:28,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-22 21:55:28,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-22 21:55:28,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-22 21:55:28,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-22 21:55:28,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-22 21:55:28,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-22 21:55:28,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-22 21:55:28,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-22 21:55:28,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-22 21:55:28,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-22 21:55:28,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-22 21:55:28,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-22 21:55:28,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-22 21:55:28,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-22 21:55:28,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-22 21:55:28,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-22 21:55:28,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-22 21:55:28,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-22 21:55:28,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-22 21:55:28,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-22 21:55:28,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-22 21:55:28,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-22 21:55:28,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-22 21:55:28,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-22 21:55:28,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-22 21:55:29,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-22 21:55:29,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-22 21:55:29,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-22 21:55:29,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-22 21:55:29,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-22 21:55:29,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-22 21:55:29,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-22 21:55:29,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-22 21:55:29,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-22 21:55:29,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-22 21:55:29,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-22 21:55:29,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-22 21:55:29,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-22 21:55:29,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-22 21:55:29,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-22 21:55:29,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-22 21:55:29,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-22 21:55:29,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-22 21:55:29,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-22 21:55:29,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-22 21:55:29,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-22 21:55:29,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-22 21:55:29,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-22 21:55:29,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-22 21:55:29,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-22 21:55:29,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-22 21:55:29,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-22 21:55:29,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-22 21:55:29,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-22 21:55:29,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-22 21:55:29,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-22 21:55:29,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-22 21:55:29,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-22 21:55:29,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-22 21:55:29,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-22 21:55:29,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-22 21:55:29,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-22 21:55:29,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-22 21:55:29,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-22 21:55:29,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-22 21:55:29,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-22 21:55:29,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-22 21:55:29,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-22 21:55:29,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-22 21:55:29,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-22 21:55:29,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-22 21:55:29,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-22 21:55:29,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-22 21:55:29,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-22 21:55:29,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-22 21:55:29,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-22 21:55:29,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-22 21:55:29,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-22 21:55:29,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-22 21:55:29,973:INFO:Uploading results into container
2024-08-22 21:55:29,975:INFO:Uploading model into container now
2024-08-22 21:55:30,024:INFO:_master_model_container: 1
2024-08-22 21:55:30,024:INFO:_display_container: 2
2024-08-22 21:55:30,026:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=8075, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-08-22 21:55:30,027:INFO:create_model() successfully completed......................................
2024-08-22 21:55:31,550:INFO:Initializing tune_model()
2024-08-22 21:55:31,551:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C5ECC056D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=8075, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-08-22 21:55:31,551:INFO:Checking exceptions
2024-08-22 21:55:32,660:INFO:Copying training dataset
2024-08-22 21:55:33,604:INFO:Checking base model
2024-08-22 21:55:33,604:INFO:Base model : Light Gradient Boosting Machine
2024-08-22 21:55:33,615:INFO:Declaring metric variables
2024-08-22 21:55:33,622:INFO:Defining Hyperparameters
2024-08-22 21:55:33,830:INFO:Tuning with n_jobs=-1
2024-08-22 21:55:33,831:INFO:Initializing RandomizedSearchCV
2024-08-22 21:55:42,290:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 21:55:43,104:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 21:55:43,173:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 21:55:43,321:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 21:55:43,549:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 21:55:43,660:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 21:55:43,707:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 21:55:44,427:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 21:58:20,603:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 21:58:20,909:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 21:58:21,674:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 21:58:21,835:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 21:58:22,266:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 21:58:23,341:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 21:58:23,898:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 22:00:19,416:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 22:00:56,446:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 22:00:56,477:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 22:01:56,610:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 22:02:06,029:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 22:02:19,838:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 22:02:27,838:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 22:02:53,655:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 22:04:01,288:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 22:04:06,039:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 22:04:26,664:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 22:05:30,831:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 22:05:31,017:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 22:05:43,465:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 22:06:06,722:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 22:06:48,526:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 22:07:09,554:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 22:07:26,001:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 22:07:30,577:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 22:07:41,528:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 22:08:10,029:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 22:09:03,160:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 22:09:16,211:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 22:09:35,514:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 22:09:50,976:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 22:09:57,064:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 22:10:02,572:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 22:10:07,286:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 22:10:45,127:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 22:11:22,390:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 22:11:42,084:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-22 22:11:57,805:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 16:26:32,135:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-26 16:26:32,136:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-26 16:26:32,136:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-26 16:26:32,136:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-26 16:26:35,410:INFO:PyCaret ClassificationExperiment
2024-08-26 16:26:35,410:INFO:Logging name: clf-default-name
2024-08-26 16:26:35,410:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-08-26 16:26:35,411:INFO:version 3.3.2
2024-08-26 16:26:35,411:INFO:Initializing setup()
2024-08-26 16:26:35,411:INFO:self.USI: e5af
2024-08-26 16:26:35,411:INFO:self._variable_keys: {'data', 'is_multiclass', 'y_train', 'html_param', '_ml_usecase', 'exp_name_log', 'fold_groups_param', 'y', 'memory', 'n_jobs_param', 'X', 'X_train', 'idx', 'y_test', 'logging_param', 'fix_imbalance', 'seed', 'fold_generator', 'log_plots_param', 'USI', 'target_param', 'pipeline', 'fold_shuffle_param', 'gpu_param', 'gpu_n_jobs_param', '_available_plots', 'X_test', 'exp_id'}
2024-08-26 16:26:35,411:INFO:Checking environment
2024-08-26 16:26:35,411:INFO:python_version: 3.11.5
2024-08-26 16:26:35,411:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-08-26 16:26:35,411:INFO:machine: AMD64
2024-08-26 16:26:35,412:INFO:platform: Windows-10-10.0.22631-SP0
2024-08-26 16:26:35,412:INFO:Memory: svmem(total=8311836672, available=835047424, percent=90.0, used=7476789248, free=835047424)
2024-08-26 16:26:35,412:INFO:Physical Core: 4
2024-08-26 16:26:35,412:INFO:Logical Core: 8
2024-08-26 16:26:35,412:INFO:Checking libraries
2024-08-26 16:26:35,412:INFO:System:
2024-08-26 16:26:35,412:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-08-26 16:26:35,412:INFO:executable: C:\Users\natha\anaconda3\python.exe
2024-08-26 16:26:35,413:INFO:   machine: Windows-10-10.0.22631-SP0
2024-08-26 16:26:35,413:INFO:PyCaret required dependencies:
2024-08-26 16:26:37,933:INFO:                 pip: 23.2.1
2024-08-26 16:26:37,933:INFO:          setuptools: 68.0.0
2024-08-26 16:26:37,933:INFO:             pycaret: 3.3.2
2024-08-26 16:26:37,934:INFO:             IPython: 8.15.0
2024-08-26 16:26:37,934:INFO:          ipywidgets: 8.0.4
2024-08-26 16:26:37,934:INFO:                tqdm: 4.65.0
2024-08-26 16:26:37,934:INFO:               numpy: 1.24.3
2024-08-26 16:26:37,934:INFO:              pandas: 2.0.3
2024-08-26 16:26:37,934:INFO:              jinja2: 3.1.2
2024-08-26 16:26:37,934:INFO:               scipy: 1.11.1
2024-08-26 16:26:37,934:INFO:              joblib: 1.3.2
2024-08-26 16:26:37,934:INFO:             sklearn: 1.4.2
2024-08-26 16:26:37,934:INFO:                pyod: 2.0.1
2024-08-26 16:26:37,934:INFO:            imblearn: 0.12.3
2024-08-26 16:26:37,934:INFO:   category_encoders: 2.6.3
2024-08-26 16:26:37,934:INFO:            lightgbm: 4.5.0
2024-08-26 16:26:37,934:INFO:               numba: 0.57.1
2024-08-26 16:26:37,934:INFO:            requests: 2.31.0
2024-08-26 16:26:37,934:INFO:          matplotlib: 3.7.2
2024-08-26 16:26:37,934:INFO:          scikitplot: 0.3.7
2024-08-26 16:26:37,934:INFO:         yellowbrick: 1.5
2024-08-26 16:26:37,934:INFO:              plotly: 5.23.0
2024-08-26 16:26:37,934:INFO:    plotly-resampler: Not installed
2024-08-26 16:26:37,934:INFO:             kaleido: 0.2.1
2024-08-26 16:26:37,935:INFO:           schemdraw: 0.15
2024-08-26 16:26:37,935:INFO:         statsmodels: 0.14.0
2024-08-26 16:26:37,935:INFO:              sktime: 0.26.0
2024-08-26 16:26:37,935:INFO:               tbats: 1.1.3
2024-08-26 16:26:37,935:INFO:            pmdarima: 2.0.4
2024-08-26 16:26:37,935:INFO:              psutil: 5.9.0
2024-08-26 16:26:37,935:INFO:          markupsafe: 2.1.1
2024-08-26 16:26:37,935:INFO:             pickle5: Not installed
2024-08-26 16:26:37,935:INFO:         cloudpickle: 2.2.1
2024-08-26 16:26:37,935:INFO:         deprecation: 2.1.0
2024-08-26 16:26:37,936:INFO:              xxhash: 2.0.2
2024-08-26 16:26:37,936:INFO:           wurlitzer: Not installed
2024-08-26 16:26:37,936:INFO:PyCaret optional dependencies:
2024-08-26 16:26:37,964:INFO:                shap: Not installed
2024-08-26 16:26:37,965:INFO:           interpret: Not installed
2024-08-26 16:26:37,965:INFO:                umap: Not installed
2024-08-26 16:26:37,965:INFO:     ydata_profiling: 4.7.0
2024-08-26 16:26:37,965:INFO:  explainerdashboard: Not installed
2024-08-26 16:26:37,965:INFO:             autoviz: Not installed
2024-08-26 16:26:37,965:INFO:           fairlearn: Not installed
2024-08-26 16:26:37,965:INFO:          deepchecks: Not installed
2024-08-26 16:26:37,965:INFO:             xgboost: Not installed
2024-08-26 16:26:37,965:INFO:            catboost: Not installed
2024-08-26 16:26:37,965:INFO:              kmodes: Not installed
2024-08-26 16:26:37,965:INFO:             mlxtend: Not installed
2024-08-26 16:26:37,965:INFO:       statsforecast: Not installed
2024-08-26 16:26:37,965:INFO:        tune_sklearn: Not installed
2024-08-26 16:26:37,965:INFO:                 ray: Not installed
2024-08-26 16:26:37,966:INFO:            hyperopt: Not installed
2024-08-26 16:26:37,966:INFO:              optuna: Not installed
2024-08-26 16:26:37,966:INFO:               skopt: Not installed
2024-08-26 16:26:37,966:INFO:              mlflow: Not installed
2024-08-26 16:26:37,966:INFO:              gradio: Not installed
2024-08-26 16:26:37,966:INFO:             fastapi: Not installed
2024-08-26 16:26:37,966:INFO:             uvicorn: Not installed
2024-08-26 16:26:37,966:INFO:              m2cgen: Not installed
2024-08-26 16:26:37,966:INFO:           evidently: Not installed
2024-08-26 16:26:37,966:INFO:               fugue: Not installed
2024-08-26 16:26:37,966:INFO:           streamlit: Not installed
2024-08-26 16:26:37,966:INFO:             prophet: Not installed
2024-08-26 16:26:37,966:INFO:None
2024-08-26 16:26:37,966:INFO:Set up data.
2024-08-26 16:26:38,039:INFO:Set up folding strategy.
2024-08-26 16:26:38,039:INFO:Set up train/test split.
2024-08-26 16:26:38,080:INFO:Set up index.
2024-08-26 16:26:38,081:INFO:Assigning column types.
2024-08-26 16:26:38,097:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-08-26 16:26:38,202:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-26 16:26:38,211:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-26 16:26:38,303:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 16:26:38,304:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 16:26:38,424:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-26 16:26:38,426:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-26 16:26:38,493:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 16:26:38,493:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 16:26:38,494:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-08-26 16:26:38,609:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-26 16:26:38,682:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 16:26:38,682:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 16:26:38,802:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-26 16:26:38,869:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 16:26:38,870:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 16:26:38,871:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-08-26 16:26:39,056:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 16:26:39,057:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 16:26:39,241:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 16:26:39,242:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 16:26:39,254:INFO:Preparing preprocessing pipeline...
2024-08-26 16:26:39,257:INFO:Set up simple imputation.
2024-08-26 16:26:39,280:INFO:Set up encoding of ordinal features.
2024-08-26 16:26:39,296:INFO:Set up encoding of categorical features.
2024-08-26 16:26:40,009:INFO:Finished creating preprocessing pipeline.
2024-08-26 16:26:40,083:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\natha\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean')...
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['tipo_renda', 'educacao',
                                             'estado_civil',
                                             'tipo_residencia'],
                                    transformer=OneHotEncoder(cols=['tipo_renda',
                                                                    'educacao',
                                                                    'estado_civil',
                                                                    'tipo_residencia'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2024-08-26 16:26:40,084:INFO:Creating final display dataframe.
2024-08-26 16:26:41,325:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target               mau
2                   Target type            Binary
3           Original data shape       (38000, 13)
4        Transformed data shape       (38000, 30)
5   Transformed train set shape       (26600, 30)
6    Transformed test set shape       (11400, 30)
7              Numeric features                 5
8          Categorical features                 7
9      Rows with missing values             16.9%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  clf-default-name
22                          USI              e5af
2024-08-26 16:26:41,521:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 16:26:41,522:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 16:26:41,719:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 16:26:41,720:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 16:26:41,724:INFO:setup() successfully completed in 6.49s...............
2024-08-26 16:26:41,733:INFO:gpu_param set to False
2024-08-26 16:26:41,926:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 16:26:41,927:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 16:26:42,117:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 16:26:42,117:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 16:26:43,556:INFO:PyCaret ClassificationExperiment
2024-08-26 16:26:43,557:INFO:Logging name: credit_1
2024-08-26 16:26:43,557:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-08-26 16:26:43,557:INFO:version 3.3.2
2024-08-26 16:26:43,557:INFO:Initializing setup()
2024-08-26 16:26:43,557:INFO:self.USI: ce5c
2024-08-26 16:26:43,557:INFO:self._variable_keys: {'data', 'is_multiclass', 'y_train', 'html_param', '_ml_usecase', 'exp_name_log', 'fold_groups_param', 'y', 'memory', 'n_jobs_param', 'X', 'X_train', 'idx', 'y_test', 'logging_param', 'fix_imbalance', 'seed', 'fold_generator', 'log_plots_param', 'USI', 'target_param', 'pipeline', 'fold_shuffle_param', 'gpu_param', 'gpu_n_jobs_param', '_available_plots', 'X_test', 'exp_id'}
2024-08-26 16:26:43,557:INFO:Checking environment
2024-08-26 16:26:43,558:INFO:python_version: 3.11.5
2024-08-26 16:26:43,558:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-08-26 16:26:43,558:INFO:machine: AMD64
2024-08-26 16:26:43,558:INFO:platform: Windows-10-10.0.22631-SP0
2024-08-26 16:26:43,559:INFO:Memory: svmem(total=8311836672, available=703836160, percent=91.5, used=7608000512, free=703836160)
2024-08-26 16:26:43,559:INFO:Physical Core: 4
2024-08-26 16:26:43,559:INFO:Logical Core: 8
2024-08-26 16:26:43,559:INFO:Checking libraries
2024-08-26 16:26:43,559:INFO:System:
2024-08-26 16:26:43,559:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-08-26 16:26:43,559:INFO:executable: C:\Users\natha\anaconda3\python.exe
2024-08-26 16:26:43,560:INFO:   machine: Windows-10-10.0.22631-SP0
2024-08-26 16:26:43,560:INFO:PyCaret required dependencies:
2024-08-26 16:26:43,560:INFO:                 pip: 23.2.1
2024-08-26 16:26:43,560:INFO:          setuptools: 68.0.0
2024-08-26 16:26:43,560:INFO:             pycaret: 3.3.2
2024-08-26 16:26:43,560:INFO:             IPython: 8.15.0
2024-08-26 16:26:43,560:INFO:          ipywidgets: 8.0.4
2024-08-26 16:26:43,560:INFO:                tqdm: 4.65.0
2024-08-26 16:26:43,560:INFO:               numpy: 1.24.3
2024-08-26 16:26:43,561:INFO:              pandas: 2.0.3
2024-08-26 16:26:43,561:INFO:              jinja2: 3.1.2
2024-08-26 16:26:43,561:INFO:               scipy: 1.11.1
2024-08-26 16:26:43,561:INFO:              joblib: 1.3.2
2024-08-26 16:26:43,561:INFO:             sklearn: 1.4.2
2024-08-26 16:26:43,561:INFO:                pyod: 2.0.1
2024-08-26 16:26:43,561:INFO:            imblearn: 0.12.3
2024-08-26 16:26:43,561:INFO:   category_encoders: 2.6.3
2024-08-26 16:26:43,561:INFO:            lightgbm: 4.5.0
2024-08-26 16:26:43,561:INFO:               numba: 0.57.1
2024-08-26 16:26:43,562:INFO:            requests: 2.31.0
2024-08-26 16:26:43,562:INFO:          matplotlib: 3.7.2
2024-08-26 16:26:43,562:INFO:          scikitplot: 0.3.7
2024-08-26 16:26:43,562:INFO:         yellowbrick: 1.5
2024-08-26 16:26:43,562:INFO:              plotly: 5.23.0
2024-08-26 16:26:43,562:INFO:    plotly-resampler: Not installed
2024-08-26 16:26:43,562:INFO:             kaleido: 0.2.1
2024-08-26 16:26:43,562:INFO:           schemdraw: 0.15
2024-08-26 16:26:43,562:INFO:         statsmodels: 0.14.0
2024-08-26 16:26:43,562:INFO:              sktime: 0.26.0
2024-08-26 16:26:43,562:INFO:               tbats: 1.1.3
2024-08-26 16:26:43,562:INFO:            pmdarima: 2.0.4
2024-08-26 16:26:43,562:INFO:              psutil: 5.9.0
2024-08-26 16:26:43,562:INFO:          markupsafe: 2.1.1
2024-08-26 16:26:43,562:INFO:             pickle5: Not installed
2024-08-26 16:26:43,563:INFO:         cloudpickle: 2.2.1
2024-08-26 16:26:43,563:INFO:         deprecation: 2.1.0
2024-08-26 16:26:43,563:INFO:              xxhash: 2.0.2
2024-08-26 16:26:43,563:INFO:           wurlitzer: Not installed
2024-08-26 16:26:43,563:INFO:PyCaret optional dependencies:
2024-08-26 16:26:43,563:INFO:                shap: Not installed
2024-08-26 16:26:43,563:INFO:           interpret: Not installed
2024-08-26 16:26:43,563:INFO:                umap: Not installed
2024-08-26 16:26:43,563:INFO:     ydata_profiling: 4.7.0
2024-08-26 16:26:43,563:INFO:  explainerdashboard: Not installed
2024-08-26 16:26:43,563:INFO:             autoviz: Not installed
2024-08-26 16:26:43,563:INFO:           fairlearn: Not installed
2024-08-26 16:26:43,563:INFO:          deepchecks: Not installed
2024-08-26 16:26:43,563:INFO:             xgboost: Not installed
2024-08-26 16:26:43,564:INFO:            catboost: Not installed
2024-08-26 16:26:43,564:INFO:              kmodes: Not installed
2024-08-26 16:26:43,564:INFO:             mlxtend: Not installed
2024-08-26 16:26:43,564:INFO:       statsforecast: Not installed
2024-08-26 16:26:43,564:INFO:        tune_sklearn: Not installed
2024-08-26 16:26:43,564:INFO:                 ray: Not installed
2024-08-26 16:26:43,564:INFO:            hyperopt: Not installed
2024-08-26 16:26:43,564:INFO:              optuna: Not installed
2024-08-26 16:26:43,564:INFO:               skopt: Not installed
2024-08-26 16:26:43,564:INFO:              mlflow: Not installed
2024-08-26 16:26:43,564:INFO:              gradio: Not installed
2024-08-26 16:26:43,564:INFO:             fastapi: Not installed
2024-08-26 16:26:43,564:INFO:             uvicorn: Not installed
2024-08-26 16:26:43,565:INFO:              m2cgen: Not installed
2024-08-26 16:26:43,565:INFO:           evidently: Not installed
2024-08-26 16:26:43,565:INFO:               fugue: Not installed
2024-08-26 16:26:43,565:INFO:           streamlit: Not installed
2024-08-26 16:26:43,565:INFO:             prophet: Not installed
2024-08-26 16:26:43,565:INFO:None
2024-08-26 16:26:43,565:INFO:Set up data.
2024-08-26 16:26:43,640:INFO:Set up folding strategy.
2024-08-26 16:26:43,641:INFO:Set up train/test split.
2024-08-26 16:26:43,679:INFO:Set up index.
2024-08-26 16:26:43,681:INFO:Assigning column types.
2024-08-26 16:26:43,700:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-08-26 16:26:43,811:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-26 16:26:43,812:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-26 16:26:43,884:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 16:26:43,885:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 16:26:43,999:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-26 16:26:44,002:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-26 16:26:44,071:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 16:26:44,071:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 16:26:44,072:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-08-26 16:26:44,196:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-26 16:26:44,267:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 16:26:44,268:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 16:26:44,387:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-26 16:26:44,464:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 16:26:44,464:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 16:26:44,464:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-08-26 16:26:44,630:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 16:26:44,631:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 16:26:44,829:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 16:26:44,830:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 16:26:44,833:INFO:Preparing preprocessing pipeline...
2024-08-26 16:26:44,837:INFO:Set up simple imputation.
2024-08-26 16:26:44,859:INFO:Set up encoding of ordinal features.
2024-08-26 16:26:44,878:INFO:Set up encoding of categorical features.
2024-08-26 16:26:44,878:INFO:Set up imbalanced handling.
2024-08-26 16:26:44,878:INFO:Set up column transformation.
2024-08-26 16:26:44,878:INFO:Set up feature normalization.
2024-08-26 16:26:47,436:INFO:Finished creating preprocessing pipeline.
2024-08-26 16:26:47,520:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\natha\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean')...
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=QuantileTransformer(copy=True,
                                                                    ignore_implicit_zeros=False,
                                                                    n_quantiles=1000,
                                                                    output_distribution='normal',
                                                                    random_state=8607,
                                                                    subsample=10000))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2024-08-26 16:26:47,520:INFO:Creating final display dataframe.
2024-08-26 16:26:49,905:INFO:Setup _display_container:                     Description            Value
0                    Session id             8607
1                        Target              mau
2                   Target type           Binary
3           Original data shape      (38000, 13)
4        Transformed data shape      (60434, 30)
5   Transformed train set shape      (49034, 30)
6    Transformed test set shape      (11400, 30)
7              Numeric features                5
8          Categorical features                7
9      Rows with missing values            16.9%
10                   Preprocess             True
11              Imputation type           simple
12           Numeric imputation             mean
13       Categorical imputation             mode
14     Maximum one-hot encoding               25
15              Encoding method             None
16                Fix imbalance             True
17         Fix imbalance method            SMOTE
18               Transformation             True
19        Transformation method         quantile
20                    Normalize             True
21             Normalize method           zscore
22               Fold Generator  StratifiedKFold
23                  Fold Number               10
24                     CPU Jobs               -1
25                      Use GPU            False
26               Log Experiment            False
27              Experiment Name         credit_1
28                          USI             ce5c
2024-08-26 16:26:50,139:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 16:26:50,140:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 16:26:50,325:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 16:26:50,327:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 16:26:50,329:INFO:setup() successfully completed in 6.85s...............
2024-08-26 16:26:50,341:INFO:Initializing compare_models()
2024-08-26 16:26:50,341:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023F0BA33290>, include=None, exclude=None, fold=4, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000023F0BA33290>, 'include': None, 'exclude': None, 'fold': 4, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-08-26 16:26:50,341:INFO:Checking exceptions
2024-08-26 16:26:50,363:INFO:Preparing display monitor
2024-08-26 16:26:50,416:INFO:Initializing Logistic Regression
2024-08-26 16:26:50,416:INFO:Total runtime is 0.0 minutes
2024-08-26 16:26:50,423:INFO:SubProcess create_model() called ==================================
2024-08-26 16:26:50,424:INFO:Initializing create_model()
2024-08-26 16:26:50,425:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023F0BA33290>, estimator=lr, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023F0BC0D750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-26 16:26:50,425:INFO:Checking exceptions
2024-08-26 16:26:50,425:INFO:Importing libraries
2024-08-26 16:26:50,425:INFO:Copying training dataset
2024-08-26 16:26:50,452:INFO:Defining folds
2024-08-26 16:26:50,452:INFO:Declaring metric variables
2024-08-26 16:26:50,460:INFO:Importing untrained model
2024-08-26 16:26:50,469:INFO:Logistic Regression Imported successfully
2024-08-26 16:26:50,485:INFO:Starting cross validation
2024-08-26 16:26:50,492:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-08-26 16:26:58,109:INFO:Calculating mean and std
2024-08-26 16:26:58,111:INFO:Creating metrics dataframe
2024-08-26 16:26:58,116:INFO:Uploading results into container
2024-08-26 16:26:58,117:INFO:Uploading model into container now
2024-08-26 16:26:58,118:INFO:_master_model_container: 1
2024-08-26 16:26:58,118:INFO:_display_container: 2
2024-08-26 16:26:58,118:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8607, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-08-26 16:26:58,119:INFO:create_model() successfully completed......................................
2024-08-26 16:26:58,337:INFO:SubProcess create_model() end ==================================
2024-08-26 16:26:58,337:INFO:Creating metrics dataframe
2024-08-26 16:26:58,347:INFO:Initializing K Neighbors Classifier
2024-08-26 16:26:58,347:INFO:Total runtime is 0.13218321800231933 minutes
2024-08-26 16:26:58,351:INFO:SubProcess create_model() called ==================================
2024-08-26 16:26:58,351:INFO:Initializing create_model()
2024-08-26 16:26:58,353:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023F0BA33290>, estimator=knn, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023F0BC0D750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-26 16:26:58,353:INFO:Checking exceptions
2024-08-26 16:26:58,353:INFO:Importing libraries
2024-08-26 16:26:58,353:INFO:Copying training dataset
2024-08-26 16:26:58,379:INFO:Defining folds
2024-08-26 16:26:58,380:INFO:Declaring metric variables
2024-08-26 16:26:58,389:INFO:Importing untrained model
2024-08-26 16:26:58,398:INFO:K Neighbors Classifier Imported successfully
2024-08-26 16:26:58,412:INFO:Starting cross validation
2024-08-26 16:26:58,420:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-08-26 16:27:22,979:INFO:Calculating mean and std
2024-08-26 16:27:22,982:INFO:Creating metrics dataframe
2024-08-26 16:27:22,991:INFO:Uploading results into container
2024-08-26 16:27:22,993:INFO:Uploading model into container now
2024-08-26 16:27:22,995:INFO:_master_model_container: 2
2024-08-26 16:27:22,996:INFO:_display_container: 2
2024-08-26 16:27:22,997:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-08-26 16:27:22,997:INFO:create_model() successfully completed......................................
2024-08-26 16:27:23,229:INFO:SubProcess create_model() end ==================================
2024-08-26 16:27:23,230:INFO:Creating metrics dataframe
2024-08-26 16:27:23,254:INFO:Initializing Naive Bayes
2024-08-26 16:27:23,255:INFO:Total runtime is 0.5473039070765178 minutes
2024-08-26 16:27:23,261:INFO:SubProcess create_model() called ==================================
2024-08-26 16:27:23,262:INFO:Initializing create_model()
2024-08-26 16:27:23,262:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023F0BA33290>, estimator=nb, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023F0BC0D750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-26 16:27:23,263:INFO:Checking exceptions
2024-08-26 16:27:23,263:INFO:Importing libraries
2024-08-26 16:27:23,263:INFO:Copying training dataset
2024-08-26 16:27:23,288:INFO:Defining folds
2024-08-26 16:27:23,289:INFO:Declaring metric variables
2024-08-26 16:27:23,297:INFO:Importing untrained model
2024-08-26 16:27:23,304:INFO:Naive Bayes Imported successfully
2024-08-26 16:27:23,322:INFO:Starting cross validation
2024-08-26 16:27:23,327:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-08-26 16:27:25,297:INFO:Calculating mean and std
2024-08-26 16:27:25,299:INFO:Creating metrics dataframe
2024-08-26 16:27:25,304:INFO:Uploading results into container
2024-08-26 16:27:25,306:INFO:Uploading model into container now
2024-08-26 16:27:25,306:INFO:_master_model_container: 3
2024-08-26 16:27:25,307:INFO:_display_container: 2
2024-08-26 16:27:25,307:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-08-26 16:27:25,307:INFO:create_model() successfully completed......................................
2024-08-26 16:27:25,488:INFO:SubProcess create_model() end ==================================
2024-08-26 16:27:25,488:INFO:Creating metrics dataframe
2024-08-26 16:27:25,501:INFO:Initializing Decision Tree Classifier
2024-08-26 16:27:25,502:INFO:Total runtime is 0.5847684939702352 minutes
2024-08-26 16:27:25,506:INFO:SubProcess create_model() called ==================================
2024-08-26 16:27:25,506:INFO:Initializing create_model()
2024-08-26 16:27:25,507:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023F0BA33290>, estimator=dt, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023F0BC0D750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-26 16:27:25,507:INFO:Checking exceptions
2024-08-26 16:27:25,507:INFO:Importing libraries
2024-08-26 16:27:25,507:INFO:Copying training dataset
2024-08-26 16:27:25,536:INFO:Defining folds
2024-08-26 16:27:25,536:INFO:Declaring metric variables
2024-08-26 16:27:25,541:INFO:Importing untrained model
2024-08-26 16:27:25,548:INFO:Decision Tree Classifier Imported successfully
2024-08-26 16:27:25,562:INFO:Starting cross validation
2024-08-26 16:27:25,569:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-08-26 16:27:28,452:INFO:Calculating mean and std
2024-08-26 16:27:28,455:INFO:Creating metrics dataframe
2024-08-26 16:27:28,462:INFO:Uploading results into container
2024-08-26 16:27:28,463:INFO:Uploading model into container now
2024-08-26 16:27:28,464:INFO:_master_model_container: 4
2024-08-26 16:27:28,464:INFO:_display_container: 2
2024-08-26 16:27:28,465:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=8607, splitter='best')
2024-08-26 16:27:28,465:INFO:create_model() successfully completed......................................
2024-08-26 16:27:28,650:INFO:SubProcess create_model() end ==================================
2024-08-26 16:27:28,650:INFO:Creating metrics dataframe
2024-08-26 16:27:28,670:INFO:Initializing SVM - Linear Kernel
2024-08-26 16:27:28,670:INFO:Total runtime is 0.6375657399495444 minutes
2024-08-26 16:27:28,680:INFO:SubProcess create_model() called ==================================
2024-08-26 16:27:28,681:INFO:Initializing create_model()
2024-08-26 16:27:28,681:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023F0BA33290>, estimator=svm, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023F0BC0D750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-26 16:27:28,681:INFO:Checking exceptions
2024-08-26 16:27:28,681:INFO:Importing libraries
2024-08-26 16:27:28,681:INFO:Copying training dataset
2024-08-26 16:27:28,711:INFO:Defining folds
2024-08-26 16:27:28,711:INFO:Declaring metric variables
2024-08-26 16:27:28,720:INFO:Importing untrained model
2024-08-26 16:27:28,730:INFO:SVM - Linear Kernel Imported successfully
2024-08-26 16:27:28,746:INFO:Starting cross validation
2024-08-26 16:27:28,752:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-08-26 16:27:31,374:INFO:Calculating mean and std
2024-08-26 16:27:31,377:INFO:Creating metrics dataframe
2024-08-26 16:27:31,382:INFO:Uploading results into container
2024-08-26 16:27:31,385:INFO:Uploading model into container now
2024-08-26 16:27:31,387:INFO:_master_model_container: 5
2024-08-26 16:27:31,387:INFO:_display_container: 2
2024-08-26 16:27:31,389:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=8607, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-08-26 16:27:31,389:INFO:create_model() successfully completed......................................
2024-08-26 16:27:31,586:INFO:SubProcess create_model() end ==================================
2024-08-26 16:27:31,586:INFO:Creating metrics dataframe
2024-08-26 16:27:31,608:INFO:Initializing Ridge Classifier
2024-08-26 16:27:31,608:INFO:Total runtime is 0.6865232626597088 minutes
2024-08-26 16:27:31,616:INFO:SubProcess create_model() called ==================================
2024-08-26 16:27:31,617:INFO:Initializing create_model()
2024-08-26 16:27:31,617:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023F0BA33290>, estimator=ridge, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023F0BC0D750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-26 16:27:31,617:INFO:Checking exceptions
2024-08-26 16:27:31,617:INFO:Importing libraries
2024-08-26 16:27:31,617:INFO:Copying training dataset
2024-08-26 16:27:31,648:INFO:Defining folds
2024-08-26 16:27:31,649:INFO:Declaring metric variables
2024-08-26 16:27:31,657:INFO:Importing untrained model
2024-08-26 16:27:31,667:INFO:Ridge Classifier Imported successfully
2024-08-26 16:27:31,681:INFO:Starting cross validation
2024-08-26 16:27:31,686:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-08-26 16:27:33,725:INFO:Calculating mean and std
2024-08-26 16:27:33,727:INFO:Creating metrics dataframe
2024-08-26 16:27:33,731:INFO:Uploading results into container
2024-08-26 16:27:33,733:INFO:Uploading model into container now
2024-08-26 16:27:33,734:INFO:_master_model_container: 6
2024-08-26 16:27:33,734:INFO:_display_container: 2
2024-08-26 16:27:33,735:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=8607, solver='auto',
                tol=0.0001)
2024-08-26 16:27:33,735:INFO:create_model() successfully completed......................................
2024-08-26 16:27:33,906:INFO:SubProcess create_model() end ==================================
2024-08-26 16:27:33,906:INFO:Creating metrics dataframe
2024-08-26 16:27:33,927:INFO:Initializing Random Forest Classifier
2024-08-26 16:27:33,927:INFO:Total runtime is 0.7251724521319073 minutes
2024-08-26 16:27:33,932:INFO:SubProcess create_model() called ==================================
2024-08-26 16:27:33,933:INFO:Initializing create_model()
2024-08-26 16:27:33,933:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023F0BA33290>, estimator=rf, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023F0BC0D750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-26 16:27:33,933:INFO:Checking exceptions
2024-08-26 16:27:33,933:INFO:Importing libraries
2024-08-26 16:27:33,933:INFO:Copying training dataset
2024-08-26 16:27:33,963:INFO:Defining folds
2024-08-26 16:27:33,964:INFO:Declaring metric variables
2024-08-26 16:27:33,971:INFO:Importing untrained model
2024-08-26 16:27:33,979:INFO:Random Forest Classifier Imported successfully
2024-08-26 16:27:33,995:INFO:Starting cross validation
2024-08-26 16:27:33,999:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-08-26 16:27:44,268:INFO:Calculating mean and std
2024-08-26 16:27:44,271:INFO:Creating metrics dataframe
2024-08-26 16:27:44,277:INFO:Uploading results into container
2024-08-26 16:27:44,279:INFO:Uploading model into container now
2024-08-26 16:27:44,280:INFO:_master_model_container: 7
2024-08-26 16:27:44,281:INFO:_display_container: 2
2024-08-26 16:27:44,282:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=8607, verbose=0,
                       warm_start=False)
2024-08-26 16:27:44,283:INFO:create_model() successfully completed......................................
2024-08-26 16:27:44,489:INFO:SubProcess create_model() end ==================================
2024-08-26 16:27:44,489:INFO:Creating metrics dataframe
2024-08-26 16:27:44,511:INFO:Initializing Quadratic Discriminant Analysis
2024-08-26 16:27:44,511:INFO:Total runtime is 0.9015750686327617 minutes
2024-08-26 16:27:44,518:INFO:SubProcess create_model() called ==================================
2024-08-26 16:27:44,519:INFO:Initializing create_model()
2024-08-26 16:27:44,519:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023F0BA33290>, estimator=qda, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023F0BC0D750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-26 16:27:44,519:INFO:Checking exceptions
2024-08-26 16:27:44,519:INFO:Importing libraries
2024-08-26 16:27:44,519:INFO:Copying training dataset
2024-08-26 16:27:44,539:INFO:Defining folds
2024-08-26 16:27:44,540:INFO:Declaring metric variables
2024-08-26 16:27:44,546:INFO:Importing untrained model
2024-08-26 16:27:44,552:INFO:Quadratic Discriminant Analysis Imported successfully
2024-08-26 16:27:44,567:INFO:Starting cross validation
2024-08-26 16:27:44,575:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-08-26 16:27:46,226:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-08-26 16:27:46,230:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-08-26 16:27:46,337:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-08-26 16:27:46,426:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-08-26 16:27:46,661:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-26 16:27:46,824:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-26 16:27:46,860:INFO:Calculating mean and std
2024-08-26 16:27:46,863:INFO:Creating metrics dataframe
2024-08-26 16:27:46,867:INFO:Uploading results into container
2024-08-26 16:27:46,868:INFO:Uploading model into container now
2024-08-26 16:27:46,869:INFO:_master_model_container: 8
2024-08-26 16:27:46,869:INFO:_display_container: 2
2024-08-26 16:27:46,870:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-08-26 16:27:46,870:INFO:create_model() successfully completed......................................
2024-08-26 16:27:47,060:INFO:SubProcess create_model() end ==================================
2024-08-26 16:27:47,061:INFO:Creating metrics dataframe
2024-08-26 16:27:47,087:INFO:Initializing Ada Boost Classifier
2024-08-26 16:27:47,087:INFO:Total runtime is 0.9445047736167909 minutes
2024-08-26 16:27:47,094:INFO:SubProcess create_model() called ==================================
2024-08-26 16:27:47,094:INFO:Initializing create_model()
2024-08-26 16:27:47,095:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023F0BA33290>, estimator=ada, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023F0BC0D750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-26 16:27:47,095:INFO:Checking exceptions
2024-08-26 16:27:47,095:INFO:Importing libraries
2024-08-26 16:27:47,095:INFO:Copying training dataset
2024-08-26 16:27:47,117:INFO:Defining folds
2024-08-26 16:27:47,117:INFO:Declaring metric variables
2024-08-26 16:27:47,124:INFO:Importing untrained model
2024-08-26 16:27:47,130:INFO:Ada Boost Classifier Imported successfully
2024-08-26 16:27:47,144:INFO:Starting cross validation
2024-08-26 16:27:47,149:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-08-26 16:27:48,604:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-08-26 16:27:48,677:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-08-26 16:27:48,724:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-08-26 16:27:48,782:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-08-26 16:27:56,367:INFO:Calculating mean and std
2024-08-26 16:27:56,370:INFO:Creating metrics dataframe
2024-08-26 16:27:56,378:INFO:Uploading results into container
2024-08-26 16:27:56,381:INFO:Uploading model into container now
2024-08-26 16:27:56,382:INFO:_master_model_container: 9
2024-08-26 16:27:56,383:INFO:_display_container: 2
2024-08-26 16:27:56,385:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=8607)
2024-08-26 16:27:56,385:INFO:create_model() successfully completed......................................
2024-08-26 16:27:56,595:INFO:SubProcess create_model() end ==================================
2024-08-26 16:27:56,596:INFO:Creating metrics dataframe
2024-08-26 16:27:56,617:INFO:Initializing Gradient Boosting Classifier
2024-08-26 16:27:56,618:INFO:Total runtime is 1.103337029616038 minutes
2024-08-26 16:27:56,624:INFO:SubProcess create_model() called ==================================
2024-08-26 16:27:56,625:INFO:Initializing create_model()
2024-08-26 16:27:56,625:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023F0BA33290>, estimator=gbc, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023F0BC0D750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-26 16:27:56,626:INFO:Checking exceptions
2024-08-26 16:27:56,626:INFO:Importing libraries
2024-08-26 16:27:56,626:INFO:Copying training dataset
2024-08-26 16:27:56,651:INFO:Defining folds
2024-08-26 16:27:56,651:INFO:Declaring metric variables
2024-08-26 16:27:56,659:INFO:Importing untrained model
2024-08-26 16:27:56,669:INFO:Gradient Boosting Classifier Imported successfully
2024-08-26 16:27:56,682:INFO:Starting cross validation
2024-08-26 16:27:56,689:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-08-26 16:28:29,794:INFO:Calculating mean and std
2024-08-26 16:28:29,798:INFO:Creating metrics dataframe
2024-08-26 16:28:29,803:INFO:Uploading results into container
2024-08-26 16:28:29,804:INFO:Uploading model into container now
2024-08-26 16:28:29,806:INFO:_master_model_container: 10
2024-08-26 16:28:29,806:INFO:_display_container: 2
2024-08-26 16:28:29,808:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8607, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-08-26 16:28:29,808:INFO:create_model() successfully completed......................................
2024-08-26 16:28:30,017:INFO:SubProcess create_model() end ==================================
2024-08-26 16:28:30,017:INFO:Creating metrics dataframe
2024-08-26 16:28:30,045:INFO:Initializing Linear Discriminant Analysis
2024-08-26 16:28:30,045:INFO:Total runtime is 1.6604786475499473 minutes
2024-08-26 16:28:30,052:INFO:SubProcess create_model() called ==================================
2024-08-26 16:28:30,052:INFO:Initializing create_model()
2024-08-26 16:28:30,052:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023F0BA33290>, estimator=lda, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023F0BC0D750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-26 16:28:30,053:INFO:Checking exceptions
2024-08-26 16:28:30,053:INFO:Importing libraries
2024-08-26 16:28:30,054:INFO:Copying training dataset
2024-08-26 16:28:30,082:INFO:Defining folds
2024-08-26 16:28:30,082:INFO:Declaring metric variables
2024-08-26 16:28:30,089:INFO:Importing untrained model
2024-08-26 16:28:30,105:INFO:Linear Discriminant Analysis Imported successfully
2024-08-26 16:28:30,120:INFO:Starting cross validation
2024-08-26 16:28:30,125:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-08-26 16:28:32,696:INFO:Calculating mean and std
2024-08-26 16:28:32,699:INFO:Creating metrics dataframe
2024-08-26 16:28:32,704:INFO:Uploading results into container
2024-08-26 16:28:32,705:INFO:Uploading model into container now
2024-08-26 16:28:32,706:INFO:_master_model_container: 11
2024-08-26 16:28:32,707:INFO:_display_container: 2
2024-08-26 16:28:32,708:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-08-26 16:28:32,710:INFO:create_model() successfully completed......................................
2024-08-26 16:28:32,897:INFO:SubProcess create_model() end ==================================
2024-08-26 16:28:32,897:INFO:Creating metrics dataframe
2024-08-26 16:28:32,921:INFO:Initializing Extra Trees Classifier
2024-08-26 16:28:32,922:INFO:Total runtime is 1.708431128660838 minutes
2024-08-26 16:28:32,930:INFO:SubProcess create_model() called ==================================
2024-08-26 16:28:32,931:INFO:Initializing create_model()
2024-08-26 16:28:32,931:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023F0BA33290>, estimator=et, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023F0BC0D750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-26 16:28:32,932:INFO:Checking exceptions
2024-08-26 16:28:32,932:INFO:Importing libraries
2024-08-26 16:28:32,932:INFO:Copying training dataset
2024-08-26 16:28:32,959:INFO:Defining folds
2024-08-26 16:28:32,960:INFO:Declaring metric variables
2024-08-26 16:28:32,967:INFO:Importing untrained model
2024-08-26 16:28:32,975:INFO:Extra Trees Classifier Imported successfully
2024-08-26 16:28:32,990:INFO:Starting cross validation
2024-08-26 16:28:32,997:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-08-26 16:28:39,980:INFO:Calculating mean and std
2024-08-26 16:28:39,982:INFO:Creating metrics dataframe
2024-08-26 16:28:39,987:INFO:Uploading results into container
2024-08-26 16:28:39,989:INFO:Uploading model into container now
2024-08-26 16:28:39,991:INFO:_master_model_container: 12
2024-08-26 16:28:39,991:INFO:_display_container: 2
2024-08-26 16:28:39,993:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=8607, verbose=0,
                     warm_start=False)
2024-08-26 16:28:39,994:INFO:create_model() successfully completed......................................
2024-08-26 16:28:40,206:INFO:SubProcess create_model() end ==================================
2024-08-26 16:28:40,206:INFO:Creating metrics dataframe
2024-08-26 16:28:40,232:INFO:Initializing Light Gradient Boosting Machine
2024-08-26 16:28:40,232:INFO:Total runtime is 1.8302656610806785 minutes
2024-08-26 16:28:40,239:INFO:SubProcess create_model() called ==================================
2024-08-26 16:28:40,239:INFO:Initializing create_model()
2024-08-26 16:28:40,239:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023F0BA33290>, estimator=lightgbm, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023F0BC0D750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-26 16:28:40,239:INFO:Checking exceptions
2024-08-26 16:28:40,240:INFO:Importing libraries
2024-08-26 16:28:40,240:INFO:Copying training dataset
2024-08-26 16:28:40,263:INFO:Defining folds
2024-08-26 16:28:40,263:INFO:Declaring metric variables
2024-08-26 16:28:40,270:INFO:Importing untrained model
2024-08-26 16:28:40,276:INFO:Light Gradient Boosting Machine Imported successfully
2024-08-26 16:28:40,293:INFO:Starting cross validation
2024-08-26 16:28:40,301:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-08-26 16:28:44,875:INFO:Calculating mean and std
2024-08-26 16:28:44,878:INFO:Creating metrics dataframe
2024-08-26 16:28:44,884:INFO:Uploading results into container
2024-08-26 16:28:44,886:INFO:Uploading model into container now
2024-08-26 16:28:44,887:INFO:_master_model_container: 13
2024-08-26 16:28:44,888:INFO:_display_container: 2
2024-08-26 16:28:44,889:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=8607, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-08-26 16:28:44,889:INFO:create_model() successfully completed......................................
2024-08-26 16:28:45,089:INFO:SubProcess create_model() end ==================================
2024-08-26 16:28:45,090:INFO:Creating metrics dataframe
2024-08-26 16:28:45,120:INFO:Initializing Dummy Classifier
2024-08-26 16:28:45,121:INFO:Total runtime is 1.9117420395215354 minutes
2024-08-26 16:28:45,131:INFO:SubProcess create_model() called ==================================
2024-08-26 16:28:45,132:INFO:Initializing create_model()
2024-08-26 16:28:45,132:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023F0BA33290>, estimator=dummy, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023F0BC0D750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-26 16:28:45,133:INFO:Checking exceptions
2024-08-26 16:28:45,133:INFO:Importing libraries
2024-08-26 16:28:45,133:INFO:Copying training dataset
2024-08-26 16:28:45,168:INFO:Defining folds
2024-08-26 16:28:45,169:INFO:Declaring metric variables
2024-08-26 16:28:45,179:INFO:Importing untrained model
2024-08-26 16:28:45,187:INFO:Dummy Classifier Imported successfully
2024-08-26 16:28:45,201:INFO:Starting cross validation
2024-08-26 16:28:45,210:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-08-26 16:28:47,141:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-26 16:28:47,160:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-26 16:28:47,180:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-26 16:28:47,213:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-26 16:28:47,245:INFO:Calculating mean and std
2024-08-26 16:28:47,247:INFO:Creating metrics dataframe
2024-08-26 16:28:47,252:INFO:Uploading results into container
2024-08-26 16:28:47,252:INFO:Uploading model into container now
2024-08-26 16:28:47,253:INFO:_master_model_container: 14
2024-08-26 16:28:47,253:INFO:_display_container: 2
2024-08-26 16:28:47,253:INFO:DummyClassifier(constant=None, random_state=8607, strategy='prior')
2024-08-26 16:28:47,254:INFO:create_model() successfully completed......................................
2024-08-26 16:28:47,469:INFO:SubProcess create_model() end ==================================
2024-08-26 16:28:47,470:INFO:Creating metrics dataframe
2024-08-26 16:28:47,519:INFO:Initializing create_model()
2024-08-26 16:28:47,519:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023F0BA33290>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8607, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-26 16:28:47,520:INFO:Checking exceptions
2024-08-26 16:28:47,525:INFO:Importing libraries
2024-08-26 16:28:47,525:INFO:Copying training dataset
2024-08-26 16:28:47,557:INFO:Defining folds
2024-08-26 16:28:47,558:INFO:Declaring metric variables
2024-08-26 16:28:47,558:INFO:Importing untrained model
2024-08-26 16:28:47,558:INFO:Declaring custom model
2024-08-26 16:28:47,560:INFO:Gradient Boosting Classifier Imported successfully
2024-08-26 16:28:47,565:INFO:Cross validation set to False
2024-08-26 16:28:47,565:INFO:Fitting Model
2024-08-26 16:29:21,768:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8607, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-08-26 16:29:21,769:INFO:create_model() successfully completed......................................
2024-08-26 16:29:22,013:INFO:_master_model_container: 14
2024-08-26 16:29:22,013:INFO:_display_container: 2
2024-08-26 16:29:22,014:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8607, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-08-26 16:29:22,014:INFO:compare_models() successfully completed......................................
2024-08-26 16:29:22,046:INFO:Initializing plot_model()
2024-08-26 16:29:22,047:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023F0BA33290>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8607, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-08-26 16:29:22,047:INFO:Checking exceptions
2024-08-26 16:29:22,065:INFO:Preloading libraries
2024-08-26 16:29:22,087:INFO:Copying training dataset
2024-08-26 16:29:22,087:INFO:Plot type: feature
2024-08-26 16:29:22,089:WARNING:No coef_ found. Trying feature_importances_
2024-08-26 16:29:22,619:INFO:Visual Rendered Successfully
2024-08-26 16:29:22,828:INFO:plot_model() successfully completed......................................
2024-08-26 16:29:22,844:INFO:Initializing plot_model()
2024-08-26 16:29:22,845:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023F0BA33290>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8607, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-08-26 16:29:22,845:INFO:Checking exceptions
2024-08-26 16:29:22,863:INFO:Preloading libraries
2024-08-26 16:29:22,884:INFO:Copying training dataset
2024-08-26 16:29:22,884:INFO:Plot type: auc
2024-08-26 16:29:23,218:INFO:Fitting Model
2024-08-26 16:29:23,223:INFO:Scoring test/hold-out set
2024-08-26 16:29:23,858:INFO:Visual Rendered Successfully
2024-08-26 16:29:24,057:INFO:plot_model() successfully completed......................................
2024-08-26 16:29:24,156:INFO:Initializing save_model()
2024-08-26 16:29:24,156:INFO:save_model(model=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8607, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), model_name=LR Model Aula 5 062022, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\natha\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean')...
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=QuantileTransformer(copy=True,
                                                                    ignore_implicit_zeros=False,
                                                                    n_quantiles=1000,
                                                                    output_distribution='normal',
                                                                    random_state=8607,
                                                                    subsample=10000))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-08-26 16:29:24,157:INFO:Adding model into prep_pipe
2024-08-26 16:29:24,203:INFO:LR Model Aula 5 062022.pkl saved in current working directory
2024-08-26 16:29:24,307:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWra...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.1, loss='log_loss',
                                            max_depth=3, max_features=None,
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.0,
                                            min_samples_leaf=1,
                                            min_samples_split=2,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=100,
                                            n_iter_no_change=None,
                                            random_state=8607, subsample=1.0,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2024-08-26 16:29:24,307:INFO:save_model() successfully completed......................................
2024-08-26 16:29:24,555:INFO:Initializing load_model()
2024-08-26 16:29:24,555:INFO:load_model(model_name=LR Model Aula 5 062022, platform=None, authentication=None, verbose=True)
2024-08-26 16:29:24,705:INFO:PyCaret ClassificationExperiment
2024-08-26 16:29:24,705:INFO:Logging name: clf-default-name
2024-08-26 16:29:24,705:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-08-26 16:29:24,705:INFO:version 3.3.2
2024-08-26 16:29:24,705:INFO:Initializing setup()
2024-08-26 16:29:24,706:INFO:self.USI: c644
2024-08-26 16:29:24,706:INFO:self._variable_keys: {'data', 'is_multiclass', 'y_train', 'html_param', '_ml_usecase', 'exp_name_log', 'fold_groups_param', 'y', 'memory', 'n_jobs_param', 'X', 'X_train', 'idx', 'y_test', 'logging_param', 'fix_imbalance', 'seed', 'fold_generator', 'log_plots_param', 'USI', 'target_param', 'pipeline', 'fold_shuffle_param', 'gpu_param', 'gpu_n_jobs_param', '_available_plots', 'X_test', 'exp_id'}
2024-08-26 16:29:24,706:INFO:Checking environment
2024-08-26 16:29:24,706:INFO:python_version: 3.11.5
2024-08-26 16:29:24,706:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-08-26 16:29:24,706:INFO:machine: AMD64
2024-08-26 16:29:24,706:INFO:platform: Windows-10-10.0.22631-SP0
2024-08-26 16:29:24,706:INFO:Memory: svmem(total=8311836672, available=899821568, percent=89.2, used=7412015104, free=899821568)
2024-08-26 16:29:24,707:INFO:Physical Core: 4
2024-08-26 16:29:24,707:INFO:Logical Core: 8
2024-08-26 16:29:24,707:INFO:Checking libraries
2024-08-26 16:29:24,707:INFO:System:
2024-08-26 16:29:24,707:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-08-26 16:29:24,707:INFO:executable: C:\Users\natha\anaconda3\python.exe
2024-08-26 16:29:24,707:INFO:   machine: Windows-10-10.0.22631-SP0
2024-08-26 16:29:24,707:INFO:PyCaret required dependencies:
2024-08-26 16:29:24,708:INFO:                 pip: 23.2.1
2024-08-26 16:29:24,708:INFO:          setuptools: 68.0.0
2024-08-26 16:29:24,708:INFO:             pycaret: 3.3.2
2024-08-26 16:29:24,708:INFO:             IPython: 8.15.0
2024-08-26 16:29:24,708:INFO:          ipywidgets: 8.0.4
2024-08-26 16:29:24,708:INFO:                tqdm: 4.65.0
2024-08-26 16:29:24,708:INFO:               numpy: 1.24.3
2024-08-26 16:29:24,708:INFO:              pandas: 2.0.3
2024-08-26 16:29:24,708:INFO:              jinja2: 3.1.2
2024-08-26 16:29:24,708:INFO:               scipy: 1.11.1
2024-08-26 16:29:24,709:INFO:              joblib: 1.3.2
2024-08-26 16:29:24,709:INFO:             sklearn: 1.4.2
2024-08-26 16:29:24,709:INFO:                pyod: 2.0.1
2024-08-26 16:29:24,709:INFO:            imblearn: 0.12.3
2024-08-26 16:29:24,709:INFO:   category_encoders: 2.6.3
2024-08-26 16:29:24,709:INFO:            lightgbm: 4.5.0
2024-08-26 16:29:24,709:INFO:               numba: 0.57.1
2024-08-26 16:29:24,709:INFO:            requests: 2.31.0
2024-08-26 16:29:24,709:INFO:          matplotlib: 3.7.2
2024-08-26 16:29:24,709:INFO:          scikitplot: 0.3.7
2024-08-26 16:29:24,710:INFO:         yellowbrick: 1.5
2024-08-26 16:29:24,710:INFO:              plotly: 5.23.0
2024-08-26 16:29:24,710:INFO:    plotly-resampler: Not installed
2024-08-26 16:29:24,710:INFO:             kaleido: 0.2.1
2024-08-26 16:29:24,710:INFO:           schemdraw: 0.15
2024-08-26 16:29:24,710:INFO:         statsmodels: 0.14.0
2024-08-26 16:29:24,710:INFO:              sktime: 0.26.0
2024-08-26 16:29:24,710:INFO:               tbats: 1.1.3
2024-08-26 16:29:24,710:INFO:            pmdarima: 2.0.4
2024-08-26 16:29:24,710:INFO:              psutil: 5.9.0
2024-08-26 16:29:24,711:INFO:          markupsafe: 2.1.1
2024-08-26 16:29:24,711:INFO:             pickle5: Not installed
2024-08-26 16:29:24,711:INFO:         cloudpickle: 2.2.1
2024-08-26 16:29:24,711:INFO:         deprecation: 2.1.0
2024-08-26 16:29:24,711:INFO:              xxhash: 2.0.2
2024-08-26 16:29:24,711:INFO:           wurlitzer: Not installed
2024-08-26 16:29:24,711:INFO:PyCaret optional dependencies:
2024-08-26 16:29:24,711:INFO:                shap: Not installed
2024-08-26 16:29:24,711:INFO:           interpret: Not installed
2024-08-26 16:29:24,712:INFO:                umap: Not installed
2024-08-26 16:29:24,712:INFO:     ydata_profiling: 4.7.0
2024-08-26 16:29:24,712:INFO:  explainerdashboard: Not installed
2024-08-26 16:29:24,712:INFO:             autoviz: Not installed
2024-08-26 16:29:24,712:INFO:           fairlearn: Not installed
2024-08-26 16:29:24,712:INFO:          deepchecks: Not installed
2024-08-26 16:29:24,712:INFO:             xgboost: Not installed
2024-08-26 16:29:24,712:INFO:            catboost: Not installed
2024-08-26 16:29:24,712:INFO:              kmodes: Not installed
2024-08-26 16:29:24,712:INFO:             mlxtend: Not installed
2024-08-26 16:29:24,713:INFO:       statsforecast: Not installed
2024-08-26 16:29:24,713:INFO:        tune_sklearn: Not installed
2024-08-26 16:29:24,713:INFO:                 ray: Not installed
2024-08-26 16:29:24,713:INFO:            hyperopt: Not installed
2024-08-26 16:29:24,713:INFO:              optuna: Not installed
2024-08-26 16:29:24,713:INFO:               skopt: Not installed
2024-08-26 16:29:24,713:INFO:              mlflow: Not installed
2024-08-26 16:29:24,713:INFO:              gradio: Not installed
2024-08-26 16:29:24,713:INFO:             fastapi: Not installed
2024-08-26 16:29:24,713:INFO:             uvicorn: Not installed
2024-08-26 16:29:24,713:INFO:              m2cgen: Not installed
2024-08-26 16:29:24,714:INFO:           evidently: Not installed
2024-08-26 16:29:24,714:INFO:               fugue: Not installed
2024-08-26 16:29:24,714:INFO:           streamlit: Not installed
2024-08-26 16:29:24,714:INFO:             prophet: Not installed
2024-08-26 16:29:24,714:INFO:None
2024-08-26 16:29:24,714:INFO:Set up data.
2024-08-26 16:29:25,331:INFO:Set up folding strategy.
2024-08-26 16:29:25,332:INFO:Set up train/test split.
2024-08-26 16:29:26,592:INFO:Set up index.
2024-08-26 16:29:26,659:INFO:Assigning column types.
2024-08-26 16:29:27,653:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-08-26 16:29:27,771:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-26 16:29:27,773:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-26 16:29:27,847:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 16:29:27,848:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 16:29:27,967:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-26 16:29:27,969:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-26 16:29:28,045:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 16:29:28,046:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 16:29:28,048:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-08-26 16:29:28,169:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-26 16:29:28,243:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 16:29:28,244:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 16:29:28,365:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-26 16:29:28,442:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 16:29:28,442:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 16:29:28,444:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-08-26 16:29:28,644:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 16:29:28,645:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 16:29:28,837:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 16:29:28,838:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 16:29:28,842:INFO:Preparing preprocessing pipeline...
2024-08-26 16:29:29,009:INFO:Set up date feature engineering.
2024-08-26 16:29:29,009:INFO:Set up simple imputation.
2024-08-26 16:29:29,009:INFO:Set up removing multicollinearity.
2024-08-26 16:29:29,009:INFO:Set up binning of numerical features.
2024-08-26 16:29:29,324:INFO:Set up column transformation.
2024-08-26 16:29:29,325:INFO:Set up feature normalization.
2024-08-26 16:29:29,485:INFO:Set up column name cleaning.
2024-08-26 16:30:37,837:INFO:Finished creating preprocessing pipeline.
2024-08-26 16:30:37,896:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\natha\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pess...
                                    transformer=PowerTransformer(copy=True,
                                                                 method='yeo-johnson',
                                                                 standardize=False))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2024-08-26 16:30:37,897:INFO:Creating final display dataframe.
2024-08-26 16:30:51,224:INFO:Setup _display_container:                     Description             Value
0                    Session id              3061
1                        Target               mau
2                   Target type            Binary
3           Original data shape      (750000, 36)
4        Transformed data shape      (750000, 38)
5   Transformed train set shape      (525000, 38)
6    Transformed test set shape      (225000, 38)
7              Numeric features                 7
8                 Date features                 1
9      Rows with missing values             16.8%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Remove multicollinearity              True
15  Multicollinearity threshold              0.95
16               Transformation              True
17        Transformation method       yeo-johnson
18                    Normalize              True
19             Normalize method            zscore
20               Fold Generator   StratifiedKFold
21                  Fold Number                10
22                     CPU Jobs                -1
23                      Use GPU             False
24               Log Experiment             False
25              Experiment Name  clf-default-name
26                          USI              c644
2024-08-26 16:30:51,834:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 16:30:51,845:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 16:30:52,103:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 16:30:52,104:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 16:30:52,121:INFO:setup() successfully completed in 87.48s...............
2024-08-26 16:30:52,300:INFO:Initializing create_model()
2024-08-26 16:30:52,301:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023F5BE20910>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-26 16:30:52,301:INFO:Checking exceptions
2024-08-26 16:30:52,400:INFO:Importing libraries
2024-08-26 16:30:52,400:INFO:Copying training dataset
2024-08-26 16:30:53,959:INFO:Defining folds
2024-08-26 16:30:53,960:INFO:Declaring metric variables
2024-08-26 16:30:53,973:INFO:Importing untrained model
2024-08-26 16:30:53,983:INFO:Light Gradient Boosting Machine Imported successfully
2024-08-26 16:30:54,001:INFO:Starting cross validation
2024-08-26 16:30:54,009:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-26 16:31:04,358:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 16:31:04,418:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 16:31:04,839:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 16:31:05,225:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 16:31:05,311:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 16:31:06,967:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2024-08-26 16:31:07,225:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 16:31:07,893:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 16:31:08,828:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 16:31:11,952:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2024-08-26 16:32:53,452:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 16:32:53,853:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 16:33:57,156:INFO:Calculating mean and std
2024-08-26 16:33:57,175:INFO:Creating metrics dataframe
2024-08-26 16:33:57,248:INFO:Finalizing model
2024-08-26 16:34:57,872:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-08-26 16:34:57,876:INFO:[LightGBM] [Info] Number of positive: 41050, number of negative: 483950
2024-08-26 16:34:58,124:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.081849 seconds.
2024-08-26 16:34:58,124:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-26 16:34:58,124:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-26 16:34:58,125:INFO:[LightGBM] [Info] Total Bins 385
2024-08-26 16:34:58,126:INFO:[LightGBM] [Info] Number of data points in the train set: 525000, number of used features: 36
2024-08-26 16:34:58,133:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.078190 -> initscore=-2.467191
2024-08-26 16:34:58,133:INFO:[LightGBM] [Info] Start training from score -2.467191
2024-08-26 16:34:58,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 16:34:58,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 16:34:58,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 16:34:58,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 16:34:58,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 16:34:58,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 16:34:58,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 16:34:58,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 16:34:58,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 16:34:58,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 16:34:58,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 16:34:58,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 16:34:58,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 16:34:58,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 16:34:58,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 16:34:58,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 16:34:58,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 16:34:58,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 16:34:58,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 16:34:58,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 16:34:58,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 16:34:58,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 16:34:58,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 16:34:58,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 16:34:58,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 16:34:58,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 16:34:58,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 16:34:58,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 16:34:58,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 16:34:58,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 16:34:58,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 16:34:58,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 16:34:58,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 16:34:58,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 16:34:58,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 16:34:58,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 16:34:58,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 16:34:58,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 16:34:58,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 16:34:58,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 16:34:58,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 16:34:58,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 16:34:58,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 16:34:58,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 16:34:58,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 16:34:58,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 16:34:58,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 16:34:58,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 16:34:58,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 16:34:58,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 16:34:58,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 16:34:59,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 16:34:59,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 16:34:59,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 16:34:59,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 16:34:59,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 16:34:59,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 16:34:59,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 16:34:59,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 16:34:59,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 16:34:59,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 16:34:59,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 16:34:59,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 16:34:59,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 16:34:59,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 16:34:59,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 16:34:59,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 16:34:59,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 16:34:59,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 16:34:59,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 16:34:59,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 16:34:59,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 16:34:59,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 16:34:59,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 16:34:59,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 16:34:59,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 16:34:59,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 16:34:59,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 16:34:59,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 16:34:59,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 16:34:59,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 16:34:59,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 16:34:59,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 16:34:59,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 16:34:59,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 16:34:59,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 16:34:59,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 16:34:59,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 16:34:59,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 16:34:59,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 16:34:59,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 16:34:59,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 16:34:59,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 16:34:59,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 16:34:59,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 16:34:59,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 16:34:59,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 16:34:59,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 16:34:59,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 16:34:59,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 16:34:59,934:INFO:Uploading results into container
2024-08-26 16:34:59,937:INFO:Uploading model into container now
2024-08-26 16:34:59,994:INFO:_master_model_container: 1
2024-08-26 16:34:59,994:INFO:_display_container: 2
2024-08-26 16:34:59,997:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3061, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-08-26 16:34:59,998:INFO:create_model() successfully completed......................................
2024-08-26 16:35:01,287:INFO:Initializing tune_model()
2024-08-26 16:35:01,287:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023F5BE20910>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3061, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-08-26 16:35:01,288:INFO:Checking exceptions
2024-08-26 16:35:02,260:INFO:Copying training dataset
2024-08-26 16:35:03,233:INFO:Checking base model
2024-08-26 16:35:03,233:INFO:Base model : Light Gradient Boosting Machine
2024-08-26 16:35:03,238:INFO:Declaring metric variables
2024-08-26 16:35:03,245:INFO:Defining Hyperparameters
2024-08-26 16:35:03,448:INFO:Tuning with n_jobs=-1
2024-08-26 16:35:03,449:INFO:Initializing RandomizedSearchCV
2024-08-26 16:35:11,617:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 16:35:12,317:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 16:35:12,882:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 16:35:13,323:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 16:35:13,482:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 16:35:13,678:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 16:35:14,311:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 16:35:14,869:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 16:35:14,943:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2024-08-26 16:35:17,622:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2024-08-26 16:36:58,130:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 16:36:59,436:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 16:36:59,494:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 16:36:59,527:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 16:36:59,837:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 16:36:59,966:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 16:37:00,668:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 16:37:02,754:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2024-08-26 16:37:02,895:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 16:38:44,649:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 16:38:46,000:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 16:38:48,714:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2024-08-26 16:39:07,891:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 16:39:08,198:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 16:39:08,539:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 16:39:11,084:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 16:39:11,646:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 16:39:13,816:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2024-08-26 16:39:20,218:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 16:40:57,829:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 16:41:07,201:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 16:41:20,653:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 16:41:23,913:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 16:41:26,984:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2024-08-26 16:41:53,994:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 16:42:03,201:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 16:42:03,205:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 16:42:21,472:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 16:42:24,369:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2024-08-26 16:56:23,347:INFO:gpu_param set to False
2024-08-26 16:56:23,536:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 16:56:23,537:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 16:56:23,737:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 16:56:23,738:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 16:56:29,861:INFO:PyCaret ClassificationExperiment
2024-08-26 16:56:29,862:INFO:Logging name: credit_1
2024-08-26 16:56:29,862:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-08-26 16:56:29,862:INFO:version 3.3.2
2024-08-26 16:56:29,862:INFO:Initializing setup()
2024-08-26 16:56:29,862:INFO:self.USI: 7bda
2024-08-26 16:56:29,862:INFO:self._variable_keys: {'data', 'is_multiclass', 'y_train', 'html_param', '_ml_usecase', 'exp_name_log', 'fold_groups_param', 'y', 'memory', 'n_jobs_param', 'X', 'X_train', 'idx', 'y_test', 'logging_param', 'fix_imbalance', 'seed', 'fold_generator', 'log_plots_param', 'USI', 'target_param', 'pipeline', 'fold_shuffle_param', 'gpu_param', 'gpu_n_jobs_param', '_available_plots', 'X_test', 'exp_id'}
2024-08-26 16:56:29,862:INFO:Checking environment
2024-08-26 16:56:29,863:INFO:python_version: 3.11.5
2024-08-26 16:56:29,863:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-08-26 16:56:29,863:INFO:machine: AMD64
2024-08-26 16:56:29,863:INFO:platform: Windows-10-10.0.22631-SP0
2024-08-26 16:56:29,863:INFO:Memory: svmem(total=8311836672, available=1535299584, percent=81.5, used=6776537088, free=1535299584)
2024-08-26 16:56:29,864:INFO:Physical Core: 4
2024-08-26 16:56:29,864:INFO:Logical Core: 8
2024-08-26 16:56:29,864:INFO:Checking libraries
2024-08-26 16:56:29,864:INFO:System:
2024-08-26 16:56:29,864:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-08-26 16:56:29,864:INFO:executable: C:\Users\natha\anaconda3\python.exe
2024-08-26 16:56:29,865:INFO:   machine: Windows-10-10.0.22631-SP0
2024-08-26 16:56:29,865:INFO:PyCaret required dependencies:
2024-08-26 16:56:29,865:INFO:                 pip: 23.2.1
2024-08-26 16:56:29,865:INFO:          setuptools: 68.0.0
2024-08-26 16:56:29,865:INFO:             pycaret: 3.3.2
2024-08-26 16:56:29,865:INFO:             IPython: 8.15.0
2024-08-26 16:56:29,865:INFO:          ipywidgets: 8.0.4
2024-08-26 16:56:29,865:INFO:                tqdm: 4.65.0
2024-08-26 16:56:29,865:INFO:               numpy: 1.24.3
2024-08-26 16:56:29,866:INFO:              pandas: 2.0.3
2024-08-26 16:56:29,866:INFO:              jinja2: 3.1.2
2024-08-26 16:56:29,866:INFO:               scipy: 1.11.1
2024-08-26 16:56:29,866:INFO:              joblib: 1.3.2
2024-08-26 16:56:29,866:INFO:             sklearn: 1.4.2
2024-08-26 16:56:29,866:INFO:                pyod: 2.0.1
2024-08-26 16:56:29,866:INFO:            imblearn: 0.12.3
2024-08-26 16:56:29,866:INFO:   category_encoders: 2.6.3
2024-08-26 16:56:29,867:INFO:            lightgbm: 4.5.0
2024-08-26 16:56:29,867:INFO:               numba: 0.57.1
2024-08-26 16:56:29,867:INFO:            requests: 2.31.0
2024-08-26 16:56:29,867:INFO:          matplotlib: 3.7.2
2024-08-26 16:56:29,867:INFO:          scikitplot: 0.3.7
2024-08-26 16:56:29,867:INFO:         yellowbrick: 1.5
2024-08-26 16:56:29,867:INFO:              plotly: 5.23.0
2024-08-26 16:56:29,867:INFO:    plotly-resampler: Not installed
2024-08-26 16:56:29,867:INFO:             kaleido: 0.2.1
2024-08-26 16:56:29,867:INFO:           schemdraw: 0.15
2024-08-26 16:56:29,867:INFO:         statsmodels: 0.14.0
2024-08-26 16:56:29,867:INFO:              sktime: 0.26.0
2024-08-26 16:56:29,867:INFO:               tbats: 1.1.3
2024-08-26 16:56:29,867:INFO:            pmdarima: 2.0.4
2024-08-26 16:56:29,868:INFO:              psutil: 5.9.0
2024-08-26 16:56:29,868:INFO:          markupsafe: 2.1.1
2024-08-26 16:56:29,868:INFO:             pickle5: Not installed
2024-08-26 16:56:29,868:INFO:         cloudpickle: 2.2.1
2024-08-26 16:56:29,868:INFO:         deprecation: 2.1.0
2024-08-26 16:56:29,868:INFO:              xxhash: 2.0.2
2024-08-26 16:56:29,868:INFO:           wurlitzer: Not installed
2024-08-26 16:56:29,868:INFO:PyCaret optional dependencies:
2024-08-26 16:56:29,869:INFO:                shap: Not installed
2024-08-26 16:56:29,869:INFO:           interpret: Not installed
2024-08-26 16:56:29,869:INFO:                umap: Not installed
2024-08-26 16:56:29,869:INFO:     ydata_profiling: 4.7.0
2024-08-26 16:56:29,869:INFO:  explainerdashboard: Not installed
2024-08-26 16:56:29,869:INFO:             autoviz: Not installed
2024-08-26 16:56:29,869:INFO:           fairlearn: Not installed
2024-08-26 16:56:29,869:INFO:          deepchecks: Not installed
2024-08-26 16:56:29,869:INFO:             xgboost: Not installed
2024-08-26 16:56:29,870:INFO:            catboost: Not installed
2024-08-26 16:56:29,870:INFO:              kmodes: Not installed
2024-08-26 16:56:29,870:INFO:             mlxtend: Not installed
2024-08-26 16:56:29,870:INFO:       statsforecast: Not installed
2024-08-26 16:56:29,870:INFO:        tune_sklearn: Not installed
2024-08-26 16:56:29,870:INFO:                 ray: Not installed
2024-08-26 16:56:29,870:INFO:            hyperopt: Not installed
2024-08-26 16:56:29,870:INFO:              optuna: Not installed
2024-08-26 16:56:29,870:INFO:               skopt: Not installed
2024-08-26 16:56:29,870:INFO:              mlflow: Not installed
2024-08-26 16:56:29,871:INFO:              gradio: Not installed
2024-08-26 16:56:29,871:INFO:             fastapi: Not installed
2024-08-26 16:56:29,871:INFO:             uvicorn: Not installed
2024-08-26 16:56:29,871:INFO:              m2cgen: Not installed
2024-08-26 16:56:29,871:INFO:           evidently: Not installed
2024-08-26 16:56:29,871:INFO:               fugue: Not installed
2024-08-26 16:56:29,871:INFO:           streamlit: Not installed
2024-08-26 16:56:29,871:INFO:             prophet: Not installed
2024-08-26 16:56:29,871:INFO:None
2024-08-26 16:56:29,871:INFO:Set up data.
2024-08-26 16:56:29,896:INFO:Set up folding strategy.
2024-08-26 16:56:29,896:INFO:Set up train/test split.
2024-08-26 16:56:29,915:INFO:Set up index.
2024-08-26 16:56:29,916:INFO:Assigning column types.
2024-08-26 16:56:29,925:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-08-26 16:56:30,048:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-26 16:56:30,050:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-26 16:56:30,124:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 16:56:30,125:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 16:56:30,250:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-26 16:56:30,252:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-26 16:56:30,328:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 16:56:30,329:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 16:56:30,330:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-08-26 16:56:30,450:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-26 16:56:30,523:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 16:56:30,524:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 16:56:30,644:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-26 16:56:30,713:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 16:56:30,714:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 16:56:30,715:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-08-26 16:56:30,920:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 16:56:30,921:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 16:56:31,144:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 16:56:31,145:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 16:56:31,151:INFO:Preparing preprocessing pipeline...
2024-08-26 16:56:31,155:INFO:Set up simple imputation.
2024-08-26 16:56:31,167:INFO:Set up encoding of ordinal features.
2024-08-26 16:56:31,178:INFO:Set up encoding of categorical features.
2024-08-26 16:56:31,178:INFO:Set up imbalanced handling.
2024-08-26 16:56:31,178:INFO:Set up column transformation.
2024-08-26 16:56:31,179:INFO:Set up feature normalization.
2024-08-26 16:56:31,975:INFO:Finished creating preprocessing pipeline.
2024-08-26 16:56:32,059:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\natha\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean')...
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=QuantileTransformer(copy=True,
                                                                    ignore_implicit_zeros=False,
                                                                    n_quantiles=1000,
                                                                    output_distribution='normal',
                                                                    random_state=3260,
                                                                    subsample=10000))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2024-08-26 16:56:32,059:INFO:Creating final display dataframe.
2024-08-26 16:56:33,352:INFO:Setup _display_container:                     Description            Value
0                    Session id             3260
1                        Target              mau
2                   Target type           Binary
3           Original data shape       (4000, 13)
4        Transformed data shape       (6352, 30)
5   Transformed train set shape       (5152, 30)
6    Transformed test set shape       (1200, 30)
7              Numeric features                5
8          Categorical features                7
9      Rows with missing values            16.6%
10                   Preprocess             True
11              Imputation type           simple
12           Numeric imputation             mean
13       Categorical imputation             mode
14     Maximum one-hot encoding               25
15              Encoding method             None
16                Fix imbalance             True
17         Fix imbalance method            SMOTE
18               Transformation             True
19        Transformation method         quantile
20                    Normalize             True
21             Normalize method           zscore
22               Fold Generator  StratifiedKFold
23                  Fold Number               10
24                     CPU Jobs               -1
25                      Use GPU            False
26               Log Experiment            False
27              Experiment Name         credit_1
28                          USI             7bda
2024-08-26 16:56:33,545:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 16:56:33,546:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 16:56:33,730:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 16:56:33,732:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 16:56:33,734:INFO:setup() successfully completed in 4.06s...............
2024-08-26 16:56:33,875:INFO:Initializing compare_models()
2024-08-26 16:56:33,875:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023F3596E710>, include=None, exclude=None, fold=4, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000023F3596E710>, 'include': None, 'exclude': None, 'fold': 4, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-08-26 16:56:33,876:INFO:Checking exceptions
2024-08-26 16:56:33,885:INFO:Preparing display monitor
2024-08-26 16:56:33,939:INFO:Initializing Logistic Regression
2024-08-26 16:56:33,939:INFO:Total runtime is 0.0 minutes
2024-08-26 16:56:33,945:INFO:SubProcess create_model() called ==================================
2024-08-26 16:56:33,945:INFO:Initializing create_model()
2024-08-26 16:56:33,945:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023F3596E710>, estimator=lr, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023F028C6F10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-26 16:56:33,945:INFO:Checking exceptions
2024-08-26 16:56:33,946:INFO:Importing libraries
2024-08-26 16:56:33,946:INFO:Copying training dataset
2024-08-26 16:56:33,960:INFO:Defining folds
2024-08-26 16:56:33,960:INFO:Declaring metric variables
2024-08-26 16:56:33,967:INFO:Importing untrained model
2024-08-26 16:56:33,976:INFO:Logistic Regression Imported successfully
2024-08-26 16:56:33,990:INFO:Starting cross validation
2024-08-26 16:56:33,997:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-08-26 16:56:48,978:INFO:Calculating mean and std
2024-08-26 16:56:48,983:INFO:Creating metrics dataframe
2024-08-26 16:56:48,990:INFO:Uploading results into container
2024-08-26 16:56:48,991:INFO:Uploading model into container now
2024-08-26 16:56:48,993:INFO:_master_model_container: 1
2024-08-26 16:56:48,994:INFO:_display_container: 2
2024-08-26 16:56:48,996:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=3260, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-08-26 16:56:48,996:INFO:create_model() successfully completed......................................
2024-08-26 16:56:49,495:INFO:SubProcess create_model() end ==================================
2024-08-26 16:56:49,495:INFO:Creating metrics dataframe
2024-08-26 16:56:49,515:INFO:Initializing K Neighbors Classifier
2024-08-26 16:56:49,516:INFO:Total runtime is 0.2596318443616231 minutes
2024-08-26 16:56:49,525:INFO:SubProcess create_model() called ==================================
2024-08-26 16:56:49,526:INFO:Initializing create_model()
2024-08-26 16:56:49,526:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023F3596E710>, estimator=knn, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023F028C6F10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-26 16:56:49,526:INFO:Checking exceptions
2024-08-26 16:56:49,527:INFO:Importing libraries
2024-08-26 16:56:49,527:INFO:Copying training dataset
2024-08-26 16:56:49,540:INFO:Defining folds
2024-08-26 16:56:49,541:INFO:Declaring metric variables
2024-08-26 16:56:49,547:INFO:Importing untrained model
2024-08-26 16:56:49,554:INFO:K Neighbors Classifier Imported successfully
2024-08-26 16:56:49,570:INFO:Starting cross validation
2024-08-26 16:56:49,581:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-08-26 16:57:02,789:INFO:Calculating mean and std
2024-08-26 16:57:02,792:INFO:Creating metrics dataframe
2024-08-26 16:57:02,799:INFO:Uploading results into container
2024-08-26 16:57:02,801:INFO:Uploading model into container now
2024-08-26 16:57:02,802:INFO:_master_model_container: 2
2024-08-26 16:57:02,802:INFO:_display_container: 2
2024-08-26 16:57:02,807:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-08-26 16:57:02,807:INFO:create_model() successfully completed......................................
2024-08-26 16:57:03,216:INFO:SubProcess create_model() end ==================================
2024-08-26 16:57:03,217:INFO:Creating metrics dataframe
2024-08-26 16:57:03,235:INFO:Initializing Naive Bayes
2024-08-26 16:57:03,237:INFO:Total runtime is 0.4882986108462016 minutes
2024-08-26 16:57:03,243:INFO:SubProcess create_model() called ==================================
2024-08-26 16:57:03,244:INFO:Initializing create_model()
2024-08-26 16:57:03,245:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023F3596E710>, estimator=nb, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023F028C6F10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-26 16:57:03,245:INFO:Checking exceptions
2024-08-26 16:57:03,245:INFO:Importing libraries
2024-08-26 16:57:03,246:INFO:Copying training dataset
2024-08-26 16:57:03,256:INFO:Defining folds
2024-08-26 16:57:03,257:INFO:Declaring metric variables
2024-08-26 16:57:03,261:INFO:Importing untrained model
2024-08-26 16:57:03,269:INFO:Naive Bayes Imported successfully
2024-08-26 16:57:03,286:INFO:Starting cross validation
2024-08-26 16:57:03,293:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-08-26 16:57:04,900:INFO:Calculating mean and std
2024-08-26 16:57:04,903:INFO:Creating metrics dataframe
2024-08-26 16:57:04,907:INFO:Uploading results into container
2024-08-26 16:57:04,909:INFO:Uploading model into container now
2024-08-26 16:57:04,910:INFO:_master_model_container: 3
2024-08-26 16:57:04,910:INFO:_display_container: 2
2024-08-26 16:57:04,911:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-08-26 16:57:04,912:INFO:create_model() successfully completed......................................
2024-08-26 16:57:05,244:INFO:SubProcess create_model() end ==================================
2024-08-26 16:57:05,244:INFO:Creating metrics dataframe
2024-08-26 16:57:05,264:INFO:Initializing Decision Tree Classifier
2024-08-26 16:57:05,264:INFO:Total runtime is 0.5220894932746887 minutes
2024-08-26 16:57:05,270:INFO:SubProcess create_model() called ==================================
2024-08-26 16:57:05,270:INFO:Initializing create_model()
2024-08-26 16:57:05,271:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023F3596E710>, estimator=dt, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023F028C6F10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-26 16:57:05,271:INFO:Checking exceptions
2024-08-26 16:57:05,271:INFO:Importing libraries
2024-08-26 16:57:05,271:INFO:Copying training dataset
2024-08-26 16:57:05,283:INFO:Defining folds
2024-08-26 16:57:05,283:INFO:Declaring metric variables
2024-08-26 16:57:05,289:INFO:Importing untrained model
2024-08-26 16:57:05,295:INFO:Decision Tree Classifier Imported successfully
2024-08-26 16:57:05,308:INFO:Starting cross validation
2024-08-26 16:57:05,315:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-08-26 16:57:07,061:INFO:Calculating mean and std
2024-08-26 16:57:07,064:INFO:Creating metrics dataframe
2024-08-26 16:57:07,067:INFO:Uploading results into container
2024-08-26 16:57:07,067:INFO:Uploading model into container now
2024-08-26 16:57:07,068:INFO:_master_model_container: 4
2024-08-26 16:57:07,068:INFO:_display_container: 2
2024-08-26 16:57:07,069:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=3260, splitter='best')
2024-08-26 16:57:07,069:INFO:create_model() successfully completed......................................
2024-08-26 16:57:07,398:INFO:SubProcess create_model() end ==================================
2024-08-26 16:57:07,398:INFO:Creating metrics dataframe
2024-08-26 16:57:07,421:INFO:Initializing SVM - Linear Kernel
2024-08-26 16:57:07,422:INFO:Total runtime is 0.5580593347549438 minutes
2024-08-26 16:57:07,431:INFO:SubProcess create_model() called ==================================
2024-08-26 16:57:07,433:INFO:Initializing create_model()
2024-08-26 16:57:07,433:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023F3596E710>, estimator=svm, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023F028C6F10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-26 16:57:07,433:INFO:Checking exceptions
2024-08-26 16:57:07,434:INFO:Importing libraries
2024-08-26 16:57:07,434:INFO:Copying training dataset
2024-08-26 16:57:07,442:INFO:Defining folds
2024-08-26 16:57:07,447:INFO:Declaring metric variables
2024-08-26 16:57:07,455:INFO:Importing untrained model
2024-08-26 16:57:07,463:INFO:SVM - Linear Kernel Imported successfully
2024-08-26 16:57:07,480:INFO:Starting cross validation
2024-08-26 16:57:07,488:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-08-26 16:57:09,141:INFO:Calculating mean and std
2024-08-26 16:57:09,144:INFO:Creating metrics dataframe
2024-08-26 16:57:09,148:INFO:Uploading results into container
2024-08-26 16:57:09,149:INFO:Uploading model into container now
2024-08-26 16:57:09,151:INFO:_master_model_container: 5
2024-08-26 16:57:09,151:INFO:_display_container: 2
2024-08-26 16:57:09,153:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=3260, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-08-26 16:57:09,154:INFO:create_model() successfully completed......................................
2024-08-26 16:57:09,477:INFO:SubProcess create_model() end ==================================
2024-08-26 16:57:09,478:INFO:Creating metrics dataframe
2024-08-26 16:57:09,497:INFO:Initializing Ridge Classifier
2024-08-26 16:57:09,497:INFO:Total runtime is 0.5926425615946452 minutes
2024-08-26 16:57:09,504:INFO:SubProcess create_model() called ==================================
2024-08-26 16:57:09,505:INFO:Initializing create_model()
2024-08-26 16:57:09,505:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023F3596E710>, estimator=ridge, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023F028C6F10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-26 16:57:09,505:INFO:Checking exceptions
2024-08-26 16:57:09,505:INFO:Importing libraries
2024-08-26 16:57:09,506:INFO:Copying training dataset
2024-08-26 16:57:09,520:INFO:Defining folds
2024-08-26 16:57:09,520:INFO:Declaring metric variables
2024-08-26 16:57:09,529:INFO:Importing untrained model
2024-08-26 16:57:09,536:INFO:Ridge Classifier Imported successfully
2024-08-26 16:57:09,551:INFO:Starting cross validation
2024-08-26 16:57:09,558:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-08-26 16:57:11,256:INFO:Calculating mean and std
2024-08-26 16:57:11,259:INFO:Creating metrics dataframe
2024-08-26 16:57:11,265:INFO:Uploading results into container
2024-08-26 16:57:11,267:INFO:Uploading model into container now
2024-08-26 16:57:11,268:INFO:_master_model_container: 6
2024-08-26 16:57:11,268:INFO:_display_container: 2
2024-08-26 16:57:11,269:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=3260, solver='auto',
                tol=0.0001)
2024-08-26 16:57:11,269:INFO:create_model() successfully completed......................................
2024-08-26 16:57:11,610:INFO:SubProcess create_model() end ==================================
2024-08-26 16:57:11,610:INFO:Creating metrics dataframe
2024-08-26 16:57:11,631:INFO:Initializing Random Forest Classifier
2024-08-26 16:57:11,631:INFO:Total runtime is 0.6282042185465495 minutes
2024-08-26 16:57:11,638:INFO:SubProcess create_model() called ==================================
2024-08-26 16:57:11,639:INFO:Initializing create_model()
2024-08-26 16:57:11,639:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023F3596E710>, estimator=rf, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023F028C6F10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-26 16:57:11,639:INFO:Checking exceptions
2024-08-26 16:57:11,639:INFO:Importing libraries
2024-08-26 16:57:11,640:INFO:Copying training dataset
2024-08-26 16:57:11,651:INFO:Defining folds
2024-08-26 16:57:11,651:INFO:Declaring metric variables
2024-08-26 16:57:11,656:INFO:Importing untrained model
2024-08-26 16:57:11,664:INFO:Random Forest Classifier Imported successfully
2024-08-26 16:57:11,675:INFO:Starting cross validation
2024-08-26 16:57:11,681:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-08-26 16:57:14,263:INFO:Calculating mean and std
2024-08-26 16:57:14,267:INFO:Creating metrics dataframe
2024-08-26 16:57:14,271:INFO:Uploading results into container
2024-08-26 16:57:14,273:INFO:Uploading model into container now
2024-08-26 16:57:14,273:INFO:_master_model_container: 7
2024-08-26 16:57:14,274:INFO:_display_container: 2
2024-08-26 16:57:14,275:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=3260, verbose=0,
                       warm_start=False)
2024-08-26 16:57:14,276:INFO:create_model() successfully completed......................................
2024-08-26 16:57:14,599:INFO:SubProcess create_model() end ==================================
2024-08-26 16:57:14,600:INFO:Creating metrics dataframe
2024-08-26 16:57:14,620:INFO:Initializing Quadratic Discriminant Analysis
2024-08-26 16:57:14,621:INFO:Total runtime is 0.6780368248621623 minutes
2024-08-26 16:57:14,627:INFO:SubProcess create_model() called ==================================
2024-08-26 16:57:14,628:INFO:Initializing create_model()
2024-08-26 16:57:14,629:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023F3596E710>, estimator=qda, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023F028C6F10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-26 16:57:14,629:INFO:Checking exceptions
2024-08-26 16:57:14,629:INFO:Importing libraries
2024-08-26 16:57:14,629:INFO:Copying training dataset
2024-08-26 16:57:14,642:INFO:Defining folds
2024-08-26 16:57:14,643:INFO:Declaring metric variables
2024-08-26 16:57:14,652:INFO:Importing untrained model
2024-08-26 16:57:14,659:INFO:Quadratic Discriminant Analysis Imported successfully
2024-08-26 16:57:14,677:INFO:Starting cross validation
2024-08-26 16:57:14,684:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-08-26 16:57:15,995:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-08-26 16:57:16,036:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-08-26 16:57:16,064:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-08-26 16:57:16,160:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-08-26 16:57:16,243:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-26 16:57:16,287:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-26 16:57:16,387:INFO:Calculating mean and std
2024-08-26 16:57:16,390:INFO:Creating metrics dataframe
2024-08-26 16:57:16,394:INFO:Uploading results into container
2024-08-26 16:57:16,396:INFO:Uploading model into container now
2024-08-26 16:57:16,397:INFO:_master_model_container: 8
2024-08-26 16:57:16,397:INFO:_display_container: 2
2024-08-26 16:57:16,397:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-08-26 16:57:16,397:INFO:create_model() successfully completed......................................
2024-08-26 16:57:16,730:INFO:SubProcess create_model() end ==================================
2024-08-26 16:57:16,730:INFO:Creating metrics dataframe
2024-08-26 16:57:16,749:INFO:Initializing Ada Boost Classifier
2024-08-26 16:57:16,749:INFO:Total runtime is 0.71351291735967 minutes
2024-08-26 16:57:16,758:INFO:SubProcess create_model() called ==================================
2024-08-26 16:57:16,759:INFO:Initializing create_model()
2024-08-26 16:57:16,759:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023F3596E710>, estimator=ada, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023F028C6F10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-26 16:57:16,759:INFO:Checking exceptions
2024-08-26 16:57:16,759:INFO:Importing libraries
2024-08-26 16:57:16,759:INFO:Copying training dataset
2024-08-26 16:57:16,773:INFO:Defining folds
2024-08-26 16:57:16,774:INFO:Declaring metric variables
2024-08-26 16:57:16,782:INFO:Importing untrained model
2024-08-26 16:57:16,789:INFO:Ada Boost Classifier Imported successfully
2024-08-26 16:57:16,802:INFO:Starting cross validation
2024-08-26 16:57:16,808:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-08-26 16:57:18,007:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-08-26 16:57:18,100:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-08-26 16:57:18,193:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-08-26 16:57:18,356:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-08-26 16:57:19,534:INFO:Calculating mean and std
2024-08-26 16:57:19,537:INFO:Creating metrics dataframe
2024-08-26 16:57:19,543:INFO:Uploading results into container
2024-08-26 16:57:19,543:INFO:Uploading model into container now
2024-08-26 16:57:19,544:INFO:_master_model_container: 9
2024-08-26 16:57:19,544:INFO:_display_container: 2
2024-08-26 16:57:19,546:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=3260)
2024-08-26 16:57:19,546:INFO:create_model() successfully completed......................................
2024-08-26 16:57:19,889:INFO:SubProcess create_model() end ==================================
2024-08-26 16:57:19,890:INFO:Creating metrics dataframe
2024-08-26 16:57:19,921:INFO:Initializing Gradient Boosting Classifier
2024-08-26 16:57:19,922:INFO:Total runtime is 0.7663942257563273 minutes
2024-08-26 16:57:19,935:INFO:SubProcess create_model() called ==================================
2024-08-26 16:57:19,935:INFO:Initializing create_model()
2024-08-26 16:57:19,936:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023F3596E710>, estimator=gbc, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023F028C6F10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-26 16:57:19,936:INFO:Checking exceptions
2024-08-26 16:57:19,936:INFO:Importing libraries
2024-08-26 16:57:19,937:INFO:Copying training dataset
2024-08-26 16:57:19,949:INFO:Defining folds
2024-08-26 16:57:19,949:INFO:Declaring metric variables
2024-08-26 16:57:19,957:INFO:Importing untrained model
2024-08-26 16:57:19,966:INFO:Gradient Boosting Classifier Imported successfully
2024-08-26 16:57:19,983:INFO:Starting cross validation
2024-08-26 16:57:19,990:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-08-26 16:57:25,056:INFO:Calculating mean and std
2024-08-26 16:57:25,059:INFO:Creating metrics dataframe
2024-08-26 16:57:25,063:INFO:Uploading results into container
2024-08-26 16:57:25,064:INFO:Uploading model into container now
2024-08-26 16:57:25,065:INFO:_master_model_container: 10
2024-08-26 16:57:25,065:INFO:_display_container: 2
2024-08-26 16:57:25,065:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=3260, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-08-26 16:57:25,065:INFO:create_model() successfully completed......................................
2024-08-26 16:57:25,395:INFO:SubProcess create_model() end ==================================
2024-08-26 16:57:25,395:INFO:Creating metrics dataframe
2024-08-26 16:57:25,419:INFO:Initializing Linear Discriminant Analysis
2024-08-26 16:57:25,419:INFO:Total runtime is 0.858010466893514 minutes
2024-08-26 16:57:25,425:INFO:SubProcess create_model() called ==================================
2024-08-26 16:57:25,426:INFO:Initializing create_model()
2024-08-26 16:57:25,426:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023F3596E710>, estimator=lda, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023F028C6F10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-26 16:57:25,426:INFO:Checking exceptions
2024-08-26 16:57:25,426:INFO:Importing libraries
2024-08-26 16:57:25,427:INFO:Copying training dataset
2024-08-26 16:57:25,439:INFO:Defining folds
2024-08-26 16:57:25,439:INFO:Declaring metric variables
2024-08-26 16:57:25,446:INFO:Importing untrained model
2024-08-26 16:57:25,452:INFO:Linear Discriminant Analysis Imported successfully
2024-08-26 16:57:25,465:INFO:Starting cross validation
2024-08-26 16:57:25,470:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-08-26 16:57:27,168:INFO:Calculating mean and std
2024-08-26 16:57:27,171:INFO:Creating metrics dataframe
2024-08-26 16:57:27,176:INFO:Uploading results into container
2024-08-26 16:57:27,177:INFO:Uploading model into container now
2024-08-26 16:57:27,178:INFO:_master_model_container: 11
2024-08-26 16:57:27,178:INFO:_display_container: 2
2024-08-26 16:57:27,179:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-08-26 16:57:27,179:INFO:create_model() successfully completed......................................
2024-08-26 16:57:27,511:INFO:SubProcess create_model() end ==================================
2024-08-26 16:57:27,512:INFO:Creating metrics dataframe
2024-08-26 16:57:27,537:INFO:Initializing Extra Trees Classifier
2024-08-26 16:57:27,538:INFO:Total runtime is 0.8933297594388326 minutes
2024-08-26 16:57:27,544:INFO:SubProcess create_model() called ==================================
2024-08-26 16:57:27,546:INFO:Initializing create_model()
2024-08-26 16:57:27,546:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023F3596E710>, estimator=et, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023F028C6F10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-26 16:57:27,546:INFO:Checking exceptions
2024-08-26 16:57:27,546:INFO:Importing libraries
2024-08-26 16:57:27,546:INFO:Copying training dataset
2024-08-26 16:57:27,558:INFO:Defining folds
2024-08-26 16:57:27,558:INFO:Declaring metric variables
2024-08-26 16:57:27,566:INFO:Importing untrained model
2024-08-26 16:57:27,572:INFO:Extra Trees Classifier Imported successfully
2024-08-26 16:57:27,585:INFO:Starting cross validation
2024-08-26 16:57:27,591:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-08-26 16:57:29,797:INFO:Calculating mean and std
2024-08-26 16:57:29,799:INFO:Creating metrics dataframe
2024-08-26 16:57:29,804:INFO:Uploading results into container
2024-08-26 16:57:29,805:INFO:Uploading model into container now
2024-08-26 16:57:29,806:INFO:_master_model_container: 12
2024-08-26 16:57:29,806:INFO:_display_container: 2
2024-08-26 16:57:29,808:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=3260, verbose=0,
                     warm_start=False)
2024-08-26 16:57:29,808:INFO:create_model() successfully completed......................................
2024-08-26 16:57:30,123:INFO:SubProcess create_model() end ==================================
2024-08-26 16:57:30,123:INFO:Creating metrics dataframe
2024-08-26 16:57:30,148:INFO:Initializing Light Gradient Boosting Machine
2024-08-26 16:57:30,149:INFO:Total runtime is 0.9368426601092021 minutes
2024-08-26 16:57:30,158:INFO:SubProcess create_model() called ==================================
2024-08-26 16:57:30,158:INFO:Initializing create_model()
2024-08-26 16:57:30,158:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023F3596E710>, estimator=lightgbm, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023F028C6F10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-26 16:57:30,159:INFO:Checking exceptions
2024-08-26 16:57:30,159:INFO:Importing libraries
2024-08-26 16:57:30,159:INFO:Copying training dataset
2024-08-26 16:57:30,166:INFO:Defining folds
2024-08-26 16:57:30,167:INFO:Declaring metric variables
2024-08-26 16:57:30,173:INFO:Importing untrained model
2024-08-26 16:57:30,182:INFO:Light Gradient Boosting Machine Imported successfully
2024-08-26 16:57:30,201:INFO:Starting cross validation
2024-08-26 16:57:30,209:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-08-26 16:57:33,095:INFO:Calculating mean and std
2024-08-26 16:57:33,098:INFO:Creating metrics dataframe
2024-08-26 16:57:33,104:INFO:Uploading results into container
2024-08-26 16:57:33,106:INFO:Uploading model into container now
2024-08-26 16:57:33,107:INFO:_master_model_container: 13
2024-08-26 16:57:33,107:INFO:_display_container: 2
2024-08-26 16:57:33,108:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3260, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-08-26 16:57:33,108:INFO:create_model() successfully completed......................................
2024-08-26 16:57:33,455:INFO:SubProcess create_model() end ==================================
2024-08-26 16:57:33,455:INFO:Creating metrics dataframe
2024-08-26 16:57:33,483:INFO:Initializing Dummy Classifier
2024-08-26 16:57:33,483:INFO:Total runtime is 0.9924111088116965 minutes
2024-08-26 16:57:33,492:INFO:SubProcess create_model() called ==================================
2024-08-26 16:57:33,493:INFO:Initializing create_model()
2024-08-26 16:57:33,494:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023F3596E710>, estimator=dummy, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023F028C6F10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-26 16:57:33,494:INFO:Checking exceptions
2024-08-26 16:57:33,494:INFO:Importing libraries
2024-08-26 16:57:33,494:INFO:Copying training dataset
2024-08-26 16:57:33,507:INFO:Defining folds
2024-08-26 16:57:33,508:INFO:Declaring metric variables
2024-08-26 16:57:33,516:INFO:Importing untrained model
2024-08-26 16:57:33,521:INFO:Dummy Classifier Imported successfully
2024-08-26 16:57:33,533:INFO:Starting cross validation
2024-08-26 16:57:33,538:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-08-26 16:57:34,831:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-26 16:57:34,962:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-26 16:57:35,045:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-26 16:57:35,098:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-26 16:57:35,116:INFO:Calculating mean and std
2024-08-26 16:57:35,119:INFO:Creating metrics dataframe
2024-08-26 16:57:35,124:INFO:Uploading results into container
2024-08-26 16:57:35,126:INFO:Uploading model into container now
2024-08-26 16:57:35,127:INFO:_master_model_container: 14
2024-08-26 16:57:35,127:INFO:_display_container: 2
2024-08-26 16:57:35,128:INFO:DummyClassifier(constant=None, random_state=3260, strategy='prior')
2024-08-26 16:57:35,129:INFO:create_model() successfully completed......................................
2024-08-26 16:57:35,450:INFO:SubProcess create_model() end ==================================
2024-08-26 16:57:35,451:INFO:Creating metrics dataframe
2024-08-26 16:57:35,498:INFO:Initializing create_model()
2024-08-26 16:57:35,498:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023F3596E710>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=3260, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-26 16:57:35,499:INFO:Checking exceptions
2024-08-26 16:57:35,501:INFO:Importing libraries
2024-08-26 16:57:35,501:INFO:Copying training dataset
2024-08-26 16:57:35,512:INFO:Defining folds
2024-08-26 16:57:35,512:INFO:Declaring metric variables
2024-08-26 16:57:35,513:INFO:Importing untrained model
2024-08-26 16:57:35,513:INFO:Declaring custom model
2024-08-26 16:57:35,514:INFO:Gradient Boosting Classifier Imported successfully
2024-08-26 16:57:35,518:INFO:Cross validation set to False
2024-08-26 16:57:35,518:INFO:Fitting Model
2024-08-26 16:57:39,671:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=3260, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-08-26 16:57:39,671:INFO:create_model() successfully completed......................................
2024-08-26 16:57:40,052:INFO:_master_model_container: 14
2024-08-26 16:57:40,053:INFO:_display_container: 2
2024-08-26 16:57:40,054:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=3260, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-08-26 16:57:40,055:INFO:compare_models() successfully completed......................................
2024-08-26 16:57:40,067:INFO:Initializing plot_model()
2024-08-26 16:57:40,067:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023F3596E710>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=3260, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-08-26 16:57:40,069:INFO:Checking exceptions
2024-08-26 16:57:40,081:INFO:Preloading libraries
2024-08-26 16:57:40,101:INFO:Copying training dataset
2024-08-26 16:57:40,102:INFO:Plot type: feature
2024-08-26 16:57:40,103:WARNING:No coef_ found. Trying feature_importances_
2024-08-26 16:57:40,552:INFO:Visual Rendered Successfully
2024-08-26 16:57:40,882:INFO:plot_model() successfully completed......................................
2024-08-26 16:57:40,898:INFO:Initializing plot_model()
2024-08-26 16:57:40,899:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023F3596E710>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=3260, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-08-26 16:57:40,899:INFO:Checking exceptions
2024-08-26 16:57:40,910:INFO:Preloading libraries
2024-08-26 16:57:40,930:INFO:Copying training dataset
2024-08-26 16:57:40,930:INFO:Plot type: auc
2024-08-26 16:57:41,160:INFO:Fitting Model
2024-08-26 16:57:41,161:INFO:Scoring test/hold-out set
2024-08-26 16:57:41,709:INFO:Visual Rendered Successfully
2024-08-26 16:57:42,050:INFO:plot_model() successfully completed......................................
2024-08-26 16:57:42,163:INFO:Initializing save_model()
2024-08-26 16:57:42,163:INFO:save_model(model=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=3260, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), model_name=LR Model Aula 5 062022, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\natha\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean')...
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=QuantileTransformer(copy=True,
                                                                    ignore_implicit_zeros=False,
                                                                    n_quantiles=1000,
                                                                    output_distribution='normal',
                                                                    random_state=3260,
                                                                    subsample=10000))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-08-26 16:57:42,163:INFO:Adding model into prep_pipe
2024-08-26 16:57:42,205:INFO:LR Model Aula 5 062022.pkl saved in current working directory
2024-08-26 16:57:42,298:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWra...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.1, loss='log_loss',
                                            max_depth=3, max_features=None,
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.0,
                                            min_samples_leaf=1,
                                            min_samples_split=2,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=100,
                                            n_iter_no_change=None,
                                            random_state=3260, subsample=1.0,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2024-08-26 16:57:42,298:INFO:save_model() successfully completed......................................
2024-08-26 16:57:42,744:INFO:Initializing load_model()
2024-08-26 16:57:42,744:INFO:load_model(model_name=LR Model Aula 5 062022, platform=None, authentication=None, verbose=True)
2024-08-26 16:57:43,057:INFO:PyCaret ClassificationExperiment
2024-08-26 16:57:43,057:INFO:Logging name: clf-default-name
2024-08-26 16:57:43,057:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-08-26 16:57:43,058:INFO:version 3.3.2
2024-08-26 16:57:43,058:INFO:Initializing setup()
2024-08-26 16:57:43,058:INFO:self.USI: dd68
2024-08-26 16:57:43,058:INFO:self._variable_keys: {'data', 'is_multiclass', 'y_train', 'html_param', '_ml_usecase', 'exp_name_log', 'fold_groups_param', 'y', 'memory', 'n_jobs_param', 'X', 'X_train', 'idx', 'y_test', 'logging_param', 'fix_imbalance', 'seed', 'fold_generator', 'log_plots_param', 'USI', 'target_param', 'pipeline', 'fold_shuffle_param', 'gpu_param', 'gpu_n_jobs_param', '_available_plots', 'X_test', 'exp_id'}
2024-08-26 16:57:43,058:INFO:Checking environment
2024-08-26 16:57:43,058:INFO:python_version: 3.11.5
2024-08-26 16:57:43,058:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-08-26 16:57:43,058:INFO:machine: AMD64
2024-08-26 16:57:43,058:INFO:platform: Windows-10-10.0.22631-SP0
2024-08-26 16:57:43,059:INFO:Memory: svmem(total=8311836672, available=518488064, percent=93.8, used=7793348608, free=518488064)
2024-08-26 16:57:43,059:INFO:Physical Core: 4
2024-08-26 16:57:43,059:INFO:Logical Core: 8
2024-08-26 16:57:43,059:INFO:Checking libraries
2024-08-26 16:57:43,059:INFO:System:
2024-08-26 16:57:43,059:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-08-26 16:57:43,060:INFO:executable: C:\Users\natha\anaconda3\python.exe
2024-08-26 16:57:43,060:INFO:   machine: Windows-10-10.0.22631-SP0
2024-08-26 16:57:43,060:INFO:PyCaret required dependencies:
2024-08-26 16:57:43,060:INFO:                 pip: 23.2.1
2024-08-26 16:57:43,060:INFO:          setuptools: 68.0.0
2024-08-26 16:57:43,060:INFO:             pycaret: 3.3.2
2024-08-26 16:57:43,060:INFO:             IPython: 8.15.0
2024-08-26 16:57:43,060:INFO:          ipywidgets: 8.0.4
2024-08-26 16:57:43,060:INFO:                tqdm: 4.65.0
2024-08-26 16:57:43,061:INFO:               numpy: 1.24.3
2024-08-26 16:57:43,061:INFO:              pandas: 2.0.3
2024-08-26 16:57:43,061:INFO:              jinja2: 3.1.2
2024-08-26 16:57:43,061:INFO:               scipy: 1.11.1
2024-08-26 16:57:43,061:INFO:              joblib: 1.3.2
2024-08-26 16:57:43,061:INFO:             sklearn: 1.4.2
2024-08-26 16:57:43,061:INFO:                pyod: 2.0.1
2024-08-26 16:57:43,061:INFO:            imblearn: 0.12.3
2024-08-26 16:57:43,061:INFO:   category_encoders: 2.6.3
2024-08-26 16:57:43,061:INFO:            lightgbm: 4.5.0
2024-08-26 16:57:43,062:INFO:               numba: 0.57.1
2024-08-26 16:57:43,062:INFO:            requests: 2.31.0
2024-08-26 16:57:43,062:INFO:          matplotlib: 3.7.2
2024-08-26 16:57:43,062:INFO:          scikitplot: 0.3.7
2024-08-26 16:57:43,062:INFO:         yellowbrick: 1.5
2024-08-26 16:57:43,062:INFO:              plotly: 5.23.0
2024-08-26 16:57:43,062:INFO:    plotly-resampler: Not installed
2024-08-26 16:57:43,062:INFO:             kaleido: 0.2.1
2024-08-26 16:57:43,062:INFO:           schemdraw: 0.15
2024-08-26 16:57:43,062:INFO:         statsmodels: 0.14.0
2024-08-26 16:57:43,063:INFO:              sktime: 0.26.0
2024-08-26 16:57:43,063:INFO:               tbats: 1.1.3
2024-08-26 16:57:43,063:INFO:            pmdarima: 2.0.4
2024-08-26 16:57:43,063:INFO:              psutil: 5.9.0
2024-08-26 16:57:43,063:INFO:          markupsafe: 2.1.1
2024-08-26 16:57:43,063:INFO:             pickle5: Not installed
2024-08-26 16:57:43,063:INFO:         cloudpickle: 2.2.1
2024-08-26 16:57:43,063:INFO:         deprecation: 2.1.0
2024-08-26 16:57:43,063:INFO:              xxhash: 2.0.2
2024-08-26 16:57:43,063:INFO:           wurlitzer: Not installed
2024-08-26 16:57:43,064:INFO:PyCaret optional dependencies:
2024-08-26 16:57:43,064:INFO:                shap: Not installed
2024-08-26 16:57:43,064:INFO:           interpret: Not installed
2024-08-26 16:57:43,064:INFO:                umap: Not installed
2024-08-26 16:57:43,064:INFO:     ydata_profiling: 4.7.0
2024-08-26 16:57:43,064:INFO:  explainerdashboard: Not installed
2024-08-26 16:57:43,064:INFO:             autoviz: Not installed
2024-08-26 16:57:43,064:INFO:           fairlearn: Not installed
2024-08-26 16:57:43,064:INFO:          deepchecks: Not installed
2024-08-26 16:57:43,065:INFO:             xgboost: Not installed
2024-08-26 16:57:43,065:INFO:            catboost: Not installed
2024-08-26 16:57:43,065:INFO:              kmodes: Not installed
2024-08-26 16:57:43,065:INFO:             mlxtend: Not installed
2024-08-26 16:57:43,065:INFO:       statsforecast: Not installed
2024-08-26 16:57:43,065:INFO:        tune_sklearn: Not installed
2024-08-26 16:57:43,065:INFO:                 ray: Not installed
2024-08-26 16:57:43,065:INFO:            hyperopt: Not installed
2024-08-26 16:57:43,065:INFO:              optuna: Not installed
2024-08-26 16:57:43,066:INFO:               skopt: Not installed
2024-08-26 16:57:43,066:INFO:              mlflow: Not installed
2024-08-26 16:57:43,066:INFO:              gradio: Not installed
2024-08-26 16:57:43,066:INFO:             fastapi: Not installed
2024-08-26 16:57:43,066:INFO:             uvicorn: Not installed
2024-08-26 16:57:43,066:INFO:              m2cgen: Not installed
2024-08-26 16:57:43,066:INFO:           evidently: Not installed
2024-08-26 16:57:43,066:INFO:               fugue: Not installed
2024-08-26 16:57:43,066:INFO:           streamlit: Not installed
2024-08-26 16:57:43,066:INFO:             prophet: Not installed
2024-08-26 16:57:43,066:INFO:None
2024-08-26 16:57:43,067:INFO:Set up data.
2024-08-26 16:57:43,705:INFO:Set up folding strategy.
2024-08-26 16:57:43,705:INFO:Set up train/test split.
2024-08-26 16:57:44,883:INFO:Set up index.
2024-08-26 16:57:44,941:INFO:Assigning column types.
2024-08-26 16:57:45,851:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-08-26 16:57:45,993:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-26 16:57:45,996:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-26 16:57:46,069:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 16:57:46,070:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 16:57:46,190:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-26 16:57:46,192:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-26 16:57:46,266:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 16:57:46,267:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 16:57:46,268:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-08-26 16:57:46,388:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-26 16:57:46,460:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 16:57:46,461:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 16:57:46,586:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-26 16:57:46,663:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 16:57:46,663:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 16:57:46,665:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-08-26 16:57:46,861:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 16:57:46,861:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 16:57:47,058:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 16:57:47,058:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 16:57:47,061:INFO:Preparing preprocessing pipeline...
2024-08-26 16:57:47,232:INFO:Set up date feature engineering.
2024-08-26 16:57:47,232:INFO:Set up simple imputation.
2024-08-26 16:57:47,232:INFO:Set up removing multicollinearity.
2024-08-26 16:57:47,232:INFO:Set up binning of numerical features.
2024-08-26 16:57:47,596:INFO:Set up column transformation.
2024-08-26 16:57:47,596:INFO:Set up feature normalization.
2024-08-26 16:57:47,736:INFO:Set up column name cleaning.
2024-08-26 16:58:54,724:INFO:Finished creating preprocessing pipeline.
2024-08-26 16:58:54,825:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\natha\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pess...
                                    transformer=PowerTransformer(copy=True,
                                                                 method='yeo-johnson',
                                                                 standardize=False))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2024-08-26 16:58:54,825:INFO:Creating final display dataframe.
2024-08-26 16:59:08,789:INFO:Setup _display_container:                     Description             Value
0                    Session id              5583
1                        Target               mau
2                   Target type            Binary
3           Original data shape      (750000, 36)
4        Transformed data shape      (750000, 38)
5   Transformed train set shape      (525000, 38)
6    Transformed test set shape      (225000, 38)
7              Numeric features                 7
8                 Date features                 1
9      Rows with missing values             16.8%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Remove multicollinearity              True
15  Multicollinearity threshold              0.95
16               Transformation              True
17        Transformation method       yeo-johnson
18                    Normalize              True
19             Normalize method            zscore
20               Fold Generator   StratifiedKFold
21                  Fold Number                10
22                     CPU Jobs                -1
23                      Use GPU             False
24               Log Experiment             False
25              Experiment Name  clf-default-name
26                          USI              dd68
2024-08-26 16:59:09,194:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 16:59:09,198:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 16:59:09,384:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 16:59:09,385:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 16:59:09,398:INFO:setup() successfully completed in 86.44s...............
2024-08-26 16:59:09,479:INFO:Initializing create_model()
2024-08-26 16:59:09,479:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023F0B75AED0>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-26 16:59:09,479:INFO:Checking exceptions
2024-08-26 16:59:09,528:INFO:Importing libraries
2024-08-26 16:59:09,529:INFO:Copying training dataset
2024-08-26 16:59:11,091:INFO:Defining folds
2024-08-26 16:59:11,097:INFO:Declaring metric variables
2024-08-26 16:59:11,105:INFO:Importing untrained model
2024-08-26 16:59:11,115:INFO:Light Gradient Boosting Machine Imported successfully
2024-08-26 16:59:11,132:INFO:Starting cross validation
2024-08-26 16:59:11,137:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-26 16:59:20,216:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 16:59:20,223:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 16:59:20,471:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 16:59:21,073:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 16:59:21,212:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 16:59:21,269:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 16:59:23,079:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 16:59:23,181:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2024-08-26 16:59:23,270:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:01:12,653:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:01:12,899:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:02:15,676:INFO:Calculating mean and std
2024-08-26 17:02:15,715:INFO:Creating metrics dataframe
2024-08-26 17:02:15,777:INFO:Finalizing model
2024-08-26 17:03:16,175:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-08-26 17:03:16,181:INFO:[LightGBM] [Info] Number of positive: 41050, number of negative: 483950
2024-08-26 17:03:16,425:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.100823 seconds.
2024-08-26 17:03:16,426:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-26 17:03:16,426:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-26 17:03:16,427:INFO:[LightGBM] [Info] Total Bins 385
2024-08-26 17:03:16,428:INFO:[LightGBM] [Info] Number of data points in the train set: 525000, number of used features: 36
2024-08-26 17:03:16,436:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.078190 -> initscore=-2.467191
2024-08-26 17:03:16,436:INFO:[LightGBM] [Info] Start training from score -2.467191
2024-08-26 17:03:16,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:03:16,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:03:16,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:03:16,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:03:16,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:03:16,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:03:16,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:03:16,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:03:16,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:03:16,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:03:16,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:03:16,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:03:16,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:03:16,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:03:16,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:03:16,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:03:16,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:03:16,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:03:16,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:03:16,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:03:16,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:03:16,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:03:16,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:03:16,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:03:16,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:03:16,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:03:16,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:03:16,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:03:16,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:03:16,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:03:16,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:03:16,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:03:16,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:03:16,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:03:17,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:03:17,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:03:17,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:03:17,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:03:17,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:03:17,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:03:17,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:03:17,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:03:17,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:03:17,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:03:17,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:03:17,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:03:17,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:03:17,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:03:17,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:03:17,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:03:17,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:03:17,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:03:17,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:03:17,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:03:17,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:03:17,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:03:17,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:03:17,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:03:17,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:03:17,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:03:17,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:03:17,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:03:17,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:03:17,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:03:17,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:03:17,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:03:17,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:03:17,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:03:17,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:03:17,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:03:17,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:03:17,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:03:17,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:03:17,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:03:17,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:03:17,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:03:17,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:03:17,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:03:17,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:03:17,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:03:17,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:03:17,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:03:17,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:03:17,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:03:17,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:03:17,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:03:17,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:03:17,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:03:17,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:03:17,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:03:17,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:03:17,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:03:17,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:03:18,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:03:18,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:03:18,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:03:18,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:03:18,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:03:18,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:03:18,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:03:18,180:INFO:Uploading results into container
2024-08-26 17:03:18,181:INFO:Uploading model into container now
2024-08-26 17:03:18,230:INFO:_master_model_container: 1
2024-08-26 17:03:18,230:INFO:_display_container: 2
2024-08-26 17:03:18,232:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5583, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-08-26 17:03:18,232:INFO:create_model() successfully completed......................................
2024-08-26 17:03:20,519:INFO:Initializing tune_model()
2024-08-26 17:03:20,519:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023F0B75AED0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5583, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-08-26 17:03:20,519:INFO:Checking exceptions
2024-08-26 17:03:21,681:INFO:Copying training dataset
2024-08-26 17:03:22,601:INFO:Checking base model
2024-08-26 17:03:22,602:INFO:Base model : Light Gradient Boosting Machine
2024-08-26 17:03:22,610:INFO:Declaring metric variables
2024-08-26 17:03:22,618:INFO:Defining Hyperparameters
2024-08-26 17:03:22,964:INFO:Tuning with n_jobs=-1
2024-08-26 17:03:22,965:INFO:Initializing RandomizedSearchCV
2024-08-26 17:03:31,449:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:03:31,645:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:03:32,027:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:03:32,313:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:03:32,787:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:03:33,111:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:03:33,222:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:03:34,604:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:03:35,220:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2024-08-26 17:05:29,503:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:05:29,822:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:05:31,582:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:05:31,779:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:05:33,794:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:05:35,977:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:05:36,025:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:05:47,899:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:07:24,128:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:07:26,675:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:07:27,129:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2024-08-26 17:07:27,167:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:07:29,071:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:07:39,715:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:07:51,036:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:07:54,829:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:08:02,965:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:09:26,635:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:09:33,993:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:09:34,122:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:09:36,719:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2024-08-26 17:09:40,612:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:11:42,950:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:11:44,734:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:11:48,446:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:11:51,593:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:12:59,257:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:13:29,737:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:13:32,147:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:13:43,601:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:15:14,079:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:15:14,541:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:15:16,916:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2024-08-26 17:15:19,305:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:15:20,384:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:16:59,693:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:17:00,150:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:17:10,065:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:17:22,228:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:19:10,279:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:19:19,014:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:19:25,717:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:19:25,905:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:19:29,930:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2024-08-26 17:19:37,513:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:19:38,322:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:20:42,691:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:20:51,973:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:22:36,853:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:22:40,401:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:22:41,291:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:22:49,754:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:22:50,126:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:22:51,525:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:22:53,175:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:22:53,456:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2024-08-26 17:23:23,691:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:24:47,178:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:24:51,988:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:24:54,834:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:24:57,867:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:24:58,759:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:25:01,909:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:25:03,660:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:25:06,987:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2024-08-26 17:25:51,246:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:27:08,829:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:27:09,990:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:27:11,028:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:27:19,774:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:27:27,492:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:27:33,785:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:27:39,289:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:28:23,712:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:29:19,652:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:29:22,631:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2024-08-26 17:29:25,432:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:30:10,244:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:30:18,249:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:30:23,490:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:30:45,064:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:31:19,279:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:32:26,490:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:32:41,255:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:32:43,744:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:33:07,982:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-26 17:33:07,983:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-26 17:33:07,983:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-26 17:33:07,983:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-26 17:33:08,959:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:33:11,708:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2024-08-26 17:33:40,251:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:35:56,199:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:36:07,962:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:36:15,857:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:36:25,541:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:36:39,801:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:37:07,113:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:38:32,760:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:39:03,168:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:39:37,553:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:39:40,263:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2024-08-26 17:39:42,587:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:40:17,752:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:41:07,269:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:42:29,350:INFO:best_params: {'actual_estimator__reg_lambda': 0.05, 'actual_estimator__reg_alpha': 3, 'actual_estimator__num_leaves': 10, 'actual_estimator__n_estimators': 80, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 36, 'actual_estimator__learning_rate': 0.3, 'actual_estimator__feature_fraction': 0.8, 'actual_estimator__bagging_freq': 6, 'actual_estimator__bagging_fraction': 0.9}
2024-08-26 17:42:29,484:INFO:Hyperparameter search completed
2024-08-26 17:42:29,487:INFO:SubProcess create_model() called ==================================
2024-08-26 17:42:29,528:INFO:Initializing create_model()
2024-08-26 17:42:29,529:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023F0B75AED0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5583, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023F5BEC90D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.05, 'reg_alpha': 3, 'num_leaves': 10, 'n_estimators': 80, 'min_split_gain': 0.9, 'min_child_samples': 36, 'learning_rate': 0.3, 'feature_fraction': 0.8, 'bagging_freq': 6, 'bagging_fraction': 0.9})
2024-08-26 17:42:29,530:INFO:Checking exceptions
2024-08-26 17:42:29,535:INFO:Importing libraries
2024-08-26 17:42:29,540:INFO:Copying training dataset
2024-08-26 17:42:31,993:INFO:Defining folds
2024-08-26 17:42:31,998:INFO:Declaring metric variables
2024-08-26 17:42:32,069:INFO:Importing untrained model
2024-08-26 17:42:32,070:INFO:Declaring custom model
2024-08-26 17:42:32,100:INFO:Light Gradient Boosting Machine Imported successfully
2024-08-26 17:42:32,120:INFO:Starting cross validation
2024-08-26 17:42:32,143:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-26 17:42:43,174:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:42:43,425:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:42:44,079:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:42:44,435:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:42:44,502:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:42:47,218:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:42:47,764:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:42:48,286:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:42:51,042:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2024-08-26 17:45:09,221:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:45:09,319:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:45:42,440:INFO:Calculating mean and std
2024-08-26 17:45:42,467:INFO:Creating metrics dataframe
2024-08-26 17:45:42,552:INFO:Finalizing model
2024-08-26 17:46:06,609:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2024-08-26 17:46:06,610:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-08-26 17:46:06,610:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-08-26 17:46:07,044:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-08-26 17:46:07,045:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2024-08-26 17:46:07,046:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-08-26 17:46:07,046:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-08-26 17:46:07,046:INFO:[LightGBM] [Info] Number of positive: 41050, number of negative: 483950
2024-08-26 17:46:07,129:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.026378 seconds.
2024-08-26 17:46:07,129:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-26 17:46:07,129:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-26 17:46:07,130:INFO:[LightGBM] [Info] Total Bins 385
2024-08-26 17:46:07,131:INFO:[LightGBM] [Info] Number of data points in the train set: 525000, number of used features: 36
2024-08-26 17:46:07,139:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.078190 -> initscore=-2.467191
2024-08-26 17:46:07,139:INFO:[LightGBM] [Info] Start training from score -2.467191
2024-08-26 17:46:07,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:46:07,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:46:07,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:46:07,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:46:07,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:46:07,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:46:07,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:46:07,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:46:07,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:46:07,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:46:07,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:46:07,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:46:07,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:46:07,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:46:07,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:46:07,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:46:07,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:46:07,487:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 17:46:07,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:46:07,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:46:07,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:46:07,520:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 17:46:07,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:46:07,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:46:07,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:46:07,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:46:07,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:46:07,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:46:07,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:46:07,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:46:07,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:46:07,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:46:07,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:46:07,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:46:07,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:46:07,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:46:07,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:46:07,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:46:07,688:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 17:46:07,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:46:07,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:46:07,701:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 17:46:07,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:46:07,707:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 17:46:07,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:46:07,715:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 17:46:07,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:46:07,723:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 17:46:07,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:46:07,730:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 17:46:07,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:46:07,737:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 17:46:07,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:46:07,742:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 17:46:07,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:46:07,748:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 17:46:07,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:46:07,755:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 17:46:07,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:46:07,760:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 17:46:07,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:46:07,768:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 17:46:07,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:46:07,774:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 17:46:07,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:46:07,780:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 17:46:07,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:46:07,786:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 17:46:07,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:46:07,792:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 17:46:07,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:46:07,800:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 17:46:07,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:46:07,806:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 17:46:07,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:46:07,811:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 17:46:07,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:46:07,817:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 17:46:07,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:46:07,823:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 17:46:07,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:46:07,829:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 17:46:07,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:46:07,834:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 17:46:07,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:46:07,841:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 17:46:07,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:46:07,847:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 17:46:07,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:46:07,854:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 17:46:07,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:46:07,859:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 17:46:07,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:46:07,865:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 17:46:07,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:46:07,872:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 17:46:07,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:46:07,877:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 17:46:07,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:46:07,883:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 17:46:07,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:46:07,890:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 17:46:07,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:46:07,895:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 17:46:07,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:46:07,901:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 17:46:07,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:46:07,908:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 17:46:07,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:46:07,914:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 17:46:07,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:46:07,921:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 17:46:07,973:INFO:Uploading results into container
2024-08-26 17:46:07,974:INFO:Uploading model into container now
2024-08-26 17:46:07,978:INFO:_master_model_container: 2
2024-08-26 17:46:07,978:INFO:_display_container: 3
2024-08-26 17:46:07,980:INFO:LGBMClassifier(bagging_fraction=0.9, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.3, max_depth=-1,
               min_child_samples=36, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=80, n_jobs=-1, num_leaves=10, objective=None,
               random_state=5583, reg_alpha=3, reg_lambda=0.05, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-08-26 17:46:07,980:INFO:create_model() successfully completed......................................
2024-08-26 17:46:09,290:INFO:SubProcess create_model() end ==================================
2024-08-26 17:46:09,290:INFO:choose_better activated
2024-08-26 17:46:09,294:INFO:SubProcess create_model() called ==================================
2024-08-26 17:46:09,295:INFO:Initializing create_model()
2024-08-26 17:46:09,295:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023F0B75AED0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5583, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-26 17:46:09,295:INFO:Checking exceptions
2024-08-26 17:46:09,298:INFO:Importing libraries
2024-08-26 17:46:09,299:INFO:Copying training dataset
2024-08-26 17:46:10,275:INFO:Defining folds
2024-08-26 17:46:10,276:INFO:Declaring metric variables
2024-08-26 17:46:10,276:INFO:Importing untrained model
2024-08-26 17:46:10,276:INFO:Declaring custom model
2024-08-26 17:46:10,277:INFO:Light Gradient Boosting Machine Imported successfully
2024-08-26 17:46:10,278:INFO:Starting cross validation
2024-08-26 17:46:10,280:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-26 17:46:19,673:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:46:20,041:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:46:21,057:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:46:21,598:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:46:22,309:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:46:22,760:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:46:23,012:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:46:23,062:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:46:23,913:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2024-08-26 17:47:59,474:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:48:00,241:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 17:48:38,443:INFO:Calculating mean and std
2024-08-26 17:48:38,455:INFO:Creating metrics dataframe
2024-08-26 17:48:38,520:INFO:Finalizing model
2024-08-26 17:49:08,148:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-08-26 17:49:08,149:INFO:[LightGBM] [Info] Number of positive: 41050, number of negative: 483950
2024-08-26 17:49:08,233:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.035719 seconds.
2024-08-26 17:49:08,233:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-26 17:49:08,233:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-26 17:49:08,234:INFO:[LightGBM] [Info] Total Bins 385
2024-08-26 17:49:08,234:INFO:[LightGBM] [Info] Number of data points in the train set: 525000, number of used features: 36
2024-08-26 17:49:08,238:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.078190 -> initscore=-2.467191
2024-08-26 17:49:08,238:INFO:[LightGBM] [Info] Start training from score -2.467191
2024-08-26 17:49:08,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:08,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:08,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:08,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:08,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:08,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:08,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:08,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:08,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:08,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:08,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:08,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:08,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:08,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:08,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:08,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:08,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:08,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:08,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:08,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:08,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:08,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:08,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:08,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:08,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:08,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:08,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:08,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:08,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:08,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:08,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:08,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:08,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:08,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:08,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:08,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:08,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:08,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:08,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:08,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:08,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:08,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:08,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:08,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:08,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:08,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:08,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:08,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:08,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:08,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:08,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:08,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:08,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:08,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:08,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:08,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:08,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:08,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:08,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:08,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:08,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:08,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:08,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:08,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:08,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:08,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:08,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:08,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:08,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:08,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:08,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:08,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:08,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:08,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:08,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:08,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:08,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:08,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:08,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:08,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:08,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:08,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:08,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:08,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:08,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:08,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:08,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:08,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:08,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:09,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:09,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:09,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:09,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:09,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:09,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:09,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:09,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:09,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:09,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:09,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:09,108:INFO:Uploading results into container
2024-08-26 17:49:09,109:INFO:Uploading model into container now
2024-08-26 17:49:09,113:INFO:_master_model_container: 3
2024-08-26 17:49:09,113:INFO:_display_container: 4
2024-08-26 17:49:09,117:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5583, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-08-26 17:49:09,117:INFO:create_model() successfully completed......................................
2024-08-26 17:49:10,192:INFO:SubProcess create_model() end ==================================
2024-08-26 17:49:10,193:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5583, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 1.0
2024-08-26 17:49:10,193:INFO:LGBMClassifier(bagging_fraction=0.9, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.3, max_depth=-1,
               min_child_samples=36, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=80, n_jobs=-1, num_leaves=10, objective=None,
               random_state=5583, reg_alpha=3, reg_lambda=0.05, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 1.0
2024-08-26 17:49:10,194:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5583, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2024-08-26 17:49:10,194:INFO:choose_better completed
2024-08-26 17:49:10,194:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-08-26 17:49:10,223:INFO:_master_model_container: 3
2024-08-26 17:49:10,224:INFO:_display_container: 3
2024-08-26 17:49:10,225:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5583, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-08-26 17:49:10,225:INFO:tune_model() successfully completed......................................
2024-08-26 17:49:10,459:INFO:Initializing finalize_model()
2024-08-26 17:49:10,460:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023F0B75AED0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5583, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-08-26 17:49:10,461:INFO:Finalizing LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5583, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-08-26 17:49:10,878:INFO:Initializing create_model()
2024-08-26 17:49:10,878:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023F0B75AED0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5583, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-08-26 17:49:10,878:INFO:Checking exceptions
2024-08-26 17:49:10,880:INFO:Importing libraries
2024-08-26 17:49:10,880:INFO:Copying training dataset
2024-08-26 17:49:10,910:INFO:Defining folds
2024-08-26 17:49:10,910:INFO:Declaring metric variables
2024-08-26 17:49:10,910:INFO:Importing untrained model
2024-08-26 17:49:10,910:INFO:Declaring custom model
2024-08-26 17:49:10,911:INFO:Light Gradient Boosting Machine Imported successfully
2024-08-26 17:49:10,912:INFO:Cross validation set to False
2024-08-26 17:49:10,912:INFO:Fitting Model
2024-08-26 17:49:59,104:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-08-26 17:49:59,105:INFO:[LightGBM] [Info] Number of positive: 58643, number of negative: 691357
2024-08-26 17:49:59,287:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.075434 seconds.
2024-08-26 17:49:59,287:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-26 17:49:59,288:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-26 17:49:59,288:INFO:[LightGBM] [Info] Total Bins 385
2024-08-26 17:49:59,289:INFO:[LightGBM] [Info] Number of data points in the train set: 750000, number of used features: 36
2024-08-26 17:49:59,294:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.078191 -> initscore=-2.467188
2024-08-26 17:49:59,295:INFO:[LightGBM] [Info] Start training from score -2.467188
2024-08-26 17:49:59,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:59,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:59,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:59,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:59,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:59,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:59,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:59,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:59,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:59,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:59,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:59,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:59,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:59,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:59,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:59,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:59,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:59,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:59,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:59,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:59,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:59,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:59,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:59,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:59,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:59,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:59,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:59,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:59,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:59,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:59,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:59,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:59,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:59,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:59,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:59,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:59,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:49:59,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:50:00,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:50:00,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:50:00,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:50:00,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:50:00,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:50:00,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:50:00,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:50:00,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:50:00,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:50:00,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:50:00,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:50:00,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:50:00,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:50:00,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:50:00,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:50:00,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:50:00,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:50:00,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:50:00,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:50:00,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:50:00,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:50:00,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:50:00,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:50:00,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:50:00,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:50:00,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:50:00,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:50:00,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:50:00,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:50:00,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:50:00,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:50:00,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:50:00,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:50:00,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:50:00,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:50:00,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:50:00,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:50:00,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:50:00,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:50:00,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:50:00,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:50:00,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:50:01,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:50:01,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:50:01,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:50:01,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:50:01,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:50:01,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:50:01,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:50:01,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:50:01,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:50:01,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:50:01,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:50:01,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:50:01,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:50:01,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:50:01,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:50:01,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:50:01,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:50:01,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:50:01,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:50:01,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 17:50:01,625:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda',
                                             'bom'],
                                    transform...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=5583, reg_alpha=0.0,
                                reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-08-26 17:50:01,626:INFO:create_model() successfully completed......................................
2024-08-26 17:50:02,049:INFO:_master_model_container: 3
2024-08-26 17:50:02,049:INFO:_display_container: 3
2024-08-26 17:50:02,081:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda',
                                             'bom'],
                                    transform...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=5583, reg_alpha=0.0,
                                reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-08-26 17:50:02,081:INFO:finalize_model() successfully completed......................................
2024-08-26 17:50:02,365:INFO:Initializing evaluate_model()
2024-08-26 17:50:02,365:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023F0B75AED0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda',
                                             'bom'],
                                    transform...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=5583, reg_alpha=0.0,
                                reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-08-26 17:50:02,807:INFO:Initializing plot_model()
2024-08-26 17:50:02,807:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023F0B75AED0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda',
                                             'bom'],
                                    transform...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=5583, reg_alpha=0.0,
                                reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-08-26 17:50:02,807:INFO:Checking exceptions
2024-08-26 17:50:03,132:INFO:Preloading libraries
2024-08-26 17:50:03,143:INFO:Copying training dataset
2024-08-26 17:50:03,143:INFO:Plot type: pipeline
2024-08-26 17:50:03,573:INFO:Visual Rendered Successfully
2024-08-26 17:50:03,830:INFO:plot_model() successfully completed......................................
2024-08-26 17:50:03,858:INFO:Initializing plot_model()
2024-08-26 17:50:03,858:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023F0B75AED0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda',
                                             'bom'],
                                    transform...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=5583, reg_alpha=0.0,
                                reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-08-26 17:50:03,858:INFO:Checking exceptions
2024-08-26 17:50:04,132:INFO:Preloading libraries
2024-08-26 17:50:04,138:INFO:Copying training dataset
2024-08-26 17:50:04,139:INFO:Plot type: auc
2024-08-26 17:50:06,605:INFO:Fitting Model
2024-08-26 17:50:06,617:INFO:Scoring test/hold-out set
2024-08-26 17:50:07,663:INFO:Visual Rendered Successfully
2024-08-26 17:50:07,931:INFO:plot_model() successfully completed......................................
2024-08-26 17:50:07,952:INFO:Initializing plot_model()
2024-08-26 17:50:07,953:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023F0B75AED0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda',
                                             'bom'],
                                    transform...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=5583, reg_alpha=0.0,
                                reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-08-26 17:50:07,953:INFO:Checking exceptions
2024-08-26 17:50:08,276:INFO:Preloading libraries
2024-08-26 17:50:08,287:INFO:Copying training dataset
2024-08-26 17:50:08,287:INFO:Plot type: confusion_matrix
2024-08-26 17:50:10,653:INFO:Fitting Model
2024-08-26 17:50:10,660:INFO:Scoring test/hold-out set
2024-08-26 17:50:11,772:INFO:Visual Rendered Successfully
2024-08-26 17:50:12,119:INFO:plot_model() successfully completed......................................
2024-08-26 18:04:18,778:INFO:PyCaret ClassificationExperiment
2024-08-26 18:04:18,779:INFO:Logging name: clf-default-name
2024-08-26 18:04:18,779:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-08-26 18:04:18,780:INFO:version 3.3.2
2024-08-26 18:04:18,780:INFO:Initializing setup()
2024-08-26 18:04:18,780:INFO:self.USI: 0160
2024-08-26 18:04:18,780:INFO:self._variable_keys: {'X_train', 'fold_groups_param', 'exp_id', 'exp_name_log', 'gpu_param', 'data', 'seed', 'log_plots_param', 'y', 'X_test', 'memory', 'y_train', 'y_test', 'idx', 'fix_imbalance', 'html_param', '_ml_usecase', 'pipeline', 'gpu_n_jobs_param', 'is_multiclass', '_available_plots', 'X', 'target_param', 'logging_param', 'USI', 'fold_shuffle_param', 'fold_generator', 'n_jobs_param'}
2024-08-26 18:04:18,781:INFO:Checking environment
2024-08-26 18:04:18,781:INFO:python_version: 3.11.5
2024-08-26 18:04:18,781:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-08-26 18:04:18,781:INFO:machine: AMD64
2024-08-26 18:04:18,782:INFO:platform: Windows-10-10.0.22631-SP0
2024-08-26 18:04:18,783:INFO:Memory: svmem(total=8311836672, available=1575174144, percent=81.0, used=6736662528, free=1575174144)
2024-08-26 18:04:18,784:INFO:Physical Core: 4
2024-08-26 18:04:18,784:INFO:Logical Core: 8
2024-08-26 18:04:18,784:INFO:Checking libraries
2024-08-26 18:04:18,784:INFO:System:
2024-08-26 18:04:18,785:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-08-26 18:04:18,785:INFO:executable: C:\Users\natha\anaconda3\python.exe
2024-08-26 18:04:18,785:INFO:   machine: Windows-10-10.0.22631-SP0
2024-08-26 18:04:18,785:INFO:PyCaret required dependencies:
2024-08-26 18:04:20,435:INFO:                 pip: 23.2.1
2024-08-26 18:04:20,435:INFO:          setuptools: 68.0.0
2024-08-26 18:04:20,435:INFO:             pycaret: 3.3.2
2024-08-26 18:04:20,435:INFO:             IPython: 8.15.0
2024-08-26 18:04:20,435:INFO:          ipywidgets: 8.0.4
2024-08-26 18:04:20,435:INFO:                tqdm: 4.65.0
2024-08-26 18:04:20,435:INFO:               numpy: 1.24.3
2024-08-26 18:04:20,435:INFO:              pandas: 2.0.3
2024-08-26 18:04:20,436:INFO:              jinja2: 3.1.2
2024-08-26 18:04:20,436:INFO:               scipy: 1.11.1
2024-08-26 18:04:20,436:INFO:              joblib: 1.3.2
2024-08-26 18:04:20,436:INFO:             sklearn: 1.4.2
2024-08-26 18:04:20,436:INFO:                pyod: 2.0.1
2024-08-26 18:04:20,436:INFO:            imblearn: 0.12.3
2024-08-26 18:04:20,436:INFO:   category_encoders: 2.6.3
2024-08-26 18:04:20,436:INFO:            lightgbm: 4.5.0
2024-08-26 18:04:20,436:INFO:               numba: 0.57.1
2024-08-26 18:04:20,436:INFO:            requests: 2.31.0
2024-08-26 18:04:20,436:INFO:          matplotlib: 3.7.2
2024-08-26 18:04:20,436:INFO:          scikitplot: 0.3.7
2024-08-26 18:04:20,436:INFO:         yellowbrick: 1.5
2024-08-26 18:04:20,436:INFO:              plotly: 5.23.0
2024-08-26 18:04:20,436:INFO:    plotly-resampler: Not installed
2024-08-26 18:04:20,436:INFO:             kaleido: 0.2.1
2024-08-26 18:04:20,436:INFO:           schemdraw: 0.15
2024-08-26 18:04:20,437:INFO:         statsmodels: 0.14.0
2024-08-26 18:04:20,437:INFO:              sktime: 0.26.0
2024-08-26 18:04:20,437:INFO:               tbats: 1.1.3
2024-08-26 18:04:20,437:INFO:            pmdarima: 2.0.4
2024-08-26 18:04:20,437:INFO:              psutil: 5.9.0
2024-08-26 18:04:20,437:INFO:          markupsafe: 2.1.1
2024-08-26 18:04:20,437:INFO:             pickle5: Not installed
2024-08-26 18:04:20,437:INFO:         cloudpickle: 2.2.1
2024-08-26 18:04:20,437:INFO:         deprecation: 2.1.0
2024-08-26 18:04:20,437:INFO:              xxhash: 2.0.2
2024-08-26 18:04:20,437:INFO:           wurlitzer: Not installed
2024-08-26 18:04:20,437:INFO:PyCaret optional dependencies:
2024-08-26 18:04:20,474:INFO:                shap: Not installed
2024-08-26 18:04:20,474:INFO:           interpret: Not installed
2024-08-26 18:04:20,474:INFO:                umap: Not installed
2024-08-26 18:04:20,474:INFO:     ydata_profiling: 4.7.0
2024-08-26 18:04:20,475:INFO:  explainerdashboard: Not installed
2024-08-26 18:04:20,475:INFO:             autoviz: Not installed
2024-08-26 18:04:20,475:INFO:           fairlearn: Not installed
2024-08-26 18:04:20,475:INFO:          deepchecks: Not installed
2024-08-26 18:04:20,475:INFO:             xgboost: Not installed
2024-08-26 18:04:20,475:INFO:            catboost: Not installed
2024-08-26 18:04:20,475:INFO:              kmodes: Not installed
2024-08-26 18:04:20,475:INFO:             mlxtend: Not installed
2024-08-26 18:04:20,475:INFO:       statsforecast: Not installed
2024-08-26 18:04:20,475:INFO:        tune_sklearn: Not installed
2024-08-26 18:04:20,475:INFO:                 ray: Not installed
2024-08-26 18:04:20,475:INFO:            hyperopt: Not installed
2024-08-26 18:04:20,475:INFO:              optuna: Not installed
2024-08-26 18:04:20,475:INFO:               skopt: Not installed
2024-08-26 18:04:20,475:INFO:              mlflow: Not installed
2024-08-26 18:04:20,476:INFO:              gradio: Not installed
2024-08-26 18:04:20,476:INFO:             fastapi: Not installed
2024-08-26 18:04:20,476:INFO:             uvicorn: Not installed
2024-08-26 18:04:20,476:INFO:              m2cgen: Not installed
2024-08-26 18:04:20,476:INFO:           evidently: Not installed
2024-08-26 18:04:20,476:INFO:               fugue: Not installed
2024-08-26 18:04:20,476:INFO:           streamlit: Not installed
2024-08-26 18:04:20,476:INFO:             prophet: Not installed
2024-08-26 18:04:20,476:INFO:None
2024-08-26 18:04:20,477:INFO:Set up data.
2024-08-26 18:04:21,066:INFO:Set up folding strategy.
2024-08-26 18:04:21,067:INFO:Set up train/test split.
2024-08-26 18:04:21,390:INFO:Set up index.
2024-08-26 18:04:21,414:INFO:Assigning column types.
2024-08-26 18:04:21,546:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-08-26 18:04:21,602:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-26 18:04:21,610:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-26 18:04:21,655:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 18:04:21,656:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 18:04:21,709:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-26 18:04:21,711:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-26 18:04:21,738:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 18:04:21,739:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 18:04:21,739:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-08-26 18:04:21,793:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-26 18:04:21,828:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 18:04:21,828:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 18:04:21,886:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-26 18:04:21,912:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 18:04:21,913:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 18:04:21,913:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-08-26 18:04:21,991:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 18:04:21,991:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 18:04:22,077:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 18:04:22,078:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 18:04:22,086:INFO:Preparing preprocessing pipeline...
2024-08-26 18:04:22,111:INFO:Set up date feature engineering.
2024-08-26 18:04:22,111:INFO:Set up simple imputation.
2024-08-26 18:04:22,292:INFO:Set up encoding of ordinal features.
2024-08-26 18:04:22,420:INFO:Set up encoding of categorical features.
2024-08-26 18:04:28,908:INFO:Finished creating preprocessing pipeline.
2024-08-26 18:04:28,945:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\natha\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pess...
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['tipo_renda', 'educacao',
                                             'estado_civil',
                                             'tipo_residencia'],
                                    transformer=OneHotEncoder(cols=['tipo_renda',
                                                                    'educacao',
                                                                    'estado_civil',
                                                                    'tipo_residencia'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2024-08-26 18:04:28,945:INFO:Creating final display dataframe.
2024-08-26 18:04:36,421:INFO:Setup _display_container:                     Description             Value
0                    Session id              2446
1                        Target               mau
2                   Target type            Binary
3           Original data shape      (750000, 15)
4        Transformed data shape      (750000, 34)
5   Transformed train set shape      (525000, 34)
6    Transformed test set shape      (225000, 34)
7              Numeric features                 6
8                 Date features                 1
9          Categorical features                 7
10     Rows with missing values             16.8%
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation              mean
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17               Fold Generator   StratifiedKFold
18                  Fold Number                10
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  clf-default-name
23                          USI              0160
2024-08-26 18:04:36,551:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 18:04:36,551:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 18:04:36,661:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 18:04:36,662:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 18:04:36,666:INFO:setup() successfully completed in 18.04s...............
2024-08-26 18:04:43,469:INFO:gpu_param set to False
2024-08-26 18:04:43,549:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 18:04:43,550:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 18:04:43,637:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 18:04:43,637:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 18:05:26,908:INFO:PyCaret ClassificationExperiment
2024-08-26 18:05:26,908:INFO:Logging name: clf-default-name
2024-08-26 18:05:26,908:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-08-26 18:05:26,908:INFO:version 3.3.2
2024-08-26 18:05:26,908:INFO:Initializing setup()
2024-08-26 18:05:26,908:INFO:self.USI: b337
2024-08-26 18:05:26,908:INFO:self._variable_keys: {'X_train', 'fold_groups_param', 'exp_id', 'exp_name_log', 'gpu_param', 'data', 'seed', 'log_plots_param', 'y', 'X_test', 'memory', 'y_train', 'y_test', 'idx', 'fix_imbalance', 'html_param', '_ml_usecase', 'pipeline', 'gpu_n_jobs_param', 'is_multiclass', '_available_plots', 'X', 'target_param', 'logging_param', 'USI', 'fold_shuffle_param', 'fold_generator', 'n_jobs_param'}
2024-08-26 18:05:26,908:INFO:Checking environment
2024-08-26 18:05:26,908:INFO:python_version: 3.11.5
2024-08-26 18:05:26,908:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-08-26 18:05:26,908:INFO:machine: AMD64
2024-08-26 18:05:26,909:INFO:platform: Windows-10-10.0.22631-SP0
2024-08-26 18:05:26,909:INFO:Memory: svmem(total=8311836672, available=1592090624, percent=80.8, used=6719746048, free=1592090624)
2024-08-26 18:05:26,909:INFO:Physical Core: 4
2024-08-26 18:05:26,909:INFO:Logical Core: 8
2024-08-26 18:05:26,909:INFO:Checking libraries
2024-08-26 18:05:26,909:INFO:System:
2024-08-26 18:05:26,909:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-08-26 18:05:26,909:INFO:executable: C:\Users\natha\anaconda3\python.exe
2024-08-26 18:05:26,909:INFO:   machine: Windows-10-10.0.22631-SP0
2024-08-26 18:05:26,909:INFO:PyCaret required dependencies:
2024-08-26 18:05:26,909:INFO:                 pip: 23.2.1
2024-08-26 18:05:26,909:INFO:          setuptools: 68.0.0
2024-08-26 18:05:26,909:INFO:             pycaret: 3.3.2
2024-08-26 18:05:26,909:INFO:             IPython: 8.15.0
2024-08-26 18:05:26,909:INFO:          ipywidgets: 8.0.4
2024-08-26 18:05:26,909:INFO:                tqdm: 4.65.0
2024-08-26 18:05:26,909:INFO:               numpy: 1.24.3
2024-08-26 18:05:26,909:INFO:              pandas: 2.0.3
2024-08-26 18:05:26,909:INFO:              jinja2: 3.1.2
2024-08-26 18:05:26,909:INFO:               scipy: 1.11.1
2024-08-26 18:05:26,909:INFO:              joblib: 1.3.2
2024-08-26 18:05:26,909:INFO:             sklearn: 1.4.2
2024-08-26 18:05:26,910:INFO:                pyod: 2.0.1
2024-08-26 18:05:26,910:INFO:            imblearn: 0.12.3
2024-08-26 18:05:26,910:INFO:   category_encoders: 2.6.3
2024-08-26 18:05:26,910:INFO:            lightgbm: 4.5.0
2024-08-26 18:05:26,910:INFO:               numba: 0.57.1
2024-08-26 18:05:26,910:INFO:            requests: 2.31.0
2024-08-26 18:05:26,910:INFO:          matplotlib: 3.7.2
2024-08-26 18:05:26,910:INFO:          scikitplot: 0.3.7
2024-08-26 18:05:26,910:INFO:         yellowbrick: 1.5
2024-08-26 18:05:26,910:INFO:              plotly: 5.23.0
2024-08-26 18:05:26,910:INFO:    plotly-resampler: Not installed
2024-08-26 18:05:26,910:INFO:             kaleido: 0.2.1
2024-08-26 18:05:26,910:INFO:           schemdraw: 0.15
2024-08-26 18:05:26,910:INFO:         statsmodels: 0.14.0
2024-08-26 18:05:26,910:INFO:              sktime: 0.26.0
2024-08-26 18:05:26,910:INFO:               tbats: 1.1.3
2024-08-26 18:05:26,910:INFO:            pmdarima: 2.0.4
2024-08-26 18:05:26,910:INFO:              psutil: 5.9.0
2024-08-26 18:05:26,910:INFO:          markupsafe: 2.1.1
2024-08-26 18:05:26,910:INFO:             pickle5: Not installed
2024-08-26 18:05:26,910:INFO:         cloudpickle: 2.2.1
2024-08-26 18:05:26,910:INFO:         deprecation: 2.1.0
2024-08-26 18:05:26,910:INFO:              xxhash: 2.0.2
2024-08-26 18:05:26,910:INFO:           wurlitzer: Not installed
2024-08-26 18:05:26,910:INFO:PyCaret optional dependencies:
2024-08-26 18:05:26,910:INFO:                shap: Not installed
2024-08-26 18:05:26,910:INFO:           interpret: Not installed
2024-08-26 18:05:26,911:INFO:                umap: Not installed
2024-08-26 18:05:26,911:INFO:     ydata_profiling: 4.7.0
2024-08-26 18:05:26,911:INFO:  explainerdashboard: Not installed
2024-08-26 18:05:26,911:INFO:             autoviz: Not installed
2024-08-26 18:05:26,911:INFO:           fairlearn: Not installed
2024-08-26 18:05:26,911:INFO:          deepchecks: Not installed
2024-08-26 18:05:26,911:INFO:             xgboost: Not installed
2024-08-26 18:05:26,911:INFO:            catboost: Not installed
2024-08-26 18:05:26,911:INFO:              kmodes: Not installed
2024-08-26 18:05:26,911:INFO:             mlxtend: Not installed
2024-08-26 18:05:26,911:INFO:       statsforecast: Not installed
2024-08-26 18:05:26,911:INFO:        tune_sklearn: Not installed
2024-08-26 18:05:26,911:INFO:                 ray: Not installed
2024-08-26 18:05:26,911:INFO:            hyperopt: Not installed
2024-08-26 18:05:26,911:INFO:              optuna: Not installed
2024-08-26 18:05:26,911:INFO:               skopt: Not installed
2024-08-26 18:05:26,911:INFO:              mlflow: Not installed
2024-08-26 18:05:26,911:INFO:              gradio: Not installed
2024-08-26 18:05:26,911:INFO:             fastapi: Not installed
2024-08-26 18:05:26,911:INFO:             uvicorn: Not installed
2024-08-26 18:05:26,911:INFO:              m2cgen: Not installed
2024-08-26 18:05:26,911:INFO:           evidently: Not installed
2024-08-26 18:05:26,911:INFO:               fugue: Not installed
2024-08-26 18:05:26,911:INFO:           streamlit: Not installed
2024-08-26 18:05:26,911:INFO:             prophet: Not installed
2024-08-26 18:05:26,911:INFO:None
2024-08-26 18:05:26,911:INFO:Set up data.
2024-08-26 18:05:27,479:INFO:Set up folding strategy.
2024-08-26 18:05:27,479:INFO:Set up train/test split.
2024-08-26 18:05:27,801:INFO:Set up index.
2024-08-26 18:05:27,828:INFO:Assigning column types.
2024-08-26 18:05:27,960:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-08-26 18:05:28,030:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-26 18:05:28,031:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-26 18:05:28,057:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 18:05:28,057:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 18:05:28,099:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-26 18:05:28,100:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-26 18:05:28,135:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 18:05:28,135:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 18:05:28,136:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-08-26 18:05:28,191:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-26 18:05:28,216:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 18:05:28,217:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 18:05:28,258:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-26 18:05:28,284:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 18:05:28,284:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 18:05:28,284:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-08-26 18:05:28,350:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 18:05:28,351:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 18:05:28,443:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 18:05:28,444:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 18:05:28,446:INFO:Preparing preprocessing pipeline...
2024-08-26 18:05:28,468:INFO:Set up date feature engineering.
2024-08-26 18:05:28,468:INFO:Set up simple imputation.
2024-08-26 18:05:28,628:INFO:Set up encoding of ordinal features.
2024-08-26 18:05:28,783:INFO:Set up encoding of categorical features.
2024-08-26 18:05:34,249:INFO:Finished creating preprocessing pipeline.
2024-08-26 18:05:34,276:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\natha\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pess...
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['tipo_renda', 'educacao',
                                             'estado_civil',
                                             'tipo_residencia'],
                                    transformer=OneHotEncoder(cols=['tipo_renda',
                                                                    'educacao',
                                                                    'estado_civil',
                                                                    'tipo_residencia'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2024-08-26 18:05:34,276:INFO:Creating final display dataframe.
2024-08-26 18:05:46,189:INFO:Setup _display_container:                     Description             Value
0                    Session id              1688
1                        Target               mau
2                   Target type            Binary
3           Original data shape      (750000, 15)
4        Transformed data shape      (750000, 34)
5   Transformed train set shape      (525000, 34)
6    Transformed test set shape      (225000, 34)
7              Numeric features                 6
8                 Date features                 1
9          Categorical features                 7
10     Rows with missing values             16.8%
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation              mean
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17               Fold Generator   StratifiedKFold
18                  Fold Number                10
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  clf-default-name
23                          USI              b337
2024-08-26 18:05:46,308:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 18:05:46,308:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 18:05:46,393:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 18:05:46,394:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 18:05:46,397:INFO:setup() successfully completed in 19.54s...............
2024-08-26 18:05:55,090:INFO:gpu_param set to False
2024-08-26 18:05:55,169:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 18:05:55,169:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 18:05:55,251:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 18:05:55,252:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 18:12:12,674:INFO:PyCaret ClassificationExperiment
2024-08-26 18:12:12,675:INFO:Logging name: clf-default-name
2024-08-26 18:12:12,675:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-08-26 18:12:12,675:INFO:version 3.3.2
2024-08-26 18:12:12,675:INFO:Initializing setup()
2024-08-26 18:12:12,675:INFO:self.USI: b51b
2024-08-26 18:12:12,675:INFO:self._variable_keys: {'X_train', 'fold_groups_param', 'exp_id', 'exp_name_log', 'gpu_param', 'data', 'seed', 'log_plots_param', 'y', 'X_test', 'memory', 'y_train', 'y_test', 'idx', 'fix_imbalance', 'html_param', '_ml_usecase', 'pipeline', 'gpu_n_jobs_param', 'is_multiclass', '_available_plots', 'X', 'target_param', 'logging_param', 'USI', 'fold_shuffle_param', 'fold_generator', 'n_jobs_param'}
2024-08-26 18:12:12,676:INFO:Checking environment
2024-08-26 18:12:12,676:INFO:python_version: 3.11.5
2024-08-26 18:12:12,676:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-08-26 18:12:12,676:INFO:machine: AMD64
2024-08-26 18:12:12,676:INFO:platform: Windows-10-10.0.22631-SP0
2024-08-26 18:12:12,676:INFO:Memory: svmem(total=8311836672, available=1349607424, percent=83.8, used=6962229248, free=1349607424)
2024-08-26 18:12:12,676:INFO:Physical Core: 4
2024-08-26 18:12:12,676:INFO:Logical Core: 8
2024-08-26 18:12:12,676:INFO:Checking libraries
2024-08-26 18:12:12,676:INFO:System:
2024-08-26 18:12:12,676:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-08-26 18:12:12,676:INFO:executable: C:\Users\natha\anaconda3\python.exe
2024-08-26 18:12:12,676:INFO:   machine: Windows-10-10.0.22631-SP0
2024-08-26 18:12:12,676:INFO:PyCaret required dependencies:
2024-08-26 18:12:12,676:INFO:                 pip: 23.2.1
2024-08-26 18:12:12,676:INFO:          setuptools: 68.0.0
2024-08-26 18:12:12,676:INFO:             pycaret: 3.3.2
2024-08-26 18:12:12,676:INFO:             IPython: 8.15.0
2024-08-26 18:12:12,677:INFO:          ipywidgets: 8.0.4
2024-08-26 18:12:12,677:INFO:                tqdm: 4.65.0
2024-08-26 18:12:12,677:INFO:               numpy: 1.24.3
2024-08-26 18:12:12,677:INFO:              pandas: 2.0.3
2024-08-26 18:12:12,677:INFO:              jinja2: 3.1.2
2024-08-26 18:12:12,677:INFO:               scipy: 1.11.1
2024-08-26 18:12:12,677:INFO:              joblib: 1.3.2
2024-08-26 18:12:12,677:INFO:             sklearn: 1.4.2
2024-08-26 18:12:12,677:INFO:                pyod: 2.0.1
2024-08-26 18:12:12,677:INFO:            imblearn: 0.12.3
2024-08-26 18:12:12,677:INFO:   category_encoders: 2.6.3
2024-08-26 18:12:12,677:INFO:            lightgbm: 4.5.0
2024-08-26 18:12:12,677:INFO:               numba: 0.57.1
2024-08-26 18:12:12,678:INFO:            requests: 2.31.0
2024-08-26 18:12:12,678:INFO:          matplotlib: 3.7.2
2024-08-26 18:12:12,678:INFO:          scikitplot: 0.3.7
2024-08-26 18:12:12,678:INFO:         yellowbrick: 1.5
2024-08-26 18:12:12,678:INFO:              plotly: 5.23.0
2024-08-26 18:12:12,678:INFO:    plotly-resampler: Not installed
2024-08-26 18:12:12,678:INFO:             kaleido: 0.2.1
2024-08-26 18:12:12,678:INFO:           schemdraw: 0.15
2024-08-26 18:12:12,678:INFO:         statsmodels: 0.14.0
2024-08-26 18:12:12,678:INFO:              sktime: 0.26.0
2024-08-26 18:12:12,679:INFO:               tbats: 1.1.3
2024-08-26 18:12:12,679:INFO:            pmdarima: 2.0.4
2024-08-26 18:12:12,679:INFO:              psutil: 5.9.0
2024-08-26 18:12:12,679:INFO:          markupsafe: 2.1.1
2024-08-26 18:12:12,679:INFO:             pickle5: Not installed
2024-08-26 18:12:12,679:INFO:         cloudpickle: 2.2.1
2024-08-26 18:12:12,679:INFO:         deprecation: 2.1.0
2024-08-26 18:12:12,679:INFO:              xxhash: 2.0.2
2024-08-26 18:12:12,679:INFO:           wurlitzer: Not installed
2024-08-26 18:12:12,679:INFO:PyCaret optional dependencies:
2024-08-26 18:12:12,679:INFO:                shap: Not installed
2024-08-26 18:12:12,679:INFO:           interpret: Not installed
2024-08-26 18:12:12,679:INFO:                umap: Not installed
2024-08-26 18:12:12,679:INFO:     ydata_profiling: 4.7.0
2024-08-26 18:12:12,679:INFO:  explainerdashboard: Not installed
2024-08-26 18:12:12,679:INFO:             autoviz: Not installed
2024-08-26 18:12:12,679:INFO:           fairlearn: Not installed
2024-08-26 18:12:12,679:INFO:          deepchecks: Not installed
2024-08-26 18:12:12,679:INFO:             xgboost: Not installed
2024-08-26 18:12:12,679:INFO:            catboost: Not installed
2024-08-26 18:12:12,680:INFO:              kmodes: Not installed
2024-08-26 18:12:12,680:INFO:             mlxtend: Not installed
2024-08-26 18:12:12,680:INFO:       statsforecast: Not installed
2024-08-26 18:12:12,680:INFO:        tune_sklearn: Not installed
2024-08-26 18:12:12,680:INFO:                 ray: Not installed
2024-08-26 18:12:12,680:INFO:            hyperopt: Not installed
2024-08-26 18:12:12,680:INFO:              optuna: Not installed
2024-08-26 18:12:12,680:INFO:               skopt: Not installed
2024-08-26 18:12:12,680:INFO:              mlflow: Not installed
2024-08-26 18:12:12,680:INFO:              gradio: Not installed
2024-08-26 18:12:12,680:INFO:             fastapi: Not installed
2024-08-26 18:12:12,680:INFO:             uvicorn: Not installed
2024-08-26 18:12:12,680:INFO:              m2cgen: Not installed
2024-08-26 18:12:12,686:INFO:           evidently: Not installed
2024-08-26 18:12:12,687:INFO:               fugue: Not installed
2024-08-26 18:12:12,687:INFO:           streamlit: Not installed
2024-08-26 18:12:12,687:INFO:             prophet: Not installed
2024-08-26 18:12:12,687:INFO:None
2024-08-26 18:12:12,687:INFO:Set up data.
2024-08-26 18:12:13,297:INFO:Set up folding strategy.
2024-08-26 18:12:13,297:INFO:Set up train/test split.
2024-08-26 18:12:13,678:INFO:Set up index.
2024-08-26 18:12:13,703:INFO:Assigning column types.
2024-08-26 18:12:13,860:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-08-26 18:12:13,924:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-26 18:12:13,925:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-26 18:12:13,951:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 18:12:13,951:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 18:12:13,993:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-26 18:12:13,994:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-26 18:12:14,020:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 18:12:14,020:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 18:12:14,020:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-08-26 18:12:14,071:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-26 18:12:14,114:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 18:12:14,114:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 18:12:14,165:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-26 18:12:14,195:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 18:12:14,195:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 18:12:14,195:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-08-26 18:12:14,274:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 18:12:14,274:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 18:12:14,348:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 18:12:14,348:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 18:12:14,350:INFO:Preparing preprocessing pipeline...
2024-08-26 18:12:14,380:INFO:Set up date feature engineering.
2024-08-26 18:12:14,380:INFO:Set up simple imputation.
2024-08-26 18:12:14,553:INFO:Set up encoding of ordinal features.
2024-08-26 18:12:14,697:INFO:Set up encoding of categorical features.
2024-08-26 18:12:21,160:INFO:Finished creating preprocessing pipeline.
2024-08-26 18:12:21,192:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\natha\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pess...
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['tipo_renda', 'educacao',
                                             'estado_civil',
                                             'tipo_residencia'],
                                    transformer=OneHotEncoder(cols=['tipo_renda',
                                                                    'educacao',
                                                                    'estado_civil',
                                                                    'tipo_residencia'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2024-08-26 18:12:21,192:INFO:Creating final display dataframe.
2024-08-26 18:12:33,059:INFO:Setup _display_container:                     Description             Value
0                    Session id              8922
1                        Target               mau
2                   Target type            Binary
3           Original data shape      (750000, 15)
4        Transformed data shape      (750000, 34)
5   Transformed train set shape      (525000, 34)
6    Transformed test set shape      (225000, 34)
7              Numeric features                 6
8                 Date features                 1
9          Categorical features                 7
10     Rows with missing values             16.8%
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation              mean
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17               Fold Generator   StratifiedKFold
18                  Fold Number                10
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  clf-default-name
23                          USI              b51b
2024-08-26 18:12:33,158:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 18:12:33,158:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 18:12:33,265:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 18:12:33,265:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 18:12:33,266:INFO:setup() successfully completed in 20.66s...............
2024-08-26 18:12:33,354:INFO:gpu_param set to False
2024-08-26 18:12:33,440:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 18:12:33,441:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 18:12:33,553:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 18:12:33,554:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 18:12:33,580:INFO:Initializing create_model()
2024-08-26 18:12:33,580:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024E98C93890>, estimator=xxx, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-26 18:12:33,580:INFO:Checking exceptions
2024-08-26 18:21:30,322:INFO:PyCaret ClassificationExperiment
2024-08-26 18:21:30,322:INFO:Logging name: credit_1
2024-08-26 18:21:30,322:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-08-26 18:21:30,322:INFO:version 3.3.2
2024-08-26 18:21:30,322:INFO:Initializing setup()
2024-08-26 18:21:30,322:INFO:self.USI: 092a
2024-08-26 18:21:30,322:INFO:self._variable_keys: {'X_train', 'fold_groups_param', 'exp_id', 'exp_name_log', 'gpu_param', 'data', 'seed', 'log_plots_param', 'y', 'X_test', 'memory', 'y_train', 'y_test', 'idx', 'fix_imbalance', 'html_param', '_ml_usecase', 'pipeline', 'gpu_n_jobs_param', 'is_multiclass', '_available_plots', 'X', 'target_param', 'logging_param', 'USI', 'fold_shuffle_param', 'fold_generator', 'n_jobs_param'}
2024-08-26 18:21:30,323:INFO:Checking environment
2024-08-26 18:21:30,323:INFO:python_version: 3.11.5
2024-08-26 18:21:30,323:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-08-26 18:21:30,323:INFO:machine: AMD64
2024-08-26 18:21:30,323:INFO:platform: Windows-10-10.0.22631-SP0
2024-08-26 18:21:30,323:INFO:Memory: svmem(total=8311836672, available=1739857920, percent=79.1, used=6571978752, free=1739857920)
2024-08-26 18:21:30,323:INFO:Physical Core: 4
2024-08-26 18:21:30,323:INFO:Logical Core: 8
2024-08-26 18:21:30,323:INFO:Checking libraries
2024-08-26 18:21:30,323:INFO:System:
2024-08-26 18:21:30,323:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-08-26 18:21:30,323:INFO:executable: C:\Users\natha\anaconda3\python.exe
2024-08-26 18:21:30,323:INFO:   machine: Windows-10-10.0.22631-SP0
2024-08-26 18:21:30,323:INFO:PyCaret required dependencies:
2024-08-26 18:21:30,323:INFO:                 pip: 23.2.1
2024-08-26 18:21:30,323:INFO:          setuptools: 68.0.0
2024-08-26 18:21:30,323:INFO:             pycaret: 3.3.2
2024-08-26 18:21:30,324:INFO:             IPython: 8.15.0
2024-08-26 18:21:30,324:INFO:          ipywidgets: 8.0.4
2024-08-26 18:21:30,324:INFO:                tqdm: 4.65.0
2024-08-26 18:21:30,324:INFO:               numpy: 1.24.3
2024-08-26 18:21:30,324:INFO:              pandas: 2.0.3
2024-08-26 18:21:30,324:INFO:              jinja2: 3.1.2
2024-08-26 18:21:30,324:INFO:               scipy: 1.11.1
2024-08-26 18:21:30,324:INFO:              joblib: 1.3.2
2024-08-26 18:21:30,324:INFO:             sklearn: 1.4.2
2024-08-26 18:21:30,324:INFO:                pyod: 2.0.1
2024-08-26 18:21:30,324:INFO:            imblearn: 0.12.3
2024-08-26 18:21:30,324:INFO:   category_encoders: 2.6.3
2024-08-26 18:21:30,324:INFO:            lightgbm: 4.5.0
2024-08-26 18:21:30,324:INFO:               numba: 0.57.1
2024-08-26 18:21:30,324:INFO:            requests: 2.31.0
2024-08-26 18:21:30,324:INFO:          matplotlib: 3.7.2
2024-08-26 18:21:30,324:INFO:          scikitplot: 0.3.7
2024-08-26 18:21:30,324:INFO:         yellowbrick: 1.5
2024-08-26 18:21:30,324:INFO:              plotly: 5.23.0
2024-08-26 18:21:30,324:INFO:    plotly-resampler: Not installed
2024-08-26 18:21:30,324:INFO:             kaleido: 0.2.1
2024-08-26 18:21:30,324:INFO:           schemdraw: 0.15
2024-08-26 18:21:30,324:INFO:         statsmodels: 0.14.0
2024-08-26 18:21:30,324:INFO:              sktime: 0.26.0
2024-08-26 18:21:30,324:INFO:               tbats: 1.1.3
2024-08-26 18:21:30,324:INFO:            pmdarima: 2.0.4
2024-08-26 18:21:30,324:INFO:              psutil: 5.9.0
2024-08-26 18:21:30,325:INFO:          markupsafe: 2.1.1
2024-08-26 18:21:30,325:INFO:             pickle5: Not installed
2024-08-26 18:21:30,325:INFO:         cloudpickle: 2.2.1
2024-08-26 18:21:30,325:INFO:         deprecation: 2.1.0
2024-08-26 18:21:30,325:INFO:              xxhash: 2.0.2
2024-08-26 18:21:30,325:INFO:           wurlitzer: Not installed
2024-08-26 18:21:30,325:INFO:PyCaret optional dependencies:
2024-08-26 18:21:30,325:INFO:                shap: Not installed
2024-08-26 18:21:30,325:INFO:           interpret: Not installed
2024-08-26 18:21:30,325:INFO:                umap: Not installed
2024-08-26 18:21:30,325:INFO:     ydata_profiling: 4.7.0
2024-08-26 18:21:30,325:INFO:  explainerdashboard: Not installed
2024-08-26 18:21:30,325:INFO:             autoviz: Not installed
2024-08-26 18:21:30,325:INFO:           fairlearn: Not installed
2024-08-26 18:21:30,325:INFO:          deepchecks: Not installed
2024-08-26 18:21:30,325:INFO:             xgboost: Not installed
2024-08-26 18:21:30,325:INFO:            catboost: Not installed
2024-08-26 18:21:30,325:INFO:              kmodes: Not installed
2024-08-26 18:21:30,325:INFO:             mlxtend: Not installed
2024-08-26 18:21:30,325:INFO:       statsforecast: Not installed
2024-08-26 18:21:30,325:INFO:        tune_sklearn: Not installed
2024-08-26 18:21:30,325:INFO:                 ray: Not installed
2024-08-26 18:21:30,325:INFO:            hyperopt: Not installed
2024-08-26 18:21:30,325:INFO:              optuna: Not installed
2024-08-26 18:21:30,325:INFO:               skopt: Not installed
2024-08-26 18:21:30,325:INFO:              mlflow: Not installed
2024-08-26 18:21:30,325:INFO:              gradio: Not installed
2024-08-26 18:21:30,326:INFO:             fastapi: Not installed
2024-08-26 18:21:30,326:INFO:             uvicorn: Not installed
2024-08-26 18:21:30,326:INFO:              m2cgen: Not installed
2024-08-26 18:21:30,326:INFO:           evidently: Not installed
2024-08-26 18:21:30,326:INFO:               fugue: Not installed
2024-08-26 18:21:30,326:INFO:           streamlit: Not installed
2024-08-26 18:21:30,326:INFO:             prophet: Not installed
2024-08-26 18:21:30,326:INFO:None
2024-08-26 18:21:30,326:INFO:Set up data.
2024-08-26 18:21:30,375:INFO:Set up folding strategy.
2024-08-26 18:21:30,375:INFO:Set up train/test split.
2024-08-26 18:21:30,396:INFO:Set up index.
2024-08-26 18:21:30,397:INFO:Assigning column types.
2024-08-26 18:21:30,407:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-08-26 18:21:30,455:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-26 18:21:30,456:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-26 18:21:30,482:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 18:21:30,482:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 18:21:30,522:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-26 18:21:30,523:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-26 18:21:30,549:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 18:21:30,549:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 18:21:30,549:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-08-26 18:21:30,596:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-26 18:21:30,621:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 18:21:30,621:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 18:21:30,682:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-26 18:21:30,708:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 18:21:30,708:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 18:21:30,708:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-08-26 18:21:30,796:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 18:21:30,797:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 18:21:30,865:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 18:21:30,865:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 18:21:30,867:INFO:Preparing preprocessing pipeline...
2024-08-26 18:21:30,868:INFO:Set up simple imputation.
2024-08-26 18:21:30,876:INFO:Set up encoding of ordinal features.
2024-08-26 18:21:30,882:INFO:Set up encoding of categorical features.
2024-08-26 18:21:30,883:INFO:Set up imbalanced handling.
2024-08-26 18:21:30,883:INFO:Set up column transformation.
2024-08-26 18:21:30,886:INFO:Set up feature normalization.
2024-08-26 18:21:32,046:INFO:Finished creating preprocessing pipeline.
2024-08-26 18:21:32,074:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\natha\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean')...
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=QuantileTransformer(copy=True,
                                                                    ignore_implicit_zeros=False,
                                                                    n_quantiles=1000,
                                                                    output_distribution='normal',
                                                                    random_state=3747,
                                                                    subsample=10000))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2024-08-26 18:21:32,074:INFO:Creating final display dataframe.
2024-08-26 18:21:33,262:INFO:Setup _display_container:                     Description            Value
0                    Session id             3747
1                        Target              mau
2                   Target type           Binary
3           Original data shape      (38000, 13)
4        Transformed data shape      (60468, 30)
5   Transformed train set shape      (49068, 30)
6    Transformed test set shape      (11400, 30)
7              Numeric features                5
8          Categorical features                7
9      Rows with missing values            16.6%
10                   Preprocess             True
11              Imputation type           simple
12           Numeric imputation             mean
13       Categorical imputation             mode
14     Maximum one-hot encoding               25
15              Encoding method             None
16                Fix imbalance             True
17         Fix imbalance method            SMOTE
18               Transformation             True
19        Transformation method         quantile
20                    Normalize             True
21             Normalize method           zscore
22               Fold Generator  StratifiedKFold
23                  Fold Number               10
24                     CPU Jobs               -1
25                      Use GPU            False
26               Log Experiment            False
27              Experiment Name         credit_1
28                          USI             092a
2024-08-26 18:21:33,346:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 18:21:33,347:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 18:21:33,441:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 18:21:33,442:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 18:21:33,443:INFO:setup() successfully completed in 3.17s...............
2024-08-26 18:21:36,702:INFO:Initializing compare_models()
2024-08-26 18:21:36,702:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024EBB3A7DD0>, include=None, exclude=None, fold=4, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000024EBB3A7DD0>, 'include': None, 'exclude': None, 'fold': 4, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-08-26 18:21:36,702:INFO:Checking exceptions
2024-08-26 18:21:36,716:INFO:Preparing display monitor
2024-08-26 18:21:36,745:INFO:Initializing Logistic Regression
2024-08-26 18:21:36,746:INFO:Total runtime is 2.2145112355550132e-05 minutes
2024-08-26 18:21:36,749:INFO:SubProcess create_model() called ==================================
2024-08-26 18:21:36,750:INFO:Initializing create_model()
2024-08-26 18:21:36,750:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024EBB3A7DD0>, estimator=lr, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024EB3665150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-26 18:21:36,750:INFO:Checking exceptions
2024-08-26 18:21:36,750:INFO:Importing libraries
2024-08-26 18:21:36,750:INFO:Copying training dataset
2024-08-26 18:21:36,766:INFO:Defining folds
2024-08-26 18:21:36,766:INFO:Declaring metric variables
2024-08-26 18:21:36,770:INFO:Importing untrained model
2024-08-26 18:21:36,774:INFO:Logistic Regression Imported successfully
2024-08-26 18:21:36,782:INFO:Starting cross validation
2024-08-26 18:21:36,785:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-08-26 18:21:44,918:INFO:Calculating mean and std
2024-08-26 18:21:44,921:INFO:Creating metrics dataframe
2024-08-26 18:21:44,926:INFO:Uploading results into container
2024-08-26 18:21:44,927:INFO:Uploading model into container now
2024-08-26 18:21:44,928:INFO:_master_model_container: 1
2024-08-26 18:21:44,929:INFO:_display_container: 2
2024-08-26 18:21:44,930:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=3747, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-08-26 18:21:44,930:INFO:create_model() successfully completed......................................
2024-08-26 18:21:45,208:INFO:SubProcess create_model() end ==================================
2024-08-26 18:21:45,208:INFO:Creating metrics dataframe
2024-08-26 18:21:45,222:INFO:Initializing K Neighbors Classifier
2024-08-26 18:21:45,222:INFO:Total runtime is 0.14127533435821532 minutes
2024-08-26 18:21:45,227:INFO:SubProcess create_model() called ==================================
2024-08-26 18:21:45,227:INFO:Initializing create_model()
2024-08-26 18:21:45,228:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024EBB3A7DD0>, estimator=knn, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024EB3665150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-26 18:21:45,228:INFO:Checking exceptions
2024-08-26 18:21:45,228:INFO:Importing libraries
2024-08-26 18:21:45,228:INFO:Copying training dataset
2024-08-26 18:21:45,249:INFO:Defining folds
2024-08-26 18:21:45,249:INFO:Declaring metric variables
2024-08-26 18:21:45,255:INFO:Importing untrained model
2024-08-26 18:21:45,259:INFO:K Neighbors Classifier Imported successfully
2024-08-26 18:21:45,270:INFO:Starting cross validation
2024-08-26 18:21:45,276:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-08-26 18:21:54,148:INFO:Calculating mean and std
2024-08-26 18:21:54,149:INFO:Creating metrics dataframe
2024-08-26 18:21:54,152:INFO:Uploading results into container
2024-08-26 18:21:54,153:INFO:Uploading model into container now
2024-08-26 18:21:54,154:INFO:_master_model_container: 2
2024-08-26 18:21:54,154:INFO:_display_container: 2
2024-08-26 18:21:54,155:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-08-26 18:21:54,155:INFO:create_model() successfully completed......................................
2024-08-26 18:21:54,402:INFO:SubProcess create_model() end ==================================
2024-08-26 18:21:54,402:INFO:Creating metrics dataframe
2024-08-26 18:21:54,412:INFO:Initializing Naive Bayes
2024-08-26 18:21:54,413:INFO:Total runtime is 0.29447116057078043 minutes
2024-08-26 18:21:54,416:INFO:SubProcess create_model() called ==================================
2024-08-26 18:21:54,417:INFO:Initializing create_model()
2024-08-26 18:21:54,417:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024EBB3A7DD0>, estimator=nb, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024EB3665150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-26 18:21:54,417:INFO:Checking exceptions
2024-08-26 18:21:54,417:INFO:Importing libraries
2024-08-26 18:21:54,418:INFO:Copying training dataset
2024-08-26 18:21:54,437:INFO:Defining folds
2024-08-26 18:21:54,437:INFO:Declaring metric variables
2024-08-26 18:21:54,444:INFO:Importing untrained model
2024-08-26 18:21:54,450:INFO:Naive Bayes Imported successfully
2024-08-26 18:21:54,459:INFO:Starting cross validation
2024-08-26 18:21:54,463:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-08-26 18:21:55,432:INFO:Calculating mean and std
2024-08-26 18:21:55,433:INFO:Creating metrics dataframe
2024-08-26 18:21:55,435:INFO:Uploading results into container
2024-08-26 18:21:55,436:INFO:Uploading model into container now
2024-08-26 18:21:55,437:INFO:_master_model_container: 3
2024-08-26 18:21:55,437:INFO:_display_container: 2
2024-08-26 18:21:55,437:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-08-26 18:21:55,437:INFO:create_model() successfully completed......................................
2024-08-26 18:21:55,655:INFO:SubProcess create_model() end ==================================
2024-08-26 18:21:55,655:INFO:Creating metrics dataframe
2024-08-26 18:21:55,663:INFO:Initializing Decision Tree Classifier
2024-08-26 18:21:55,663:INFO:Total runtime is 0.31529121796290077 minutes
2024-08-26 18:21:55,667:INFO:SubProcess create_model() called ==================================
2024-08-26 18:21:55,667:INFO:Initializing create_model()
2024-08-26 18:21:55,667:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024EBB3A7DD0>, estimator=dt, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024EB3665150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-26 18:21:55,667:INFO:Checking exceptions
2024-08-26 18:21:55,667:INFO:Importing libraries
2024-08-26 18:21:55,667:INFO:Copying training dataset
2024-08-26 18:21:55,685:INFO:Defining folds
2024-08-26 18:21:55,685:INFO:Declaring metric variables
2024-08-26 18:21:55,690:INFO:Importing untrained model
2024-08-26 18:21:55,695:INFO:Decision Tree Classifier Imported successfully
2024-08-26 18:21:55,704:INFO:Starting cross validation
2024-08-26 18:21:55,710:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-08-26 18:21:56,960:INFO:Calculating mean and std
2024-08-26 18:21:56,961:INFO:Creating metrics dataframe
2024-08-26 18:21:56,963:INFO:Uploading results into container
2024-08-26 18:21:56,963:INFO:Uploading model into container now
2024-08-26 18:21:56,964:INFO:_master_model_container: 4
2024-08-26 18:21:56,964:INFO:_display_container: 2
2024-08-26 18:21:56,964:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=3747, splitter='best')
2024-08-26 18:21:56,964:INFO:create_model() successfully completed......................................
2024-08-26 18:21:57,195:INFO:SubProcess create_model() end ==================================
2024-08-26 18:21:57,195:INFO:Creating metrics dataframe
2024-08-26 18:21:57,208:INFO:Initializing SVM - Linear Kernel
2024-08-26 18:21:57,208:INFO:Total runtime is 0.34104775985081986 minutes
2024-08-26 18:21:57,212:INFO:SubProcess create_model() called ==================================
2024-08-26 18:21:57,212:INFO:Initializing create_model()
2024-08-26 18:21:57,212:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024EBB3A7DD0>, estimator=svm, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024EB3665150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-26 18:21:57,212:INFO:Checking exceptions
2024-08-26 18:21:57,213:INFO:Importing libraries
2024-08-26 18:21:57,213:INFO:Copying training dataset
2024-08-26 18:21:57,228:INFO:Defining folds
2024-08-26 18:21:57,228:INFO:Declaring metric variables
2024-08-26 18:21:57,232:INFO:Importing untrained model
2024-08-26 18:21:57,237:INFO:SVM - Linear Kernel Imported successfully
2024-08-26 18:21:57,255:INFO:Starting cross validation
2024-08-26 18:21:57,258:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-08-26 18:21:58,495:INFO:Calculating mean and std
2024-08-26 18:21:58,497:INFO:Creating metrics dataframe
2024-08-26 18:21:58,501:INFO:Uploading results into container
2024-08-26 18:21:58,502:INFO:Uploading model into container now
2024-08-26 18:21:58,503:INFO:_master_model_container: 5
2024-08-26 18:21:58,503:INFO:_display_container: 2
2024-08-26 18:21:58,504:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=3747, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-08-26 18:21:58,504:INFO:create_model() successfully completed......................................
2024-08-26 18:21:58,742:INFO:SubProcess create_model() end ==================================
2024-08-26 18:21:58,742:INFO:Creating metrics dataframe
2024-08-26 18:21:58,760:INFO:Initializing Ridge Classifier
2024-08-26 18:21:58,761:INFO:Total runtime is 0.3669247547785441 minutes
2024-08-26 18:21:58,766:INFO:SubProcess create_model() called ==================================
2024-08-26 18:21:58,766:INFO:Initializing create_model()
2024-08-26 18:21:58,766:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024EBB3A7DD0>, estimator=ridge, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024EB3665150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-26 18:21:58,767:INFO:Checking exceptions
2024-08-26 18:21:58,767:INFO:Importing libraries
2024-08-26 18:21:58,767:INFO:Copying training dataset
2024-08-26 18:21:58,783:INFO:Defining folds
2024-08-26 18:21:58,785:INFO:Declaring metric variables
2024-08-26 18:21:58,790:INFO:Importing untrained model
2024-08-26 18:21:58,795:INFO:Ridge Classifier Imported successfully
2024-08-26 18:21:58,805:INFO:Starting cross validation
2024-08-26 18:21:58,807:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-08-26 18:21:59,769:INFO:Calculating mean and std
2024-08-26 18:21:59,771:INFO:Creating metrics dataframe
2024-08-26 18:21:59,774:INFO:Uploading results into container
2024-08-26 18:21:59,774:INFO:Uploading model into container now
2024-08-26 18:21:59,775:INFO:_master_model_container: 6
2024-08-26 18:21:59,775:INFO:_display_container: 2
2024-08-26 18:21:59,775:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=3747, solver='auto',
                tol=0.0001)
2024-08-26 18:21:59,776:INFO:create_model() successfully completed......................................
2024-08-26 18:22:00,033:INFO:SubProcess create_model() end ==================================
2024-08-26 18:22:00,033:INFO:Creating metrics dataframe
2024-08-26 18:22:00,044:INFO:Initializing Random Forest Classifier
2024-08-26 18:22:00,045:INFO:Total runtime is 0.38832456270853677 minutes
2024-08-26 18:22:00,048:INFO:SubProcess create_model() called ==================================
2024-08-26 18:22:00,049:INFO:Initializing create_model()
2024-08-26 18:22:00,049:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024EBB3A7DD0>, estimator=rf, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024EB3665150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-26 18:22:00,049:INFO:Checking exceptions
2024-08-26 18:22:00,049:INFO:Importing libraries
2024-08-26 18:22:00,049:INFO:Copying training dataset
2024-08-26 18:22:00,069:INFO:Defining folds
2024-08-26 18:22:00,069:INFO:Declaring metric variables
2024-08-26 18:22:00,073:INFO:Importing untrained model
2024-08-26 18:22:00,079:INFO:Random Forest Classifier Imported successfully
2024-08-26 18:22:00,085:INFO:Starting cross validation
2024-08-26 18:22:00,089:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-08-26 18:22:04,635:INFO:Calculating mean and std
2024-08-26 18:22:04,638:INFO:Creating metrics dataframe
2024-08-26 18:22:04,641:INFO:Uploading results into container
2024-08-26 18:22:04,642:INFO:Uploading model into container now
2024-08-26 18:22:04,643:INFO:_master_model_container: 7
2024-08-26 18:22:04,643:INFO:_display_container: 2
2024-08-26 18:22:04,643:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=3747, verbose=0,
                       warm_start=False)
2024-08-26 18:22:04,643:INFO:create_model() successfully completed......................................
2024-08-26 18:22:04,873:INFO:SubProcess create_model() end ==================================
2024-08-26 18:22:04,873:INFO:Creating metrics dataframe
2024-08-26 18:22:04,881:INFO:Initializing Quadratic Discriminant Analysis
2024-08-26 18:22:04,881:INFO:Total runtime is 0.46893680493036904 minutes
2024-08-26 18:22:04,886:INFO:SubProcess create_model() called ==================================
2024-08-26 18:22:04,886:INFO:Initializing create_model()
2024-08-26 18:22:04,886:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024EBB3A7DD0>, estimator=qda, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024EB3665150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-26 18:22:04,887:INFO:Checking exceptions
2024-08-26 18:22:04,887:INFO:Importing libraries
2024-08-26 18:22:04,887:INFO:Copying training dataset
2024-08-26 18:22:04,906:INFO:Defining folds
2024-08-26 18:22:04,906:INFO:Declaring metric variables
2024-08-26 18:22:04,912:INFO:Importing untrained model
2024-08-26 18:22:04,917:INFO:Quadratic Discriminant Analysis Imported successfully
2024-08-26 18:22:04,925:INFO:Starting cross validation
2024-08-26 18:22:04,928:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-08-26 18:22:05,664:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-08-26 18:22:05,666:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-08-26 18:22:05,721:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-08-26 18:22:05,728:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-08-26 18:22:05,860:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-26 18:22:05,886:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-26 18:22:05,898:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-26 18:22:05,900:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-26 18:22:05,916:INFO:Calculating mean and std
2024-08-26 18:22:05,917:INFO:Creating metrics dataframe
2024-08-26 18:22:05,919:INFO:Uploading results into container
2024-08-26 18:22:05,919:INFO:Uploading model into container now
2024-08-26 18:22:05,920:INFO:_master_model_container: 8
2024-08-26 18:22:05,920:INFO:_display_container: 2
2024-08-26 18:22:05,920:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-08-26 18:22:05,921:INFO:create_model() successfully completed......................................
2024-08-26 18:22:06,167:INFO:SubProcess create_model() end ==================================
2024-08-26 18:22:06,167:INFO:Creating metrics dataframe
2024-08-26 18:22:06,184:INFO:Initializing Ada Boost Classifier
2024-08-26 18:22:06,185:INFO:Total runtime is 0.49067091544469194 minutes
2024-08-26 18:22:06,191:INFO:SubProcess create_model() called ==================================
2024-08-26 18:22:06,192:INFO:Initializing create_model()
2024-08-26 18:22:06,192:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024EBB3A7DD0>, estimator=ada, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024EB3665150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-26 18:22:06,192:INFO:Checking exceptions
2024-08-26 18:22:06,192:INFO:Importing libraries
2024-08-26 18:22:06,192:INFO:Copying training dataset
2024-08-26 18:22:06,212:INFO:Defining folds
2024-08-26 18:22:06,212:INFO:Declaring metric variables
2024-08-26 18:22:06,218:INFO:Importing untrained model
2024-08-26 18:22:06,222:INFO:Ada Boost Classifier Imported successfully
2024-08-26 18:22:06,237:INFO:Starting cross validation
2024-08-26 18:22:06,241:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-08-26 18:22:06,926:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-08-26 18:22:06,950:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-08-26 18:22:06,996:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-08-26 18:22:07,026:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-08-26 18:22:10,223:INFO:Calculating mean and std
2024-08-26 18:22:10,225:INFO:Creating metrics dataframe
2024-08-26 18:22:10,226:INFO:Uploading results into container
2024-08-26 18:22:10,227:INFO:Uploading model into container now
2024-08-26 18:22:10,228:INFO:_master_model_container: 9
2024-08-26 18:22:10,228:INFO:_display_container: 2
2024-08-26 18:22:10,229:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=3747)
2024-08-26 18:22:10,229:INFO:create_model() successfully completed......................................
2024-08-26 18:22:10,451:INFO:SubProcess create_model() end ==================================
2024-08-26 18:22:10,451:INFO:Creating metrics dataframe
2024-08-26 18:22:10,463:INFO:Initializing Gradient Boosting Classifier
2024-08-26 18:22:10,464:INFO:Total runtime is 0.561958913008372 minutes
2024-08-26 18:22:10,468:INFO:SubProcess create_model() called ==================================
2024-08-26 18:22:10,469:INFO:Initializing create_model()
2024-08-26 18:22:10,469:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024EBB3A7DD0>, estimator=gbc, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024EB3665150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-26 18:22:10,469:INFO:Checking exceptions
2024-08-26 18:22:10,469:INFO:Importing libraries
2024-08-26 18:22:10,469:INFO:Copying training dataset
2024-08-26 18:22:10,488:INFO:Defining folds
2024-08-26 18:22:10,488:INFO:Declaring metric variables
2024-08-26 18:22:10,493:INFO:Importing untrained model
2024-08-26 18:22:10,498:INFO:Gradient Boosting Classifier Imported successfully
2024-08-26 18:22:10,505:INFO:Starting cross validation
2024-08-26 18:22:10,508:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-08-26 18:22:23,550:INFO:Calculating mean and std
2024-08-26 18:22:23,551:INFO:Creating metrics dataframe
2024-08-26 18:22:23,554:INFO:Uploading results into container
2024-08-26 18:22:23,555:INFO:Uploading model into container now
2024-08-26 18:22:23,556:INFO:_master_model_container: 10
2024-08-26 18:22:23,556:INFO:_display_container: 2
2024-08-26 18:22:23,557:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=3747, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-08-26 18:22:23,558:INFO:create_model() successfully completed......................................
2024-08-26 18:22:23,771:INFO:SubProcess create_model() end ==================================
2024-08-26 18:22:23,772:INFO:Creating metrics dataframe
2024-08-26 18:22:23,794:INFO:Initializing Linear Discriminant Analysis
2024-08-26 18:22:23,794:INFO:Total runtime is 0.7841463843981424 minutes
2024-08-26 18:22:23,800:INFO:SubProcess create_model() called ==================================
2024-08-26 18:22:23,800:INFO:Initializing create_model()
2024-08-26 18:22:23,800:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024EBB3A7DD0>, estimator=lda, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024EB3665150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-26 18:22:23,801:INFO:Checking exceptions
2024-08-26 18:22:23,801:INFO:Importing libraries
2024-08-26 18:22:23,801:INFO:Copying training dataset
2024-08-26 18:22:23,817:INFO:Defining folds
2024-08-26 18:22:23,818:INFO:Declaring metric variables
2024-08-26 18:22:23,824:INFO:Importing untrained model
2024-08-26 18:22:23,828:INFO:Linear Discriminant Analysis Imported successfully
2024-08-26 18:22:23,835:INFO:Starting cross validation
2024-08-26 18:22:23,839:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-08-26 18:22:24,965:INFO:Calculating mean and std
2024-08-26 18:22:24,967:INFO:Creating metrics dataframe
2024-08-26 18:22:24,969:INFO:Uploading results into container
2024-08-26 18:22:24,970:INFO:Uploading model into container now
2024-08-26 18:22:24,971:INFO:_master_model_container: 11
2024-08-26 18:22:24,971:INFO:_display_container: 2
2024-08-26 18:22:24,971:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-08-26 18:22:24,971:INFO:create_model() successfully completed......................................
2024-08-26 18:22:25,194:INFO:SubProcess create_model() end ==================================
2024-08-26 18:22:25,195:INFO:Creating metrics dataframe
2024-08-26 18:22:25,204:INFO:Initializing Extra Trees Classifier
2024-08-26 18:22:25,204:INFO:Total runtime is 0.8076495091120401 minutes
2024-08-26 18:22:25,207:INFO:SubProcess create_model() called ==================================
2024-08-26 18:22:25,207:INFO:Initializing create_model()
2024-08-26 18:22:25,207:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024EBB3A7DD0>, estimator=et, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024EB3665150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-26 18:22:25,207:INFO:Checking exceptions
2024-08-26 18:22:25,207:INFO:Importing libraries
2024-08-26 18:22:25,207:INFO:Copying training dataset
2024-08-26 18:22:25,220:INFO:Defining folds
2024-08-26 18:22:25,220:INFO:Declaring metric variables
2024-08-26 18:22:25,224:INFO:Importing untrained model
2024-08-26 18:22:25,228:INFO:Extra Trees Classifier Imported successfully
2024-08-26 18:22:25,238:INFO:Starting cross validation
2024-08-26 18:22:25,241:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-08-26 18:22:29,140:INFO:Calculating mean and std
2024-08-26 18:22:29,143:INFO:Creating metrics dataframe
2024-08-26 18:22:29,147:INFO:Uploading results into container
2024-08-26 18:22:29,148:INFO:Uploading model into container now
2024-08-26 18:22:29,149:INFO:_master_model_container: 12
2024-08-26 18:22:29,149:INFO:_display_container: 2
2024-08-26 18:22:29,150:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=3747, verbose=0,
                     warm_start=False)
2024-08-26 18:22:29,150:INFO:create_model() successfully completed......................................
2024-08-26 18:22:29,416:INFO:SubProcess create_model() end ==================================
2024-08-26 18:22:29,416:INFO:Creating metrics dataframe
2024-08-26 18:22:29,427:INFO:Initializing Light Gradient Boosting Machine
2024-08-26 18:22:29,428:INFO:Total runtime is 0.8780527075131733 minutes
2024-08-26 18:22:29,431:INFO:SubProcess create_model() called ==================================
2024-08-26 18:22:29,432:INFO:Initializing create_model()
2024-08-26 18:22:29,432:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024EBB3A7DD0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024EB3665150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-26 18:22:29,432:INFO:Checking exceptions
2024-08-26 18:22:29,432:INFO:Importing libraries
2024-08-26 18:22:29,432:INFO:Copying training dataset
2024-08-26 18:22:29,462:INFO:Defining folds
2024-08-26 18:22:29,462:INFO:Declaring metric variables
2024-08-26 18:22:29,467:INFO:Importing untrained model
2024-08-26 18:22:29,476:INFO:Light Gradient Boosting Machine Imported successfully
2024-08-26 18:22:29,486:INFO:Starting cross validation
2024-08-26 18:22:29,493:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-08-26 18:22:31,762:INFO:Calculating mean and std
2024-08-26 18:22:31,763:INFO:Creating metrics dataframe
2024-08-26 18:22:31,765:INFO:Uploading results into container
2024-08-26 18:22:31,766:INFO:Uploading model into container now
2024-08-26 18:22:31,766:INFO:_master_model_container: 13
2024-08-26 18:22:31,767:INFO:_display_container: 2
2024-08-26 18:22:31,767:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3747, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-08-26 18:22:31,767:INFO:create_model() successfully completed......................................
2024-08-26 18:22:32,026:INFO:SubProcess create_model() end ==================================
2024-08-26 18:22:32,027:INFO:Creating metrics dataframe
2024-08-26 18:22:32,040:INFO:Initializing Dummy Classifier
2024-08-26 18:22:32,041:INFO:Total runtime is 0.9215991934140523 minutes
2024-08-26 18:22:32,046:INFO:SubProcess create_model() called ==================================
2024-08-26 18:22:32,046:INFO:Initializing create_model()
2024-08-26 18:22:32,046:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024EBB3A7DD0>, estimator=dummy, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024EB3665150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-26 18:22:32,047:INFO:Checking exceptions
2024-08-26 18:22:32,047:INFO:Importing libraries
2024-08-26 18:22:32,047:INFO:Copying training dataset
2024-08-26 18:22:32,064:INFO:Defining folds
2024-08-26 18:22:32,065:INFO:Declaring metric variables
2024-08-26 18:22:32,069:INFO:Importing untrained model
2024-08-26 18:22:32,075:INFO:Dummy Classifier Imported successfully
2024-08-26 18:22:32,086:INFO:Starting cross validation
2024-08-26 18:22:32,089:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-08-26 18:22:33,008:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-26 18:22:33,073:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-26 18:22:33,121:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-26 18:22:33,181:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-26 18:22:33,200:INFO:Calculating mean and std
2024-08-26 18:22:33,201:INFO:Creating metrics dataframe
2024-08-26 18:22:33,203:INFO:Uploading results into container
2024-08-26 18:22:33,203:INFO:Uploading model into container now
2024-08-26 18:22:33,203:INFO:_master_model_container: 14
2024-08-26 18:22:33,204:INFO:_display_container: 2
2024-08-26 18:22:33,204:INFO:DummyClassifier(constant=None, random_state=3747, strategy='prior')
2024-08-26 18:22:33,204:INFO:create_model() successfully completed......................................
2024-08-26 18:22:33,393:INFO:SubProcess create_model() end ==================================
2024-08-26 18:22:33,393:INFO:Creating metrics dataframe
2024-08-26 18:22:33,418:INFO:Initializing create_model()
2024-08-26 18:22:33,419:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024EBB3A7DD0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=3747, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-26 18:22:33,419:INFO:Checking exceptions
2024-08-26 18:22:33,421:INFO:Importing libraries
2024-08-26 18:22:33,421:INFO:Copying training dataset
2024-08-26 18:22:33,437:INFO:Defining folds
2024-08-26 18:22:33,438:INFO:Declaring metric variables
2024-08-26 18:22:33,438:INFO:Importing untrained model
2024-08-26 18:22:33,438:INFO:Declaring custom model
2024-08-26 18:22:33,440:INFO:Gradient Boosting Classifier Imported successfully
2024-08-26 18:22:33,442:INFO:Cross validation set to False
2024-08-26 18:22:33,442:INFO:Fitting Model
2024-08-26 18:22:48,017:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=3747, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-08-26 18:22:48,018:INFO:create_model() successfully completed......................................
2024-08-26 18:22:48,281:INFO:_master_model_container: 14
2024-08-26 18:22:48,281:INFO:_display_container: 2
2024-08-26 18:22:48,282:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=3747, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-08-26 18:22:48,282:INFO:compare_models() successfully completed......................................
2024-08-26 18:22:51,016:INFO:Initializing plot_model()
2024-08-26 18:22:51,017:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024EBB3A7DD0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=3747, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-08-26 18:22:51,017:INFO:Checking exceptions
2024-08-26 18:22:51,029:INFO:Preloading libraries
2024-08-26 18:22:51,042:INFO:Copying training dataset
2024-08-26 18:22:51,042:INFO:Plot type: feature
2024-08-26 18:22:51,042:WARNING:No coef_ found. Trying feature_importances_
2024-08-26 18:22:51,280:INFO:Visual Rendered Successfully
2024-08-26 18:22:51,516:INFO:plot_model() successfully completed......................................
2024-08-26 18:22:54,015:INFO:Initializing plot_model()
2024-08-26 18:22:54,015:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024EBB3A7DD0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=3747, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-08-26 18:22:54,016:INFO:Checking exceptions
2024-08-26 18:22:54,026:INFO:Preloading libraries
2024-08-26 18:22:54,034:INFO:Copying training dataset
2024-08-26 18:22:54,034:INFO:Plot type: auc
2024-08-26 18:22:54,196:INFO:Fitting Model
2024-08-26 18:22:54,198:INFO:Scoring test/hold-out set
2024-08-26 18:22:54,447:INFO:Visual Rendered Successfully
2024-08-26 18:22:54,674:INFO:plot_model() successfully completed......................................
2024-08-26 18:22:57,649:INFO:Initializing save_model()
2024-08-26 18:22:57,649:INFO:save_model(model=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=3747, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), model_name=LR Model Aula 5 062022, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\natha\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean')...
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=QuantileTransformer(copy=True,
                                                                    ignore_implicit_zeros=False,
                                                                    n_quantiles=1000,
                                                                    output_distribution='normal',
                                                                    random_state=3747,
                                                                    subsample=10000))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-08-26 18:22:57,649:INFO:Adding model into prep_pipe
2024-08-26 18:22:57,666:INFO:LR Model Aula 5 062022.pkl saved in current working directory
2024-08-26 18:22:57,714:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWra...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.1, loss='log_loss',
                                            max_depth=3, max_features=None,
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.0,
                                            min_samples_leaf=1,
                                            min_samples_split=2,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=100,
                                            n_iter_no_change=None,
                                            random_state=3747, subsample=1.0,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2024-08-26 18:22:57,715:INFO:save_model() successfully completed......................................
2024-08-26 18:23:01,048:INFO:Initializing load_model()
2024-08-26 18:23:01,048:INFO:load_model(model_name=LR Model Aula 5 062022, platform=None, authentication=None, verbose=True)
2024-08-26 18:23:07,021:INFO:PyCaret ClassificationExperiment
2024-08-26 18:23:07,021:INFO:Logging name: clf-default-name
2024-08-26 18:23:07,021:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-08-26 18:23:07,021:INFO:version 3.3.2
2024-08-26 18:23:07,021:INFO:Initializing setup()
2024-08-26 18:23:07,021:INFO:self.USI: 6b54
2024-08-26 18:23:07,021:INFO:self._variable_keys: {'X_train', 'fold_groups_param', 'exp_id', 'exp_name_log', 'gpu_param', 'data', 'seed', 'log_plots_param', 'y', 'X_test', 'memory', 'y_train', 'y_test', 'idx', 'fix_imbalance', 'html_param', '_ml_usecase', 'pipeline', 'gpu_n_jobs_param', 'is_multiclass', '_available_plots', 'X', 'target_param', 'logging_param', 'USI', 'fold_shuffle_param', 'fold_generator', 'n_jobs_param'}
2024-08-26 18:23:07,021:INFO:Checking environment
2024-08-26 18:23:07,021:INFO:python_version: 3.11.5
2024-08-26 18:23:07,021:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-08-26 18:23:07,021:INFO:machine: AMD64
2024-08-26 18:23:07,021:INFO:platform: Windows-10-10.0.22631-SP0
2024-08-26 18:23:07,021:INFO:Memory: svmem(total=8311836672, available=1156378624, percent=86.1, used=7155458048, free=1156378624)
2024-08-26 18:23:07,021:INFO:Physical Core: 4
2024-08-26 18:23:07,021:INFO:Logical Core: 8
2024-08-26 18:23:07,021:INFO:Checking libraries
2024-08-26 18:23:07,021:INFO:System:
2024-08-26 18:23:07,021:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-08-26 18:23:07,022:INFO:executable: C:\Users\natha\anaconda3\python.exe
2024-08-26 18:23:07,022:INFO:   machine: Windows-10-10.0.22631-SP0
2024-08-26 18:23:07,022:INFO:PyCaret required dependencies:
2024-08-26 18:23:07,022:INFO:                 pip: 23.2.1
2024-08-26 18:23:07,022:INFO:          setuptools: 68.0.0
2024-08-26 18:23:07,022:INFO:             pycaret: 3.3.2
2024-08-26 18:23:07,022:INFO:             IPython: 8.15.0
2024-08-26 18:23:07,022:INFO:          ipywidgets: 8.0.4
2024-08-26 18:23:07,022:INFO:                tqdm: 4.65.0
2024-08-26 18:23:07,022:INFO:               numpy: 1.24.3
2024-08-26 18:23:07,022:INFO:              pandas: 2.0.3
2024-08-26 18:23:07,022:INFO:              jinja2: 3.1.2
2024-08-26 18:23:07,022:INFO:               scipy: 1.11.1
2024-08-26 18:23:07,022:INFO:              joblib: 1.3.2
2024-08-26 18:23:07,022:INFO:             sklearn: 1.4.2
2024-08-26 18:23:07,022:INFO:                pyod: 2.0.1
2024-08-26 18:23:07,022:INFO:            imblearn: 0.12.3
2024-08-26 18:23:07,022:INFO:   category_encoders: 2.6.3
2024-08-26 18:23:07,022:INFO:            lightgbm: 4.5.0
2024-08-26 18:23:07,022:INFO:               numba: 0.57.1
2024-08-26 18:23:07,022:INFO:            requests: 2.31.0
2024-08-26 18:23:07,022:INFO:          matplotlib: 3.7.2
2024-08-26 18:23:07,022:INFO:          scikitplot: 0.3.7
2024-08-26 18:23:07,022:INFO:         yellowbrick: 1.5
2024-08-26 18:23:07,022:INFO:              plotly: 5.23.0
2024-08-26 18:23:07,023:INFO:    plotly-resampler: Not installed
2024-08-26 18:23:07,023:INFO:             kaleido: 0.2.1
2024-08-26 18:23:07,023:INFO:           schemdraw: 0.15
2024-08-26 18:23:07,023:INFO:         statsmodels: 0.14.0
2024-08-26 18:23:07,023:INFO:              sktime: 0.26.0
2024-08-26 18:23:07,023:INFO:               tbats: 1.1.3
2024-08-26 18:23:07,023:INFO:            pmdarima: 2.0.4
2024-08-26 18:23:07,023:INFO:              psutil: 5.9.0
2024-08-26 18:23:07,023:INFO:          markupsafe: 2.1.1
2024-08-26 18:23:07,023:INFO:             pickle5: Not installed
2024-08-26 18:23:07,023:INFO:         cloudpickle: 2.2.1
2024-08-26 18:23:07,023:INFO:         deprecation: 2.1.0
2024-08-26 18:23:07,023:INFO:              xxhash: 2.0.2
2024-08-26 18:23:07,023:INFO:           wurlitzer: Not installed
2024-08-26 18:23:07,023:INFO:PyCaret optional dependencies:
2024-08-26 18:23:07,023:INFO:                shap: Not installed
2024-08-26 18:23:07,023:INFO:           interpret: Not installed
2024-08-26 18:23:07,023:INFO:                umap: Not installed
2024-08-26 18:23:07,023:INFO:     ydata_profiling: 4.7.0
2024-08-26 18:23:07,023:INFO:  explainerdashboard: Not installed
2024-08-26 18:23:07,023:INFO:             autoviz: Not installed
2024-08-26 18:23:07,023:INFO:           fairlearn: Not installed
2024-08-26 18:23:07,023:INFO:          deepchecks: Not installed
2024-08-26 18:23:07,023:INFO:             xgboost: Not installed
2024-08-26 18:23:07,023:INFO:            catboost: Not installed
2024-08-26 18:23:07,023:INFO:              kmodes: Not installed
2024-08-26 18:23:07,024:INFO:             mlxtend: Not installed
2024-08-26 18:23:07,024:INFO:       statsforecast: Not installed
2024-08-26 18:23:07,024:INFO:        tune_sklearn: Not installed
2024-08-26 18:23:07,024:INFO:                 ray: Not installed
2024-08-26 18:23:07,024:INFO:            hyperopt: Not installed
2024-08-26 18:23:07,024:INFO:              optuna: Not installed
2024-08-26 18:23:07,024:INFO:               skopt: Not installed
2024-08-26 18:23:07,024:INFO:              mlflow: Not installed
2024-08-26 18:23:07,024:INFO:              gradio: Not installed
2024-08-26 18:23:07,024:INFO:             fastapi: Not installed
2024-08-26 18:23:07,024:INFO:             uvicorn: Not installed
2024-08-26 18:23:07,024:INFO:              m2cgen: Not installed
2024-08-26 18:23:07,024:INFO:           evidently: Not installed
2024-08-26 18:23:07,024:INFO:               fugue: Not installed
2024-08-26 18:23:07,024:INFO:           streamlit: Not installed
2024-08-26 18:23:07,024:INFO:             prophet: Not installed
2024-08-26 18:23:07,024:INFO:None
2024-08-26 18:23:07,024:INFO:Set up data.
2024-08-26 18:23:07,422:INFO:Set up folding strategy.
2024-08-26 18:23:07,422:INFO:Set up train/test split.
2024-08-26 18:23:08,036:INFO:Set up index.
2024-08-26 18:23:08,060:INFO:Assigning column types.
2024-08-26 18:23:08,441:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-08-26 18:23:08,489:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-26 18:23:08,490:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-26 18:23:08,514:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 18:23:08,515:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 18:23:08,554:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-26 18:23:08,555:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-26 18:23:08,579:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 18:23:08,580:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 18:23:08,580:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-08-26 18:23:08,619:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-26 18:23:08,655:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 18:23:08,656:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 18:23:08,713:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-26 18:23:08,752:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 18:23:08,752:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 18:23:08,753:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-08-26 18:23:08,817:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 18:23:08,817:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 18:23:08,902:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 18:23:08,902:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 18:23:08,903:INFO:Preparing preprocessing pipeline...
2024-08-26 18:23:08,980:INFO:Set up date feature engineering.
2024-08-26 18:23:08,980:INFO:Set up simple imputation.
2024-08-26 18:23:08,980:INFO:Set up removing multicollinearity.
2024-08-26 18:23:08,980:INFO:Set up binning of numerical features.
2024-08-26 18:23:09,105:INFO:Set up column transformation.
2024-08-26 18:23:09,108:INFO:Set up feature normalization.
2024-08-26 18:23:09,191:INFO:Set up column name cleaning.
2024-08-26 18:23:38,591:INFO:Finished creating preprocessing pipeline.
2024-08-26 18:23:38,611:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\natha\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pess...
                                    transformer=PowerTransformer(copy=True,
                                                                 method='yeo-johnson',
                                                                 standardize=False))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2024-08-26 18:23:38,611:INFO:Creating final display dataframe.
2024-08-26 18:23:53,425:INFO:Setup _display_container:                     Description             Value
0                    Session id              6080
1                        Target               mau
2                   Target type            Binary
3           Original data shape      (750000, 36)
4        Transformed data shape      (750000, 38)
5   Transformed train set shape      (525000, 38)
6    Transformed test set shape      (225000, 38)
7              Numeric features                 7
8                 Date features                 1
9      Rows with missing values             16.8%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Remove multicollinearity              True
15  Multicollinearity threshold              0.95
16               Transformation              True
17        Transformation method       yeo-johnson
18                    Normalize              True
19             Normalize method            zscore
20               Fold Generator   StratifiedKFold
21                  Fold Number                10
22                     CPU Jobs                -1
23                      Use GPU             False
24               Log Experiment             False
25              Experiment Name  clf-default-name
26                          USI              6b54
2024-08-26 18:23:53,720:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 18:23:53,725:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 18:23:53,816:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 18:23:53,817:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-26 18:23:53,831:INFO:setup() successfully completed in 46.88s...............
2024-08-26 18:23:58,711:INFO:Initializing create_model()
2024-08-26 18:23:58,712:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024E8E181510>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-26 18:23:58,712:INFO:Checking exceptions
2024-08-26 18:23:58,756:INFO:Importing libraries
2024-08-26 18:23:58,757:INFO:Copying training dataset
2024-08-26 18:23:59,539:INFO:Defining folds
2024-08-26 18:23:59,539:INFO:Declaring metric variables
2024-08-26 18:23:59,546:INFO:Importing untrained model
2024-08-26 18:23:59,552:INFO:Light Gradient Boosting Machine Imported successfully
2024-08-26 18:23:59,562:INFO:Starting cross validation
2024-08-26 18:23:59,568:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-26 18:24:14,356:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:24:14,514:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:24:14,773:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:24:14,984:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:24:15,073:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:24:16,072:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:24:16,160:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:24:16,292:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:24:17,699:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2024-08-26 18:24:17,815:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2024-08-26 18:25:48,670:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:25:48,914:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:26:20,575:INFO:Calculating mean and std
2024-08-26 18:26:20,630:INFO:Creating metrics dataframe
2024-08-26 18:26:20,705:INFO:Finalizing model
2024-08-26 18:26:49,076:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-08-26 18:26:49,079:INFO:[LightGBM] [Info] Number of positive: 41050, number of negative: 483950
2024-08-26 18:26:49,153:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.028293 seconds.
2024-08-26 18:26:49,153:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-26 18:26:49,153:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-26 18:26:49,154:INFO:[LightGBM] [Info] Total Bins 385
2024-08-26 18:26:49,155:INFO:[LightGBM] [Info] Number of data points in the train set: 525000, number of used features: 36
2024-08-26 18:26:49,159:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.078190 -> initscore=-2.467191
2024-08-26 18:26:49,159:INFO:[LightGBM] [Info] Start training from score -2.467191
2024-08-26 18:26:49,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:26:49,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:26:49,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:26:49,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:26:49,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:26:49,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:26:49,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:26:49,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:26:49,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:26:49,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:26:49,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:26:49,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:26:49,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:26:49,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:26:49,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:26:49,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:26:49,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:26:49,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:26:49,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:26:49,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:26:49,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:26:49,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:26:49,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:26:49,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:26:49,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:26:49,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:26:49,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:26:49,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:26:49,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:26:49,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:26:49,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:26:49,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:26:49,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:26:49,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:26:49,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:26:49,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:26:49,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:26:49,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:26:49,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:26:49,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:26:49,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:26:49,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:26:49,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:26:49,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:26:49,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:26:49,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:26:49,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:26:49,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:26:49,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:26:49,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:26:49,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:26:49,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:26:49,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:26:49,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:26:49,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:26:49,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:26:49,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:26:49,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:26:49,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:26:49,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:26:49,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:26:49,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:26:49,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:26:49,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:26:49,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:26:49,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:26:49,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:26:49,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:26:49,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:26:49,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:26:49,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:26:49,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:26:49,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:26:49,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:26:49,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:26:49,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:26:49,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:26:49,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:26:49,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:26:49,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:26:49,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:26:49,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:26:49,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:26:49,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:26:49,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:26:49,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:26:49,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:26:49,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:26:49,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:26:49,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:26:49,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:26:49,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:26:49,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:26:49,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:26:49,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:26:49,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:26:49,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:26:49,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:26:49,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:26:49,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:26:49,943:INFO:Uploading results into container
2024-08-26 18:26:49,945:INFO:Uploading model into container now
2024-08-26 18:26:49,982:INFO:_master_model_container: 1
2024-08-26 18:26:49,982:INFO:_display_container: 2
2024-08-26 18:26:49,985:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6080, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-08-26 18:26:49,985:INFO:create_model() successfully completed......................................
2024-08-26 18:26:51,189:INFO:Initializing tune_model()
2024-08-26 18:26:51,189:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024E8E181510>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6080, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-08-26 18:26:51,190:INFO:Checking exceptions
2024-08-26 18:26:51,721:INFO:Copying training dataset
2024-08-26 18:26:52,174:INFO:Checking base model
2024-08-26 18:26:52,174:INFO:Base model : Light Gradient Boosting Machine
2024-08-26 18:26:52,178:INFO:Declaring metric variables
2024-08-26 18:26:52,182:INFO:Defining Hyperparameters
2024-08-26 18:26:52,382:INFO:Tuning with n_jobs=-1
2024-08-26 18:26:52,382:INFO:Initializing RandomizedSearchCV
2024-08-26 18:26:57,168:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:26:57,282:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:26:57,311:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:26:57,864:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:26:57,976:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:26:57,979:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:26:59,003:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:26:59,650:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2024-08-26 18:27:00,228:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:27:01,318:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2024-08-26 18:28:46,089:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:28:46,702:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:28:46,945:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:28:47,439:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:28:49,849:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:28:51,072:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:29:04,896:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:30:17,813:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:30:19,930:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2024-08-26 18:30:38,793:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:30:39,350:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:30:41,000:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2024-08-26 18:30:45,134:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:30:57,164:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:31:44,922:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:32:15,773:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:32:18,558:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:32:19,004:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:32:32,946:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:32:58,843:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:33:00,870:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2024-08-26 18:33:42,718:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:33:44,478:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2024-08-26 18:33:58,671:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:34:00,174:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:34:00,685:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:34:07,989:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:34:29,979:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:34:36,902:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:35:24,482:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:35:55,783:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:35:59,897:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:36:01,819:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2024-08-26 18:36:01,825:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:36:04,200:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2024-08-26 18:36:11,577:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:36:13,339:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:36:40,291:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:36:45,088:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:37:21,820:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:37:41,365:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:37:41,576:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:37:43,065:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:37:49,106:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:37:51,206:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2024-08-26 18:38:00,666:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:38:02,462:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2024-08-26 18:38:25,246:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:40:04,939:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:40:05,524:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:40:06,483:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:40:06,810:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:40:08,719:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:40:42,260:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:41:27,392:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:41:52,269:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:41:53,909:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2024-08-26 18:41:54,314:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:41:56,210:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2024-08-26 18:41:59,399:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:42:58,362:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:42:59,578:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:43:18,000:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:43:18,588:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:43:26,689:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:43:57,433:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:44:46,642:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:44:48,104:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:44:49,719:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2024-08-26 18:44:59,016:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:45:01,716:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:45:02,971:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2024-08-26 18:45:07,771:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:46:24,892:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:46:32,876:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:46:39,038:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:46:39,694:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:46:41,521:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:47:37,983:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:47:59,959:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:48:01,978:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2024-08-26 18:48:02,327:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:48:03,427:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:48:04,516:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:48:04,635:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2024-08-26 18:48:42,622:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:49:23,696:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:49:29,237:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:49:29,420:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:49:30,280:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:49:44,205:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:50:42,286:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:50:44,074:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2024-08-26 18:50:56,955:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:50:59,001:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2024-08-26 18:50:59,190:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:50:59,693:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:51:00,575:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:51:34,387:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:52:23,651:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:52:29,804:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:52:30,147:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:52:35,315:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:52:44,426:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:52:46,498:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2024-08-26 18:53:54,726:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:53:55,190:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:53:56,461:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:53:56,590:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2024-08-26 18:54:05,575:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:55:10,729:INFO:best_params: {'actual_estimator__reg_lambda': 0.1, 'actual_estimator__reg_alpha': 0.05, 'actual_estimator__num_leaves': 2, 'actual_estimator__n_estimators': 250, 'actual_estimator__min_split_gain': 0.2, 'actual_estimator__min_child_samples': 91, 'actual_estimator__learning_rate': 0.3, 'actual_estimator__feature_fraction': 0.5, 'actual_estimator__bagging_freq': 7, 'actual_estimator__bagging_fraction': 0.7}
2024-08-26 18:55:10,849:INFO:Hyperparameter search completed
2024-08-26 18:55:10,857:INFO:SubProcess create_model() called ==================================
2024-08-26 18:55:10,897:INFO:Initializing create_model()
2024-08-26 18:55:10,897:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024E8E181510>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6080, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024E9289A490>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.1, 'reg_alpha': 0.05, 'num_leaves': 2, 'n_estimators': 250, 'min_split_gain': 0.2, 'min_child_samples': 91, 'learning_rate': 0.3, 'feature_fraction': 0.5, 'bagging_freq': 7, 'bagging_fraction': 0.7})
2024-08-26 18:55:10,898:INFO:Checking exceptions
2024-08-26 18:55:10,902:INFO:Importing libraries
2024-08-26 18:55:10,907:INFO:Copying training dataset
2024-08-26 18:55:12,923:INFO:Defining folds
2024-08-26 18:55:12,927:INFO:Declaring metric variables
2024-08-26 18:55:13,117:INFO:Importing untrained model
2024-08-26 18:55:13,118:INFO:Declaring custom model
2024-08-26 18:55:13,138:INFO:Light Gradient Boosting Machine Imported successfully
2024-08-26 18:55:13,150:INFO:Starting cross validation
2024-08-26 18:55:13,172:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-26 18:55:21,163:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:55:21,828:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:55:21,834:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:55:23,161:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:55:23,287:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:55:23,965:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:55:24,413:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:55:25,391:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2024-08-26 18:55:26,381:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2024-08-26 18:57:11,098:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:57:11,257:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:57:49,142:INFO:Calculating mean and std
2024-08-26 18:57:49,182:INFO:Creating metrics dataframe
2024-08-26 18:57:49,287:INFO:Finalizing model
2024-08-26 18:58:18,951:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-08-26 18:58:18,952:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-08-26 18:58:18,952:INFO:[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7
2024-08-26 18:58:19,907:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-08-26 18:58:19,911:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-08-26 18:58:19,911:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-08-26 18:58:19,911:INFO:[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7
2024-08-26 18:58:19,912:INFO:[LightGBM] [Info] Number of positive: 41050, number of negative: 483950
2024-08-26 18:58:20,007:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.028548 seconds.
2024-08-26 18:58:20,008:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-26 18:58:20,008:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-26 18:58:20,008:INFO:[LightGBM] [Info] Total Bins 385
2024-08-26 18:58:20,008:INFO:[LightGBM] [Info] Number of data points in the train set: 525000, number of used features: 36
2024-08-26 18:58:20,015:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.078190 -> initscore=-2.467191
2024-08-26 18:58:20,016:INFO:[LightGBM] [Info] Start training from score -2.467191
2024-08-26 18:58:20,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:20,439:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:20,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:20,448:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:20,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:20,499:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:20,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:20,517:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:20,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:20,526:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:20,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:20,534:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:20,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:20,561:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:20,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:20,619:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:20,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:20,627:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:20,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:20,636:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:20,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:20,644:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:20,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:20,670:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:20,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:20,706:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:20,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:20,729:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:20,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:20,744:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:20,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:20,777:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:20,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:20,786:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:20,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:20,794:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:20,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:20,811:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:20,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:20,828:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:20,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:20,836:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:20,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:20,840:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:20,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:20,848:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:20,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:20,857:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:20,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:20,865:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:20,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:20,874:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:20,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:20,882:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:20,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:20,891:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:20,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:20,903:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:20,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:20,911:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:20,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:20,921:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:20,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:20,930:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:20,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:20,939:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:20,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:20,947:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:20,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:20,955:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:20,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:20,964:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:20,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:20,971:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:20,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:20,981:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:20,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:20,989:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:20,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:20,997:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,006:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,015:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,023:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,031:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,040:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,049:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,057:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,066:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,074:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,082:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,091:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,099:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,107:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,115:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,124:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,133:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,141:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,151:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,159:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,168:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,176:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,185:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,193:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,202:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,211:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,220:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,228:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,237:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,246:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,255:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,263:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,271:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,281:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,290:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,299:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,307:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,315:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,324:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,333:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,342:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,350:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,358:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,366:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,375:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,384:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,392:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,401:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,410:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,421:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,430:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,439:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,447:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,456:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,465:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,472:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,481:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,489:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,498:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,506:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,515:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,525:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,534:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,542:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,552:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,560:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,569:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,577:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,586:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,595:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,603:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,611:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,624:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,632:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,640:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,649:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,657:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,665:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,672:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,682:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,686:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,695:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,703:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,711:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,720:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,728:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,736:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,745:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,753:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,761:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,769:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,778:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,787:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,796:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,805:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,813:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,823:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,833:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,841:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,851:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,859:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,868:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,877:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,886:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,895:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,903:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,911:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,920:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,929:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,943:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,952:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,960:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,969:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,978:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,986:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,990:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:21,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:21,999:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:22,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:22,008:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:22,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:22,018:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:22,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:22,026:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:22,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:22,037:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:22,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:22,047:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:22,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:22,058:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:22,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:22,066:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:22,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:22,075:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:22,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:22,083:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:22,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:22,092:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:22,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:22,100:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:22,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:22,109:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:22,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:22,118:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:22,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:22,127:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:22,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:22,136:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:22,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:22,144:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:22,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:22,154:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:22,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:22,163:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:22,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:22,175:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:22,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:22,185:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:22,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:22,194:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:22,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:22,203:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:22,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:22,211:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:22,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:22,221:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:22,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:22,229:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:22,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:22,239:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:22,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:22,249:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:22,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:22,257:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:22,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:22,265:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:22,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:22,276:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:22,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:22,285:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:22,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:22,293:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:22,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:22,302:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:22,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 18:58:22,312:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-08-26 18:58:22,352:INFO:Uploading results into container
2024-08-26 18:58:22,353:INFO:Uploading model into container now
2024-08-26 18:58:22,360:INFO:_master_model_container: 2
2024-08-26 18:58:22,360:INFO:_display_container: 3
2024-08-26 18:58:22,363:INFO:LGBMClassifier(bagging_fraction=0.7, bagging_freq=7, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.3, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.2,
               n_estimators=250, n_jobs=-1, num_leaves=2, objective=None,
               random_state=6080, reg_alpha=0.05, reg_lambda=0.1, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-08-26 18:58:22,363:INFO:create_model() successfully completed......................................
2024-08-26 18:58:23,601:INFO:SubProcess create_model() end ==================================
2024-08-26 18:58:23,601:INFO:choose_better activated
2024-08-26 18:58:23,604:INFO:SubProcess create_model() called ==================================
2024-08-26 18:58:23,605:INFO:Initializing create_model()
2024-08-26 18:58:23,605:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024E8E181510>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6080, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-26 18:58:23,605:INFO:Checking exceptions
2024-08-26 18:58:23,608:INFO:Importing libraries
2024-08-26 18:58:23,610:INFO:Copying training dataset
2024-08-26 18:58:24,463:INFO:Defining folds
2024-08-26 18:58:24,463:INFO:Declaring metric variables
2024-08-26 18:58:24,463:INFO:Importing untrained model
2024-08-26 18:58:24,463:INFO:Declaring custom model
2024-08-26 18:58:24,465:INFO:Light Gradient Boosting Machine Imported successfully
2024-08-26 18:58:24,465:INFO:Starting cross validation
2024-08-26 18:58:24,467:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-26 18:58:29,431:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:58:29,975:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:58:30,305:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:58:31,699:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:58:33,888:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:58:34,324:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:58:34,373:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:58:35,099:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 18:58:36,374:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2024-08-26 18:58:36,492:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2024-08-26 19:00:08,603:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 19:00:08,739:WARNING:C:\Users\natha\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2024-08-26 19:00:41,071:INFO:Calculating mean and std
2024-08-26 19:00:41,082:INFO:Creating metrics dataframe
2024-08-26 19:00:41,131:INFO:Finalizing model
2024-08-26 19:01:09,155:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-08-26 19:01:09,158:INFO:[LightGBM] [Info] Number of positive: 41050, number of negative: 483950
2024-08-26 19:01:09,245:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.030541 seconds.
2024-08-26 19:01:09,245:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-26 19:01:09,245:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-26 19:01:09,246:INFO:[LightGBM] [Info] Total Bins 385
2024-08-26 19:01:09,247:INFO:[LightGBM] [Info] Number of data points in the train set: 525000, number of used features: 36
2024-08-26 19:01:09,250:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.078190 -> initscore=-2.467191
2024-08-26 19:01:09,250:INFO:[LightGBM] [Info] Start training from score -2.467191
2024-08-26 19:01:09,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:09,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:09,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:09,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:09,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:09,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:09,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:09,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:09,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:09,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:09,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:09,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:09,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:09,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:09,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:09,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:09,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:09,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:09,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:09,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:09,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:09,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:09,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:09,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:09,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:09,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:09,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:09,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:09,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:09,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:09,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:09,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:09,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:09,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:09,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:09,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:09,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:09,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:09,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:09,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:09,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:09,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:09,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:09,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:09,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:09,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:09,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:09,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:09,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:09,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:09,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:09,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:09,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:09,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:09,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:09,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:09,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:09,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:09,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:09,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:09,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:09,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:09,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:09,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:09,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:09,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:09,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:09,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:09,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:09,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:09,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:09,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:09,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:09,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:09,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:09,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:09,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:09,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:09,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:09,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:09,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:09,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:09,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:09,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:09,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:09,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:09,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:09,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:09,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:09,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:09,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:09,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:09,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:09,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:09,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:09,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:09,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:09,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:09,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:09,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:10,022:INFO:Uploading results into container
2024-08-26 19:01:10,023:INFO:Uploading model into container now
2024-08-26 19:01:10,027:INFO:_master_model_container: 3
2024-08-26 19:01:10,027:INFO:_display_container: 4
2024-08-26 19:01:10,030:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6080, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-08-26 19:01:10,030:INFO:create_model() successfully completed......................................
2024-08-26 19:01:10,979:INFO:SubProcess create_model() end ==================================
2024-08-26 19:01:10,981:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6080, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 1.0
2024-08-26 19:01:10,981:INFO:LGBMClassifier(bagging_fraction=0.7, bagging_freq=7, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.3, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.2,
               n_estimators=250, n_jobs=-1, num_leaves=2, objective=None,
               random_state=6080, reg_alpha=0.05, reg_lambda=0.1, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 1.0
2024-08-26 19:01:10,982:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6080, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2024-08-26 19:01:10,982:INFO:choose_better completed
2024-08-26 19:01:10,985:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-08-26 19:01:11,006:INFO:_master_model_container: 3
2024-08-26 19:01:11,006:INFO:_display_container: 3
2024-08-26 19:01:11,007:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6080, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-08-26 19:01:11,007:INFO:tune_model() successfully completed......................................
2024-08-26 19:01:11,234:INFO:Initializing finalize_model()
2024-08-26 19:01:11,234:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024E8E181510>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6080, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-08-26 19:01:11,237:INFO:Finalizing LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6080, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-08-26 19:01:11,643:INFO:Initializing create_model()
2024-08-26 19:01:11,643:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024E8E181510>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6080, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-08-26 19:01:11,644:INFO:Checking exceptions
2024-08-26 19:01:11,647:INFO:Importing libraries
2024-08-26 19:01:11,647:INFO:Copying training dataset
2024-08-26 19:01:11,671:INFO:Defining folds
2024-08-26 19:01:11,671:INFO:Declaring metric variables
2024-08-26 19:01:11,671:INFO:Importing untrained model
2024-08-26 19:01:11,671:INFO:Declaring custom model
2024-08-26 19:01:11,672:INFO:Light Gradient Boosting Machine Imported successfully
2024-08-26 19:01:11,674:INFO:Cross validation set to False
2024-08-26 19:01:11,675:INFO:Fitting Model
2024-08-26 19:01:54,222:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-08-26 19:01:54,223:INFO:[LightGBM] [Info] Number of positive: 58643, number of negative: 691357
2024-08-26 19:01:54,337:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044766 seconds.
2024-08-26 19:01:54,338:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-26 19:01:54,338:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-26 19:01:54,338:INFO:[LightGBM] [Info] Total Bins 385
2024-08-26 19:01:54,338:INFO:[LightGBM] [Info] Number of data points in the train set: 750000, number of used features: 36
2024-08-26 19:01:54,341:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.078191 -> initscore=-2.467188
2024-08-26 19:01:54,342:INFO:[LightGBM] [Info] Start training from score -2.467188
2024-08-26 19:01:54,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:54,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:54,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:54,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:54,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:54,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:54,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:54,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:54,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:54,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:54,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:54,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:54,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:54,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:54,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:54,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:54,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:54,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:54,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:54,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:54,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:54,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:54,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:54,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:54,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:54,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:54,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:54,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:54,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:54,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:54,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:54,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:54,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:54,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:54,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:54,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:54,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:54,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:54,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:54,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:54,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:54,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:54,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:54,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:54,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:54,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:54,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:54,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:54,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:54,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:54,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:54,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:54,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:54,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:54,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:54,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:54,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:54,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:54,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:54,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:54,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:55,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:55,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:55,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:55,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:55,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:55,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:55,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:55,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:55,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:55,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:55,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:55,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:55,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:55,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:55,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:55,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:55,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:55,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:55,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:55,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:55,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:55,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:55,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:55,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:55,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:55,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:55,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:55,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:55,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:55,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:55,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:55,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:55,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:55,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:55,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:55,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:55,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:55,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:55,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-26 19:01:55,626:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda',
                                             'bom'],
                                    transform...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=6080, reg_alpha=0.0,
                                reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-08-26 19:01:55,627:INFO:create_model() successfully completed......................................
2024-08-26 19:01:55,875:INFO:_master_model_container: 3
2024-08-26 19:01:55,875:INFO:_display_container: 3
2024-08-26 19:01:55,900:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda',
                                             'bom'],
                                    transform...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=6080, reg_alpha=0.0,
                                reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-08-26 19:01:55,900:INFO:finalize_model() successfully completed......................................
2024-08-26 19:01:56,109:INFO:Initializing evaluate_model()
2024-08-26 19:01:56,109:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024E8E181510>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda',
                                             'bom'],
                                    transform...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=6080, reg_alpha=0.0,
                                reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-08-26 19:01:56,446:INFO:Initializing plot_model()
2024-08-26 19:01:56,446:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024E8E181510>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda',
                                             'bom'],
                                    transform...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=6080, reg_alpha=0.0,
                                reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-08-26 19:01:56,446:INFO:Checking exceptions
2024-08-26 19:01:56,681:INFO:Preloading libraries
2024-08-26 19:01:56,689:INFO:Copying training dataset
2024-08-26 19:01:56,689:INFO:Plot type: pipeline
2024-08-26 19:01:57,099:INFO:Visual Rendered Successfully
2024-08-26 19:01:57,345:INFO:plot_model() successfully completed......................................
2024-08-26 19:03:22,717:INFO:Initializing plot_model()
2024-08-26 19:03:22,717:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024E8E181510>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda',
                                             'bom'],
                                    transform...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=6080, reg_alpha=0.0,
                                reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-08-26 19:03:22,717:INFO:Checking exceptions
2024-08-26 19:03:22,975:INFO:Preloading libraries
2024-08-26 19:03:22,984:INFO:Copying training dataset
2024-08-26 19:03:22,985:INFO:Plot type: auc
2024-08-26 19:03:25,245:INFO:Fitting Model
2024-08-26 19:03:25,256:INFO:Scoring test/hold-out set
2024-08-26 19:03:26,285:INFO:Visual Rendered Successfully
2024-08-26 19:03:26,545:INFO:plot_model() successfully completed......................................
2024-08-26 19:03:26,573:INFO:Initializing plot_model()
2024-08-26 19:03:26,573:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024E8E181510>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda',
                                             'bom'],
                                    transform...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=6080, reg_alpha=0.0,
                                reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-08-26 19:03:26,573:INFO:Checking exceptions
2024-08-26 19:03:26,890:INFO:Preloading libraries
2024-08-26 19:03:26,895:INFO:Copying training dataset
2024-08-26 19:03:26,895:INFO:Plot type: confusion_matrix
2024-08-26 19:03:28,975:INFO:Fitting Model
2024-08-26 19:03:28,981:INFO:Scoring test/hold-out set
2024-08-26 19:03:29,883:INFO:Visual Rendered Successfully
2024-08-26 19:03:30,132:INFO:plot_model() successfully completed......................................
